{"0": {
    "doc": "Example",
    "title": "Example",
    "content": "Directory: /home/groups/oroaklab/sample/directory . Summary of post. Placeholder sentence. Write descriptions here. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Description of Figure 1. figure-01 . Description of Figure 2. figure-02 . | Function example 1: Line 1 Line 2 Line 3 . | Function example 2: Line 1 Line 2 Line 3 . | . ",
    "url": "/docs/to_be_sorted/2020-10-07-post-0001.html",
    "relUrl": "/docs/to_be_sorted/2020-10-07-post-0001.html"
  },"1": {
    "doc": "SSC Final Validation Tables with Annotations",
    "title": "SSC Final Validation Tables with Annotations",
    "content": "Directory: /home/groups/oroaklab/nishida/ssc Box Directory: https://ohsu.app.box.com/folder/81820136345 . Updated the SSC variant tables to include annotations derived from the columns. The biggest discrepancies come from the borderline cases at AF 0.40-0.60 that are hard to call either mosaic or germline. The auto-annotations use the PHET values but can still differ in calls between LCL and WB. Also note that there are cases where it is identified as mosaic parental trans in LCL and mosaic parental nontrans in WB (or vice versa). Twin variant calls in pool 5 do not have twin information in this sheet. An issue with these annotations are cases where the mutation shows up in small frequency in a non-main sample. This may be more than error and may be evidence of a trans parental mosaic mutation. We are currently only testing pzero on the main sample with the previously derived allele frequency. We could test for novel mosaics in other samples. For now, I am using a hard cutoff where a mutation must have of an allele frequency &gt; 0.01 (found in 1 of 100 reads). Three examples taken from pool 1 where the originally identified mutation was in a child but from this validation could be a parental mosaic. The first two cases are germline in the child and could be parental mosaics. figure-01 . ",
    "url": "/docs/to_be_sorted/2020-10-09-post-0002.html",
    "relUrl": "/docs/to_be_sorted/2020-10-09-post-0002.html"
  },"2": {
    "doc": "Two Week Update: 2020-10-09",
    "title": "Two Week Update: 2020-10-09",
    "content": "Mosaic - Read through Deidre’s notes and now have a clear picture of the next steps in collating the data after variant calls. I will first send a draft description of what I believe the next round of summary files should look like. If these seem good I will get them all together across all the data for summarization for the progress report. Glial Atlas - Resolved the issue with global TSS enrichments and finished the dimensionality reduction on the full set of data (all peaks and all cells). Will ping Casey to get cluster information for the individual DA’s. Exacloud’s pay structure is changing so we might need to think about a longer-term solution for how to process these larger data sets. MIPs - The Friday Illumina run seemed to have died at the tail end. I demuxed everything and gave Sara her share. I need to give Sally a different suite of scripts to deal with the data quality issues of R2 for her processing. SSC - New auto-annotations were generated for each pool, manually checked, and I wrote up the few common discrepencies found. This should conclude any changes to the final variant validation tables for the time being. CRISPRcapture - The modified tables were finished and I gave some more QC metrics split out by the genome stratifications for sanity checks. Methods writeup was sent to Taylor and I’ll finish a more static summary of where everything is and put it on this blog. Spark Networks - Presented some preliminary data fixing the enrichment test and showing the enrichments across the layers/area in addition to age. Similar enrichment patterns across clusters indicate how to best group these clusters together for redoing the enrichments to give us more meaningful results (because everything is enriched currently). Do some qualitative heatmaps and pseudotime-sorted summaries of key genes. Coussen’s - Finish pseudotime DA. We will probably have to set up data migration with Google Cloud, which is what they are using instead of exacloud, eventually. ",
    "url": "/docs/to_be_sorted/2020-10-09-post-0003.html",
    "relUrl": "/docs/to_be_sorted/2020-10-09-post-0003.html"
  },"3": {
    "doc": "Two Week Update: 2020-11-09",
    "title": "Two Week Update: 2020-11-09",
    "content": "Mosaics - The progress report was finished and the majority of the processing and organization of the data is now complete. There are errors somewhere in the categorical classification of the putative variants and the next step is to figure out from where they are occuring. For this initial pass I have only looked at simplex quad families and now I can take another pass through the scripts and code to work on the multiple quad and trio families. As I’m going through this next pass I will make a more formal writeup and recording of the methods and where everything is located here on this blog. SPARK Single Cell / Networks - Start collapsing the original clusters into more discrete groups and get some loose pseudotime analyses done within the larger clusters. Take a look at the actual significance values of the enrichments being performed. SciTools Updates - I want to make some quick fixes to beautify the TSS enrichment plots. Also I will add hg19 into the TSS enrichment options. I have some DA updates that can get pushed as well. I also want to do another quick cleaning and updating of the dependencies. And I have handful of code related to paralellizing some operations like creating the matrix and TSS enrichment but I think I will just put them up on this blog rather than pushing them directly into the scitools code (since who knows how we will be using SLURM and exacloud in the future). Coussen’s - Get in touch with Christian to see where things were left and pass off the remaining pseudotime analyses. Misc - Write up something for the Master’s level job posting. Check in with Sally about the MIP processing. Interview with Ellen. And I’m going to mess around with the Box API because I think moving files from the cluster directly to Box or vice versa would be convenient (gets around having to both download and then upload using my own slower bandwidth). ",
    "url": "/docs/to_be_sorted/2020-11-09-post-0004.html",
    "relUrl": "/docs/to_be_sorted/2020-11-09-post-0004.html"
  },"4": {
    "doc": "Scitools scATAC Metrics",
    "title": "Scitools scATAC Metrics",
    "content": "TSS enrichment at a single cell level: Calculated as the ratio of signal to noise. Signal is defined as the region around TSS +/- 100bp. Noise is defined as the 100bp regions +/- 2000bp from TSS regions that do no overlap with signal. This leads signal and noise being slightly different in size but reads are uniquely counted into a single bin versus other methods where a read can fall into multiple TSS and noise regions. Output is a two-column value file. scitools bam_tssenrich [bam] [hg38 or mm10 or dm6] . TSS enrichment at bulk level, ENCODE: Calculated via ENCODE standards, ENCODE ENRICHMENT scitools bam_tssenrich -E [bam] [hg38 or mm10 or dm6] Example enrichment output figure: figure-01 . TSS bulk calculation starts with a bam2bed conversion and is potentially intensive depending on the size of the BAM. A parallelizable version of the bulk TSS calculation can be performed on exacloud. TSS enrichment at bulk level, inflated: This uses a larger distance from TSS sites, larger bins combining more reads, and chooses highest positions via, this article scitools bam_tssenrich -E -r 2000 -n 11 -s MAX [bam] [hg38 or mm10 or dm6] . TSS sites are gathered from ENSEMBL and are curated as such: /home/groups/oroaklab/refs/hg38/ensembl_tss/readme.txt /home/groups/oroaklab/refs/mm10/ensembl_tss/readme.txt /home/groups/oroaklab/refs/dm6/ensembl_tss/readme.txt . Independent FRIP caller: This FRIP calculation is divorced from scitools atac_count and is slightly more accurate. The existing FRIP calculation that occurs during matrix generation double-counts reads that overlap multiple peaks. scitools bam_frip [bam] [bed] . ",
    "url": "/docs/to_be_sorted/2020-12-17-post-0005.html",
    "relUrl": "/docs/to_be_sorted/2020-12-17-post-0005.html"
  },"5": {
    "doc": "Scitools Scrublet Function",
    "title": "Scitools Scrublet Function",
    "content": "Load the scitools python environment. source /home/groups/oroaklab/nishida/scitools_env/bin/activate . Link and rename example data. dir=\"/home/groups/oroaklab/adey_lab/projects/Drosophila_Tau/201208_EL_Tau\" pre=\"201208_EL_Tau_all.no_bulk.merge.bbrd.q10.filt.macs3.TSS2plus.filt.RG.dm_peaks.w_bulk_bed.counts\" ln -s ${dir}/${pre}.sparseMatrix.cols.gz cols.gz ln -s ${dir}/${pre}.sparseMatrix.values.gz values.gz ln -s ${dir}/${pre}.cistopic.50.UMAP.dims umap.dims . Run the scitools function. scitools matrix_scrublet values.gz cols.gz output_prefix . Plot the values onto UMAP. scitools plot-dims -V output_prefix.doublet_scores.values -S 0,1 umap.dims . Example Scrublet distribution figure: figure-01 Example Scrublet values projected onto UMAP figure: figure-02 . A bimodial scrublet distribution should make a clear case for what is and isn’t a doublet. A scrublet distribution that just tapers off is likely not flagging true doublets, just cells with weaker signal. Draw your own threshold and remove doublet-filled clusters based on the projection onto the UMAP. ",
    "url": "/docs/to_be_sorted/2021-02-18-post-0006.html",
    "relUrl": "/docs/to_be_sorted/2021-02-18-post-0006.html"
  },"6": {
    "doc": "NextSeq Fidelity Evaluation",
    "title": "NextSeq Fidelity Evaluation",
    "content": "Directory: /home/groups/oroaklab/nishida/nextseq_organization_may4 Ran: /home/groups/oroaklab/nishida/nextseq_organization_may4/run.txt . Here’s the breakdown of how our runs have fared over the years. There’s about ~300 runs post-2018 and 89 have errors that terminate NextSeq2Fastq but there’s no re-calling. 451 Madbum Seq Runs: 234 DO NOT have folders in both oroaklab and oroakdata 209 are missing log files 190 before 2018 19 after 2018 17 successful bcl2fastq but not attempt to backup 7 prematurely terminate 1 extreme outlier problem 217 have folders in both oroaklab and oroakdata 184 have md5sums 176 successful copying 8 unsuccessful copying 6 prematurely terminate during bcl2fastq but falsely counted as successful by NextSeq2Fastq 2 are missing log files 27 DO NOT have md5sums 13 successful bcl2fastq but overly cautious and terminate before copying 3 are missing log files 9 prematurely terminate 2 extreme outlier problems 6 other (alt chemistry with different formats) . Are all these prematurely terminations and missing logs bad? Yes and no. These may represent cases where people may not actually be using the data (the run is bad and isn’t used). These may also represent cases where the FASTQs are incomplete and are being used as though they were complete. But there’s no way to discern this difference, there are no records or logs meaning we can’t go back, and ultimately the data doesn’t become backed up. I fixed NextSeq2Fastq to more accurately parse the logs but this is one of the minor issues (we only have 6 instances where bcl2fastq fails but does not properly give an ERROR message so everything continues without detection). For the most part, it is accurately throwing errors in the logs and correctly stopping the process but nobody is reading the logs. If the process terminates and throws an error we need to evaluate what happened. And if you do nonstandard bcl2fastq calls or if the run has some funky chemistry you need to manually calculate md5sums and rsync the folder or we won’t have backups. Here’s an example using my adjusted NextSeq2Fastq call showing how we’re losing 75% of the data. $ perl /home/groups/oroaklab/nishida/nextseq_organization_may4/NextSeq2Fastq.pl -R 210326_NS500556_0469_AHKWVYAFX2 -f /home/groups/oroaklab/nishida/nextseq_organization_may4 -l /home/groups/oroaklab/nishida/nextseq_organization_may4/run_processing.log f6c2b0ec6a4bcf2c6c1725bdf3fa7b47 /home/groups/oroaklab/nishida/nextseq_organization_may4/210326_NS500556_0469_AHKWVYAFX2/Undetermined_S0_R1_001.fastq.gz 0bd9dd75fbdab145d749fac73b0503db /home/groups/oroaklab/nishida/nextseq_organization_may4/210326_NS500556_0469_AHKWVYAFX2/Undetermined_S0_R2_001.fastq.gz 86a47c890822517dc8e15f414548fedd /home/groups/oroaklab/fastq/210326_NS500556_0469_AHKWVYAFX2/Undetermined_S0_R1_001.fastq.gz 5b5d52f587f9f6ae05292009cf39fe4f /home/groups/oroaklab/fastq/210326_NS500556_0469_AHKWVYAFX2/Undetermined_S0_R2_001.fastq.gz $ zcat /home/groups/oroaklab/nishida/nextseq_organization_may4/210326_NS500556_0469_AHKWVYAFX2/Undetermined_S0_R1_001.fastq.gz | wc -l 919755600 $ zcat /home/groups/oroaklab/fastq/210326_NS500556_0469_AHKWVYAFX2/Undetermined_S0_R1_001.fastq.gz | wc -l 228860360 . How do we fix our old runs? I think for every pre-2021 we just freeze and rsync it as it is but for everything post-2021 we redo it. Also, once the machine finally gets back on the network we are changing how Nextseq2Fastq works and nobody else will have to run it (which is why we’re looking at it now in addition to trying to backup and save space). ",
    "url": "/docs/to_be_sorted/2021-05-05-post-0007.html",
    "relUrl": "/docs/to_be_sorted/2021-05-05-post-0007.html"
  },"7": {
    "doc": "Single Cell TBR1 Preliminary Evaluations",
    "title": "Single Cell TBR1 Preliminary Evaluations",
    "content": "Directory: /home/groups/oroaklab/nishida/sc_tmp1 . Ryan made a first pass through this data written up on his blog. I used his annotations and kept the old TSS enrichments (ArchR calculates its own internally). He made these after filtering so not all of the cells in the current ArchR project will have entries but these cells are confidently going to be filtered out. I went through ArchR up to about part 6 in the ArchR full manual. I made a broad first pass to get everything recorded, added Ryan’s existing stuff, plotted the metrics, filtered, and then did the dimensionality reduction and clustering. Then after the lab meeting I went and played around the filtering and iterative LSI options. General metrics show low TSS enrichment and higher fragment sizes. figure-01 . “The bump around 200 is tagmentation on either side of a nucleosome (they are about 185bp) below that is subnucleosomal, which can be a sign of over-tagmentation or poor chromatin structure. The linker region between nucleosome is 11-80ish no but usually on the much smaller size so you don’t expect two tagmentation events between nucleosomes. I think in this case it is reflecting nucleosomes falling apart/off DNA.” -Ryan . Various UMAPs with different methods, variables, and cutoffs. All of the methods reveal the characteristics of a blob. figure-02 . - Directory setup and bigwig creation, run.txt. - Setting up the Arrow file, run_archr_1_setup.Rscript. - Tiling matrix workaround and the main steps without filtering, run_archr_2_process.Rscript. - Adding annotations, plotting distributions, filtering, and dimred/clustering, run_archr_3_filter.Rscript. - Similar to preliminary pass but with harder filtering, run_archr_4_harderfilter.Rscript. - Harder filtering and alternative LSI calling, run_archr_5_LSIfeatures_harderfilter.Rscript. - All of the above but with also with filtering by fragment size, run_archr_6_fragFilter_LSIfeatures_harderfilter.Rscript. With module R/4.0.4 this little bit will let you load up the current ArchR project for yourself: . # library, resource ArchR library(presto) library(ArchR) # set env addArchRGenome(\"mm10\") set.seed(25) # reload the previous project proj &lt;- loadArchRProject(path = \"/home/groups/oroaklab/nishida/sc_tmp1/ArchROutput/\") . ",
    "url": "/docs/to_be_sorted/2021-05-07-post-0008.html",
    "relUrl": "/docs/to_be_sorted/2021-05-07-post-0008.html"
  },"8": {
    "doc": "Single Cell Alignments with no Alt Chromosomes",
    "title": "Single Cell Alignments with no Alt Chromosomes",
    "content": "Alt chromosomes in our hg38 and mm10 alignments (UCSC description) cause multi-mapping in those regions. BWA flags multi-mapping reads with a MAPQ score of 0 causing them to all be lost downstream in our analysis pipeline. For most single-cell analyses we do not need to consider the alternative chromosomes and they can fall in regions of genes used as markers. Here are replaced genome builds without alts. See /home/groups/oroaklab/refs/hg38/GCA_000001405.15_GRCh38/retrieval.txt and /home/groups/oroaklab/refs/mm10/GCA_000001635.5_GRCm38.p3_no_alt_analysis_set/retrieval.txt for origins of FASTA files. Indexes for BWA were recalled with v0.7.15-r1140. FASTQ-Align Call . ln -s /home/groups/oroaklab/demultiplex/201214_NS500556_0445_AHMF2CBGXF/201214_NS500556_0445_AHMF2CBGXF.1.fq.gz testR1.fq.gz ln -s /home/groups/oroaklab/demultiplex/201214_NS500556_0445_AHMF2CBGXF/201214_NS500556_0445_AHMF2CBGXF.2.fq.gz testR2.fq.gz no_alt_align_hg38_=\"/home/groups/oroaklab/refs/hg38/hs38d1_noalt.fna.gz\" no_alt_align_mm10_=\"/home/groups/oroaklab/refs/mm10/GCA_000001635.5_GRCm38.p3_noalt.fna.gz\" scitools fastq-align -t 28 $no_alt_align_hg38_ testoutput testR1.fq.gz testR2.fq.gz . MAPQ using standard genome with alts vs. hs38d1_noalt . $ samtools view /home/groups/oroaklab/adey_lab/projects/Panc_U54/201214_NS500556_0445_AHMF2CBGXF/201214_NS500556_0445_AHMF2CBGXF.bam chr1:198,636,928-198,659,067 | cut -f 5 | sort | uniq -c 2500 0 $ samtools view testoutput.bam chr1:198,636,928-198,659,067 | cut -f 5 | sort | uniq -c 19 0 1 1 1 6 3 24 1 36 1 39 22 40 1 41 1 44 1 45 1 49 1 50 1 51 2 53 4 54 1 57 2 59 4874 60 . ",
    "url": "/docs/to_be_sorted/2021-05-08-post-0009.html",
    "relUrl": "/docs/to_be_sorted/2021-05-08-post-0009.html"
  },"9": {
    "doc": "Single Cell TBR1 Coembedding Tests",
    "title": "Single Cell TBR1 Coembedding Tests",
    "content": "Directory: /home/groups/oroaklab/nishida/sc_tmp1/casey_coembed . To address the lack of discrete clustering we used previously generated data from Casey to anchor our data. Using Casey’s peak set alone with the data creates a bit more separation. Though maybe it is mostly from how small and transparent I plotted the points on the UMAP. figure-01 . Direct coembedding of the data together fails. Datasets are completely separated. figure-02 . - Setting up the Arrow file with coembedded data, run_archr_1_setup.Rscript. - Preliminary analysis with the coembedded data, run_archr_2_coembed.Rscript. - Commands for merging datasets and using the alternative peak set, run_coembed.txt. ",
    "url": "/docs/to_be_sorted/2021-05-09-post-0010.html",
    "relUrl": "/docs/to_be_sorted/2021-05-09-post-0010.html"
  },"10": {
    "doc": "Single Cell TBR1 ENCODE DHS Index Tests",
    "title": "Single Cell TBR1 ENCODE DHS Index Tests",
    "content": "Directory: /home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index/first_pass . Code: run.txt. Calling peaks on this data doesn’t work because it is too noisy. Using Casey’s cleaner peak set was working a bit better. Tiling helps sparse amounts of data but won’t help with noise. This peak set is basically Casey’s peak set+. List is from here: biorxiv paper. If the data wasn’t as noisy then calling peaks specifically across this dataset is the best approach. You’d even get novel peaks. But with technically poor data the technical methods alone do not seem to be working. Using biologically motivated references however seems to select appropriate sites for consideration in dimensionality reduction. figure-01 . Since this seems to be working, the dimensionality reduction needs to be re-run with filtering and doublet removal. Doublet removal on a dataset this size is giving memory issues so I am moving it to Exacloud. ",
    "url": "/docs/to_be_sorted/2021-05-11-post-0011.html",
    "relUrl": "/docs/to_be_sorted/2021-05-11-post-0011.html"
  },"11": {
    "doc": "SPARK Mosaic List, Summary Counts of Annotations",
    "title": "SPARK Mosaic List, Summary Counts of Annotations",
    "content": "Directory: https://www.dropbox.com/home/SPARK%20Mosaics . This provides a full tabulated count of the annotations per category for each of the lists of SPARK mosaic data using the data without germline parental calls. Link to Markdown: R Markdown . ",
    "url": "/docs/to_be_sorted/2021-05-11-post-0012.html",
    "relUrl": "/docs/to_be_sorted/2021-05-11-post-0012.html"
  },"12": {
    "doc": "Single Cell TBR1 ENCODE DHS Index Final UMAP and Clusters",
    "title": "Single Cell TBR1 ENCODE DHS Index Final UMAP and Clusters",
    "content": "Directory: /home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index Run: run.txt Final Matrix: tbr1_ko_encodeDHSindex_finalfilter.filt.sparseMatrix.values Final UMAP Dims: tbr1_ko_encodeDHSindex_finalfilter.filt.cistopic.30.UMAP.dims Final Clusters: tbr1_ko_encodeDHSindex_finalfilter.filt.cistopic.30.k50.pg.annot . Here is the final UMAP and clusters. This was performed using the ENCODE DHS index, a milder TSS enrichment filter for cells &gt; 1.5 TSS enrichment, and default scrublet calling. Why does this end up looking better? My guess is that the cells with lower TSS enrichment are genuine clusters (like a cell type that is hard to get in general). These lower TSS cells cannot get normal peaks called so using the ENCODE DHS index is able to better identify their signal. And their inclusion helps cluster everything else. figure-01 . Compare these to some failed attempts using higher TSS enrichment filters at 2 and 2.7 which lose all form. figure-02 . ",
    "url": "/docs/to_be_sorted/2021-05-27-post-0013.html",
    "relUrl": "/docs/to_be_sorted/2021-05-27-post-0013.html"
  },"13": {
    "doc": "Single Cell TBR1 Cluster DA",
    "title": "Single Cell TBR1 Cluster DA",
    "content": "Directory: /home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index/DA Run: run.txt Header for DA: header.txt . These are the results from comparing all the clusters against one another to look for differentially accessible peaks. I performed a term factor transformation to adjust for depth and compared cells by pheograph cluster annotation via the Wilcoxon rank sum test. Peaks are annotated to their nearest gene and p-values are corrected with an FDR correction. The FDR correction does not work on this dataset. There are +1M peaks but peaks with p-values of &lt; 0.01 are usually in the few hundreds or lower. The FDR correction ends up setting everything to 1. For now, just use the regular p-values. Probably start it at a threshold of 0.01 but you can move it up to 0.05 or even higher if desirable. I left the files with the FDR column in there with the suffix FDR but they won’t be of use. Here’s an example of how I’d start parsing through the data. This example would show you the nearby genes that have statistically different peaks between pg_10 and pg_11. This example yields 55 results which is consistent with what we normally see from this analysis (and also a friendly number for humans to parse through). # open the file, filter for peaks with a pvalue &lt; 0.01, filter for peaks +/- 10000bp to a TSS, pull out gene names, sort, print unique results # move the thresholds as desired cat DA_pg.pg_10_pg_11.txt | awk '$7 &lt; 0.01' | awk '$10 &lt; 10000 &amp;&amp; $10 &gt; -10000' | cut -f 9 | sort | uniq . ",
    "url": "/docs/to_be_sorted/2021-05-28-post-0014.html",
    "relUrl": "/docs/to_be_sorted/2021-05-28-post-0014.html"
  },"14": {
    "doc": "SPARK RefSeq CDS and Splice Site Reference Generation",
    "title": "SPARK RefSeq CDS and Splice Site Reference Generation",
    "content": "Directory: /home/groups/oroaklab/nishida/spark_mosaic/refs/cds_splice_sites Run: run.txt . The purpose of this is to establish the reference file created in hg19 for hg38: /home/groups/oroaklab/refs/GRCh37/Homo_sapiens_refseq_cds_splice_positions.txt. There are however no instructions concerning how it was made or the refseq version from which it was created. To try to replicate this reference, every CDS and stop codon entry in the GTF will be pulled out to represent ‘cds’. Every transcript with more than one exon will have a ‘splice’ entry for the two bases extending internally for each internal exon boundary. Below is a comparison of the originally generated cds/splice reference from an unknown hg19 RefSeq version to a version of hg19 RefSeq from circa ~2015 using the logic above. There is greater than 99.5% similarity between these references with the ~2015 reference having more bases in all categories in general (likely because it is newer). Also included are the numbers from the 2021 RefSeq version for hg38 and the liftOver of that back to hg19. Similarity is closer to 95% here and also the hg38 version contains more bases in all categories relative to the other references. With such high concordance, I am comfortable with using this going forward as our reference. SDTRF sites are taken from Annovar’s hg38 genomicSuperDups and simpleRepeats databases (the same used for annotation of the mosaic list). Original hg19 contained 2,909,050 sites representing 8.104452% of the original sites. This hg38 references contains 3,476,939 sites representing 8.492237% of the original sites, a comparable amount. Screenshot of spreadsheet: figure-01 . Spreadsheet: figure-02 . ",
    "url": "/docs/to_be_sorted/2021-05-28-post-0015.html",
    "relUrl": "/docs/to_be_sorted/2021-05-28-post-0015.html"
  },"15": {
    "doc": "SPARK Joint Coverage Counter Tool Fidelity",
    "title": "SPARK Joint Coverage Counter Tool Fidelity",
    "content": "Directory: /home/groups/oroaklab/nishida/spark_mosaic/burden/test_compare . The tool, /home/users/kruppd/scripts/file/joint_coverage_calc_front.py, needed to be rewritten into something more flexible. It also needs to eliminate hard-coded family information since my tables are already pre-split by family. This changes it into simply looking for the overlap of sites between a sorted coverage file and the reference with bedops and takes advantage of numerical sorting of the output to make quicker counts. Here a comparison is performed attempting to regenerate the original output in both manners and checking for fidelity. Code for running is in: /home/groups/oroaklab/nishida/spark_mosaic/burden/test_compare/run.txt. The md5sums are comparable in the first check of comparing the re-use of the original tools. $ md5sum $NEW_OUT aae58c37f826d37f62e9449e8a03c90a /home/groups/oroaklab/nishida/spark_mosaic/burden/test_compare/interval_joint_cov_P24_01.comp.table $ md5sum $ORIGINAL_OUT aae58c37f826d37f62e9449e8a03c90a /home/groups/oroaklab/data/SSC/reprocessed/metrics/joint_cov/pilot_24/interval_joint_cov_P24_01.table . The count outputs are nearly identical in the second check for comparing the new tool to the old tool. The minor difference is that they are off by 51 due to me missing a count when I am transitioning between thresholds. But since the counts are in the 1M’s this seems like a gentle difference (and can be fixed post-hoc if necessary). Markdown showing the similarities: figure-01 . ",
    "url": "/docs/to_be_sorted/2021-05-30-post-0016.html",
    "relUrl": "/docs/to_be_sorted/2021-05-30-post-0016.html"
  },"16": {
    "doc": "SPARK Joint Coverage Plots",
    "title": "SPARK Joint Coverage Plots",
    "content": "Warning! Legacy entry. Refer to Jun 2 update fixing lower coverages. Directory: /home/groups/oroaklab/nishida/spark_mosaic/burden Run: run.txt . Joint coverage plots were created separately for simplex quads, multiplex quads, and simplex trios. These count the number of bases over 52 thresholds (from the range of needing 1-250 counts) for each member of a family, the total of the family, and the average of the family. These are subset into six regions, non-SDTRF (CDS) sites and SDTRF sites and then those are split into autosomal, X, and Y chromosomes. Coverage plots are in the following markdown. At a threshold of 5x coverage still only less than half of the bases are covered. figure-01 . Links to Burden Data: jointcoverage.simplextrios.txt jointcoverage.simplexquads.txt jointcoverage.multiplexquads.txt . ",
    "url": "/docs/to_be_sorted/2021-05-30-post-0017.html",
    "relUrl": "/docs/to_be_sorted/2021-05-30-post-0017.html"
  },"17": {
    "doc": "SPARK Joint Coverage Table Fix",
    "title": "SPARK Joint Coverage Table Fix",
    "content": "Directory: /home/groups/oroaklab/nishida/spark_mosaic/refs/cds_splice_sites/annovar_hg38 Run: run.txt . Directory: /home/groups/oroaklab/nishida/spark_mosaic/burden Run: run.2_redo_newref.txt . References are regenerated from ANNOVAR. Comparisons between this Annovar 2018 hg38 reference and the current 2021 reference are here showing &gt; 99% bases present in the older version relative to the newer. figure-01 . Joint coverage across families were recalled with this new reference and with the small bug fixed (coverage counts are no longer off by 1). Joint coverage plots were recreated separately for simplex quads, multiplex quads, and simplex trios. These count the number of bases over 52 thresholds (from the range of needing 1-250 counts) for each member of a family, the total of the family, and the average of the family. These are subset into six regions, non-SDTRF (CDS) sites and SDTRF sites and then those are split into autosomal, X, and Y chromosomes. Coverage plots are in the following markdown. There is now appropriate coverage across the exome and thresholds can be picked. figure-02 . Links to Burden Data: jointcoverage.simplextrios.txt jointcoverage.simplexquads.txt jointcoverage.multiplexquads.txt . ",
    "url": "/docs/to_be_sorted/2021-06-02-post-0018.html",
    "relUrl": "/docs/to_be_sorted/2021-06-02-post-0018.html"
  },"18": {
    "doc": "SPARK Mosaic List FRACTION_MORE Annotations",
    "title": "SPARK Mosaic List FRACTION_MORE Annotations",
    "content": "Directory: /home/groups/oroaklab/nishida/spark_mosaic/final_june Run: run.txt . Another round of recategorizing as per: /home/users/kruppd/scripts/cohort/ssc_fraction_and_filter_snvs.R. To all final SPARK tables, we are adding a column for the annotation of FRACTION_MORE and columns for the PSAME tests (for mosaic transmission only). FRACTION_MORE describes and subsets the categories of FRACTION into more granularity. The following tests are applied to the following categories: - GERMLINE_CHILD is tested for GERMLINE_CHILD_GONADAL (50% in both children and absent in parents, quads only) - MULTI_MOSAIC calls are tested if they are MOSAIC_CHILD_GONADAL (mosaic in both children and absent in parents, quads only). - GERMLINE_PARENTAL calls are tested for transmission and become either GERMLINE_PARENTAL_NONTRANS, GERMLINE_PARENTAL_TRANS_MATERNAL, GERMLINE_PARENTAL_TRANS_PATERNAL, GERMLINE_PARENTAL_TRANS_EITHER, or GERMLINE_PARENTAL_TRANS_CONFLICT. - MOSAIC_PARENTAL_TRANS and MOSAIC_PARENTAL_WITH_TRANS_CONFLICT are tested with stricter parameters. Their phet threshold is decreased from 0.001 to 0.0001 and they are tested with a Fisher’s Exact test between parents and children, the probability yielding PSAME with a threhsold of &lt; 0.01. MOSAIC_PARENTAL_TRANS_PATERNAL, MOSAIC_PARENTAL_TRANS_MATERNAL, MOSAIC_PARENTAL_LIKELY_GERMLINE (if failing higher phet thresholding), or put back into MOSAIC_PARENTAL_WITH_TRANS_CONFLICT (if failing PSAME tests). - All other FRACTION categories are left as they are for FRACTION_MORE. ",
    "url": "/docs/to_be_sorted/2021-06-03-post-0019.html",
    "relUrl": "/docs/to_be_sorted/2021-06-03-post-0019.html"
  },"19": {
    "doc": "SPARK Mosaic Index",
    "title": "SPARK Mosaic Index",
    "content": "This serves as a separate accessible copy of the README.txt for the SPARK Mosaic project. Final Mosaic Lists (July 17th): Simplex Quads w/ Loose Filter DISCONTINUED BUT HERE FOR POSTERITY . Mosaic Lists (June): Simplex Quads w/ Loose Filter Multiplex Quads w/ Loose Filter Simplex Trios w/ Loose Filter Simplex Quads w/ Strict Test Filter Multiplex Quads w/ Strict Test Filter Simplex Trios w/ Strict Test Filter Simplex Quads w/ Strict Test Filter, no Germline Parental Multiplex Quads w/ Strict Test Filter, no Germline Parental Simplex Trios w/ Strict Test Filter, no Germline Parental . SPARK Annotations Used, 20190820: SPARK Annotations . Links to List of Gene Names with Alternate Names: Essential.alt.genes Exac.Intol.alt.genes Exac.Mid.alt.genes Exac.Tol.alt.genes FUSIL.alt.genes . Joint Coverage: Genomic Individal/Avg Coverage, Simplex Quads Genomic Joint Coverage, Simplex Quads Genomic Individal/Avg Coverage, Multiplex Quads Genomic Joint Coverage, Multiplex Quads Genomic Individal/Avg Coverage, Simplex Trios Genomic Joint Coverage, Simplex Trios . Joint Coverage by Gene-set for Quad Simplex: jointcoverage.Essential.txt jointcoverage.ExacInt.txt jointcoverage.ExacMid.txt jointcoverage.ExacTol.txt jointcoverage.FUSIL.txt . Joint Coverage by Gene-set for Quad Multiplex: jointcoverage.Essential.txt jointcoverage.ExacInt.txt jointcoverage.ExacMid.txt jointcoverage.ExacTol.txt jointcoverage.FUSIL.txt . Joint Coverage by Gene-set for Trio Simplex: jointcoverage.Essential.txt jointcoverage.ExacInt.txt jointcoverage.ExacMid.txt jointcoverage.ExacTol.txt jointcoverage.FUSIL.txt . Markdowns: Preliminary, Loading, Filtering, and Subsetting, Simplex Quad Preliminary, Plotting Genomic Coverages and SNV Counts, Simplex Quad Preliminary, Plotting SNV Counts as Hists, Simplex Quad Preliminary, Plotting Allele Frequencies, Simplex Quad Preliminary, Updated Loading, Filtering, and Subsetting, Simplex Quad Preliminary, Updated Genomic Coverages and SNV Counts, Simplex Quad Preliminary, Final Table Creation, Simplex Quad Preliminary, Loading, Filtering, and Subsetting, Simplex Trio Preliminary, Genomic Coverages, SNV Counts, and Allele Frequencies, Simplex Trio Preliminary, Loading, Filtering, and Subsetting, Multiplex Quad Preliminary, Genomic Coverages, SNV Counts, and Allele Frequencies, Multiplex Quad Testing, Comparison of Burden Counters Testing, Summary of FRACTION Annotations Testing, Genomic Burden Coverage Plots Simplex Quad Synonymous SNV Splice Distances Outlier Detection Prep, Simplex Quads Outlier Detection Figures, Simplex Quads Outlier Detection Prep, Simplex Trios Outlier Detection Figures, Simplex Trios Outlier Detection Prep, Multiplex Quads Outlier Detection Figures, Multiplex Quads . The data is first filtered with loose criteria that will not be changed: there must be 8 reads at the location for the samples, the population allele frequencies must be less than 0.001, the variant is called less than four times across the families in the list, it must have at least 3 variant reads, and it must have an exonic refseq annotation. The data is then filtered again with stricter criteria (testfilter). These criteria were developed for the older lists, might not be as appropriate for these lists, and may change eventually. These stricter criteria are: five variant reads, greater than 0.03 AF, called by at least two callers (mpup, lofreq, or varscan), has an upper 90% confidence intervals via Agresti-Coull method above or equal to 5%, MISMATCH_XM_ALT_MEDIAN &lt;= 3, and SCORE_400_RB3 &gt; 0.518. I then filtered it down to toss out the numerous germline parental calls that won’t be of use to us for looking at mosaics. The data here is unlikely to change but will certainly get filtered down further in the future. Currently, the three lists were made and looked at completely separate from each other. So columns like “NUM_FAMILY_FOUND” will only count up families where the variant is found within the one list and not across all three lists. All columns are the same across the three lists. The trio list has “NAs” for the columns referencing the ‘sib’ family member. For the multiplex list, know that Spark labels usually use the convention of ‘father’, ‘mother’, ‘proband’, and ‘sibling’ but a few families are labeled differently – either with multiple probands, multiple siblings, or “half_sibling” or other labels. In these cases, I continue to use the column names for PRO and SIB in my list even if a family has two samples labeled “SIB”. The exact sample in question will be in the Sample field. The categories (FRACTION column) we group into are: GERMLINE_CHILD, MOSAIC_CHILD, MOSAIC_PARENTAL_NONTRANS, MOSAIC_PARENTAL_TRANS, GERMLINE_CONFLICT, MOSAIC_CHILD_WITH_PARENTAL_CONFLICT, MOSAIC_PARENTAL_WITH_TRANS_CONFLICT, and MULTI_MOSAIC. The “MULTI_MOSAIC” and “CONFLICT” groups will probably be entirely ignored going forward. They indicate that a putative mosaic was found but the variant’s presence or absence in the other members of the family is not resolved or conflating. “SCORE_400_RB3” is probably our best column for the time being to use for sorting mosaics by which have the best support. Here are descriptions of all the columns in the table: 1/CHR, 2/START, 3/STOP, 4/REF, 5/ALT - general variant information 6/FAMILY, 7/SAMPLE, 8/FRACTION - SF family ID, SP sample ID, putative mosaic annotation 9/DP_MAIN, 10/DPALT_MAIN, 11/AF_MAIN - the depth of reads, depth of alt reads, and AF for the main person of the family 12/LOFREQ_STATS_NAMES, 13/LOFREQ_STATS, 14/MPUP_STATS_NAMES, 15/MPUP_STATS, 16/VARSCAN_STATS_NAMES, 17/VARSCAN_STATS - stats from the three variant callers with their descriptor fields 18/MISMATCH_REF_READS, 19/MISMATCH_ALT_READS, 20/MISMATCH_OTHER_READS, 21/MISMATCH_SPAN_DELS, 22/MISMATCH_MAPQ_REF_MEAN, 23/MISMATCH_MAPQ_ALT_MEAN, 24/MISMATCH_MAPQ_OTHER_MEAN, 25/MISMATCH_MAPQ_REF_MEDIAN, 26/MISMATCH_MAPQ_ALT_MEDIAN, 27/MISMATCH_MAPQ_OTHER_MEDIAN, 28/MISMATCH_MAPQ_REF_MODE, 29/MISMATCH_MAPQ_ALT_MODE, 30/MISMATCH_MAPQ_OTHER_MODE, 31/MISMATCH_XM_REF_MEAN, 32/MISMATCH_XM_ALT_MEAN, 33/MISMATCH_XM_OTHER_MEAN, 34/MISMATCH_XM_REF_MEDIAN, 35/MISMATCH_XM_ALT_MEDIAN, 36/MISMATCH_XM_OTHER_MEDIAN, 37/MISMATCH_XM_REF_MODE, 38/MISMATCH_XM_ALT_MODE, 39/MISMATCH_XM_OTHER_MODE - large collection of stats concerning mismatches across the region, only MISMATCH_XM_ALT_MEDIAN gets used downstream for another derived column 40/DP_FA, 41/DP_MO, 42/DP_PRO, 43/DP_SIB, 44/DPALT_FA, 45/DPALT_MO, 46/DPALT_PRO, 47/DPALT_SIB - depths across all family members 48/AF_EXAC, 49/AF_gnomAD - AFs from ExAC v0.3 and gnomAD 2.1 50/ERROR_VAR, 51/ERROR_ALL, 52/ERROR_VARMAX, 53/ERROR_RATE - error in the region calculated over a random subset of 1000 samples, only rate gets used downstream for another derived column 54/NUM_FAMILY_FOUND - number of families the variant is found before filtering 55/PHET_FA, 56/PHET_MO, 57/PHET_PRO, 58/PHET_SIB - pvalue of exact test given the depth and the depth of the alt read in each family member testing if it is less than 0.5 (heterogeneous) 59/PERSON - identity of the person 60/DPALT_BIN - binary column derived from DPALT_MAIN used for SCORE_400_RB3 61/ERROR_BIN_3 - categorical column (low, medium, high) derived from ERROR_RATE used for SCORE_400_RB3 62/AF_BIN_3 - categorical column (low, medium, high) derived from AF_MAIN used for SCORE_400_RB3 63/REF_CG - categorical column (C or G) derived from REF used for SCORE_400_RB3 64/XM_ALT_1 - binary column derived from MISMATCH_XM_ALT_MEDIAN used for SCORE_400_RB3 65/SCORE_400_RB3 - score from logistic regression model that takes into account many of the other columns 66/genomicSuperDupes, 67/rmsk, 68/simpleRepeat, 69/mutationType, 70/exonicAnnotation, 71/variantFunctionType, 72/variantFunctionGene - annotations with annovar-2018-06-15 73/filteredCohortCount - number of families the variant is found after preliminary filtering 74/AF_L90CI_AC_MAIN, 75/AF_U90CI_AC_MAIN - upper and lower 90% confidence intervals via Agresti-Coull method 76/FRACTION_ORIGINAL - old, erroneous annotations of the site for posterity, see May 9 update 77/FRACTION_MORE - a subset of column 8, FRACTION, with further granularity, see June 3 update 78/PSAME_FAxPRO, 79/PSAME_FAxSIB, 80/PSAME_MOxPRO, 81/PSAME_MOxSIB - Fisher’s exact test comparing depths and alt reads from parents versus children for the purposes of testing a transmission event. Final tables also contain: 82/MIN_DP - The minimum depth of all family members. 83/ACC_DIST, 84/DON_DIST, 85/ACC_TRANSCRIPT, 86/DON_TRANSCRIPT - The distances in basepairs to an acceptor or donor site and which transcript from which this distance is derived. 87/COMPLEX_EVENT - All FALSE in final tables representing collapsed complex events. ### . *Update for July 17, 2021 . Tables are modified for July 17. Final tables have been added with final filters applied and collapsing of duplicate entries and complex events. Five new columns have been added. One for minimum depth, four for the donor and acceptor distances and transcripts, and one for whether or not the row represents a complex event. ### . *Update for June 3, 2021 . Tables are modified for June 3. I added five new columns. The PSAME columns and the FRACTION_MORE column. FRACTION_MORE is derived here. ### . *Update for May 9, 2021 . Tables are modified for May 9. I updated the “FRACTION” annotation column adjusting an error in the later files. There is one new column at the end called, “FRACTION_ORIGINAL”. This contains the first call of the fraction that should be ignored but I’m keeping it in the file as a record. ",
    "url": "/docs/to_be_sorted/2021-06-03-post-0020.html",
    "relUrl": "/docs/to_be_sorted/2021-06-03-post-0020.html"
  },"20": {
    "doc": "SPARK Gene Set Joint Coverage",
    "title": "SPARK Gene Set Joint Coverage",
    "content": "Directory: /home/groups/oroaklab/nishida/spark_mosaic/refs/cds_splice_sites/annovar_hg38/genesets Run: run.txt . The list of gene names are taken directly from the files used previously except for the newer FUSIL list. They are taken from the following references: Essential gene list, 2455 genes EXAC gene lists, 3232 genes (Intolerant), 4555 genes (Mid), 10264 genes (Tolerant) FUSIL gene list, 163 genes . Annotations of the base positions are taken from Annovar’s hg38 RefSeq reference (2018-06-15). Previously, the appropriate annotations were pulled with a simple grep and throwing out anything annotated as antisense ‘-AS’ as such: . while read gene ; do grep -w $gene /home/groups/oroaklab/refs/GRCh37/Homo_sapiens_refseq_cds_splice_with_gene_and_SDTRF.txt | grep -v \\-AS.\\&gt; | grep -vw SDTRF &gt;&gt; geneset_pos_cds_exac_tolerant.txt grep -w $gene /home/groups/oroaklab/refs/GRCh37/Homo_sapiens_refseq_cds_splice_with_gene_and_SDTRF.txt | grep -v \\-AS.\\&gt; | grep -w SDTRF &gt;&gt; geneset_pos_sdtrf_exac_tolerant.txt done &lt; ~/tmp/Exac.Tol.genes . Annotations now are done by looking for exact matches of the gene name parsing every name after spliting the annotation field by both ‘,’ and ‘;’. Gene names were originally derived from older hg19 annotations. Gene names that were not found in hg38 by the same name were replaced with their updated name taken from GeneCards.org. Gene name changes are preserved in the directory and the usable gene name lists are below and in the main index of files. The small, following list of genes remained missing after this replacement and also could not be found by any of their other alternate names, /home/groups/oroaklab/nishida/spark_mosaic/refs/cds_splice_sites/annovar_hg38/genesets/missing.txt. The contents of the file are below for perusing and mostly consist of pseudogenes and RNA-genes. It is likely these were not designed to be captured in this sequencing. # Bases annotated with these genes by Annovar were absent. Multiple names for the genes were consulted via GeneCards.org. FUSIL list and ESSENTIAL list had the presence of all genes. EXAC INTOL LIST: 1 RNA gene(s) - SNAR-A6 EXAC MID LIST: 5 protein-coding gene(s) - ZNF487, CCDC163, ZNF738, RPSAP58, MFSD14C 7 pseudogene(s) - ANKRD20A4P, FAM153CP, SEPT7P9, TCP10L3, TMEM14EP, TMPRSS11BNL, FMO6P 7 RNA gene(s) - MIR9-1HG, IRF1-AS1, LINC02897, LINC00696, ST20-AS1, PRNT, TMEM256-PLSCR3 EXAC TOL LIST: 5 protein-coding gene(s) - LILRA3, PRR21, GSTT1, GOLGA8S, ZNF724 8 pseudogene(s) - PCDHB17P, FRG1BP, ATP5F1EP2, ZNF812P, FAM183BP, EP400P1, GABARAPL3, TTLL13 21 RNA gene(s) - LINC01588, PIK3CD-AS1, LINC01599, LINC01600, C5orf55, LINC02915, ZNF436-AS1, RAD51L3-RFFL, TLX1NB, GAS8-AS1, C1orf220, LINC01098, LINC01559, CLLU1, ARHGAP19-SLIT1, LINC01465, ARRDC1-AS1, LINC01565, IGF2BP2-AS1, NDUFV1-DT, DSCR4 1 chimeric gene(s) - ERCC6-PGBD3 . Gene set joint coverage files for the burden analysis were made using these five gene lists. Directory: /home/groups/oroaklab/nishida/spark_mosaic/burden_genesets Run: run.txt . Total bases covered. essential nonSDTRF full 5823791 essential nonSDTRF chrx 130972 essential nonSDTRF chry 0 essential SDTRF full 238236 essential SDTRF chrx 6074 essential SDTRF chry 0 exintol nonSDTRF full 8778453 exintol nonSDTRF chrx 585376 exintol nonSDTRF chry 0 exintol SDTRF full 298903 exintol SDTRF chrx 23054 exintol SDTRF chry 0 exmid nonSDTRF full 5348096 exmid nonSDTRF chrx 309748 exmid nonSDTRF chry 25108 exmid SDTRF full 525697 exmid SDTRF chrx 70317 exmid SDTRF chry 132 extol nonSDTRF full 16220596 extol nonSDTRF chrx 195333 extol nonSDTRF chry 23785 extol SDTRF full 1162687 extol SDTRF chrx 35326 extol SDTRF chry 4724 fusil nonSDTRF full 357541 fusil nonSDTRF chrx 0 fusil nonSDTRF chry 0 fusil SDTRF full 12170 fusil SDTRF chrx 0 fusil SDTRF chry 0 . Links to List of Gene Names with Alternate Names: Essential.alt.genes Exac.Intol.alt.genes Exac.Mid.alt.genes Exac.Tol.alt.genes FUSIL.alt.genes . Links to Geneset Burden Data for Quad Simplex: jointcoverage.Essential.txt jointcoverage.ExacInt.txt jointcoverage.ExacMid.txt jointcoverage.ExacTol.txt jointcoverage.FUSIL.txt . Links to Geneset Burden Data for Quad Multiplex: jointcoverage.Essential.txt jointcoverage.ExacInt.txt jointcoverage.ExacMid.txt jointcoverage.ExacTol.txt jointcoverage.FUSIL.txt . Links to Geneset Burden Data for Trio Simplex: jointcoverage.Essential.txt jointcoverage.ExacInt.txt jointcoverage.ExacMid.txt jointcoverage.ExacTol.txt jointcoverage.FUSIL.txt . ",
    "url": "/docs/to_be_sorted/2021-06-10-post-0021.html",
    "relUrl": "/docs/to_be_sorted/2021-06-10-post-0021.html"
  },"21": {
    "doc": "Single Cell TBR1 Cicero/Monocle3 with TSS > 2.7",
    "title": "Single Cell TBR1 Cicero/Monocle3 with TSS > 2.7",
    "content": "Directory: /home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index/third_pass_filt_TSS2p7/cicero Run: /home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index/third_pass_filt_TSS2p7/cicero/cicero.Rscript . The Cicero instruction was taken from the more specific Monocle3 guide and not the default guide here. Files generated: cicero.conns.txt - three column file with pairwise comparisons of two peaks and their connectivity score, -1 to 1 cicero.CCAN.txt - two column file with the peak name and its CCAN group membership cicero.pseudotimes.txt - cell and their pseudotime cicero.cicero.pseudotime_coeffs.txt - coefficients from fit of expression over time w/ header . Pseudotimes projected onto UMAP made within Cicero/Monocle3. FIGURE-1 . Pseudotimes projected onto UMAP we made. FIGURE-2 . Two well defined peaks significantly changing over pseudotime. FIGURE-3 . ",
    "url": "/docs/to_be_sorted/2021-06-10-post-0022.html",
    "relUrl": "/docs/to_be_sorted/2021-06-10-post-0022.html"
  },"22": {
    "doc": "SPARK Preliminary Pass 01, Filtering and Classifications",
    "title": "SPARK Preliminary Pass 01, Filtering and Classifications",
    "content": "This is the first pass through the data, getting it organized, and the framework for reiteration of these analyses setup. Here I am going through the loading and reorganizing of the data. This includes preliminary filtering, collapsing of certain rows, and reclassifying some specific names. This is just on the quad simplex files. Link to markdown: Preliminary Burden, part 1 . Notes per section: 2.6 - Load/Masterlist Subset - I should bring in the full master-table down instead of this subset eventually. 2.7 - Load/Coverage Denominators - Move this to a loadable file eventually. 3.1 - Filter and Subset/Variant Filter - Right now not filtering families, add those here. 3.2 - Filter and Subset/Duplicate Variant Entries - This describes and collapses the situations where multiple variants for the same family are occuring (usually due to transmission). There are 5 mosaic child calls that are borderline that we are dropping here which should be fine (the full numbers for these are printed out so you can see why they are at the border). There are also many instances where a variant is called in the child but found to be mosaic in the parent who does not have an original call. I am currently dropping these on the basis of the fact that no original variant call was made for these. 3.3 - Filter and Subset/Collapse Complex Events - Currently not marking or collapsing complex events. 3.4 - Filter and Subset/Variant Reclassification to Germline - Hard reclassification of any mosaic with AF_U90_CI_AC_MAIN &gt;= 0.4 as “MOSAIC_TO_GERMLINE”. Check AF plots before and after down the road. 3.5 - Filter and Subset/Function Reclassifications - The current categories are: nonsynonymous SNV, stopgain, stoploss, synonymous SNV, unknown. We may want to group these or add splicing information into these column. ",
    "url": "/docs/to_be_sorted/2021-06-22-post-0023.html",
    "relUrl": "/docs/to_be_sorted/2021-06-22-post-0023.html"
  },"23": {
    "doc": "SPARK Preliminary Pass 02, Loading for Coverage and SNV Count Plots",
    "title": "SPARK Preliminary Pass 02, Loading for Coverage and SNV Count Plots",
    "content": "This is the first pass through the data, getting it organized, and the framework for reiteration of these analyses setup. Here I am plotting preliminary coverage figures and getting SNV counts by grouping. Counting and pasting coverages per family should probably be done outside of R to actually work quickly. This is just on the quad simplex files. Link to markdown: Preliminary Burden, part 2 . Notes per section: 4.1 - Generate Count Tables/Count Table Creation for All Variants - This takes too long in R. Just count them up outside of R. 5.2/5.3 - Plot/Decile Plot, All Deciles - Just choose one of percent bases or # bases going forward, doens’t matter. There’s not a dramatic tail at the bottom fifthtile but its reasonably lower than everything to just drop. Splitting out by FA, MO, PRO, and SIB shows they’re all the same. 5.9/5.10 - Plot/Plot SNV Counts, Mosaic Child, Boxplots using # SNVs and # SNVs / EXOME COVERAGE - The boxplots don’t work that well since most of the families have 0 counts in the discrete categories. These would probably be better as histograms. I wanted to plot out just the raw number of counts to see if there were outlying families with too many calls. There are a few and the ones I spot checked also have low exome coverage. Plot # of calls by Exome Coverage really quick. ",
    "url": "/docs/to_be_sorted/2021-06-22-post-0024.html",
    "relUrl": "/docs/to_be_sorted/2021-06-22-post-0024.html"
  },"24": {
    "doc": "SPARK Preliminary Pass 02b, Coverage and SNV Count Plots as Hists",
    "title": "SPARK Preliminary Pass 02b, Coverage and SNV Count Plots as Hists",
    "content": "This is the first pass through the data, getting it organized, and the framework for reiteration of these analyses setup. Here I am plotting preliminary coverage figures and getting SNV counts by grouping. This is just on the quad simplex files. This is similar to the previous post but with histograms instead of boxplots for SNV counting with and without families with 0 counts removed from the plots. These were the filter Deidre used at one point to identify outlying families that are in the ballpark of the counts we have. mosaic_c 45x 5%, adjusted &gt;=10 calls mosaic_nontrans 45x 5%, adjusted &gt;=12 calls germline_c 45x 5%, adjusted &gt;=12 calls mosaic_trans 45x 5%, adjusted &gt;= 6 calls . Link to markdown: Preliminary Burden, part 2b . Notes per section: 4.4 - Plot / Mosaic Child - There is a single Proband from a family with 12 counts which is a clear outlier with every other family having less than 5 counts. 4.7 - Plot / Germline Child - There is a single Sibling from a family with 8 counts where every other family has 5 or less. 4.10 - Plot / Mosaic Parental Non-Trans - There are two Mothers from families with 8 and 9 counts with every other family having 5 or less. 4.13 - Plot / Mosaic Parental Trans - There are no families with higher than 5 counts. ",
    "url": "/docs/to_be_sorted/2021-06-26-post-0025.html",
    "relUrl": "/docs/to_be_sorted/2021-06-26-post-0025.html"
  },"25": {
    "doc": "SPARK Preliminary Pass 03, Allele Fraction Histograms",
    "title": "SPARK Preliminary Pass 03, Allele Fraction Histograms",
    "content": "This is the first pass through the data, getting it organized, and the framework for reiteration of these analyses setup. Here I am plotting out the fraction of allele frequencies we seeing across the different variant fractions and by person. This is just on the quad simplex files. Link to markdown: Preliminary Allele Fractions, part 3 . Notes per section: 4 - Plots of All AF Densities - These look in line with what we expect. 5.2, 6.2, 7.2, 8.2 - Plots Relative to Old, Original Data - All of this newer data is slightly right-shifted relative to the older data. This is due to the older data having more depth and more capable of getting smaller AF’s and is expected. 5.3, 6.3, 7.3, 8.3 - Plots with and without Filters - The filters are pretty conservative but are taking out a large number of calls aggressively on the lower-end. The numbers of calls being thrown out from these filters are large but expected (mainly just getting rid of calls with fewer than 5 alt reads). 9 - Plots with and without Transmission Filters - This also shows how dramatic the PSAME and higher PHET threshold are for removing false parental transmission calls. The higher PHET threshold does seem to eliminate more calls on the higher end of AF. ",
    "url": "/docs/to_be_sorted/2021-06-28-post-0026.html",
    "relUrl": "/docs/to_be_sorted/2021-06-28-post-0026.html"
  },"26": {
    "doc": "SPARK Preliminary Pass 04, Coverages and SNV Counts with Joint Family Coverages",
    "title": "SPARK Preliminary Pass 04, Coverages and SNV Counts with Joint Family Coverages",
    "content": "This is a second pass through the data. This is a redo of parts 1, 2, and 2b with coverages coming from joint coverages (entire family, parents, and children). This is just on the quad simplex files. The first markdown includes how the data was loaded, filtered, and subset and has no plots. The second markdown contains the plots. Link to markdown: Loading and Organizing, part 4a Plots of Coverages and SNV Counts, part 4b . Notes per section from 4b: 4.5 - Decile Plots of Joint Coverage by Family - There is a bit more of a tail than by individual. 4.6/4.7 - Decile Plots of Joint Parent/Child Coverage by Family - The tails are more observable in these. 5.2 - Plot Genomic Coverage, Autosomal - Here is the comparison of joint coverage distributions alongside individual coverages. Joint coverage takes families into the 25-50% range whereas individuals are in the 50-75% range. 6.2 and 6.3 - Plot SNV Counts, Mosaic Child - There is the single outlier proband with 9 counts. 7.2 and 7.3 - Plot SNV Counts, Germline Child - There is a slight outlier sibling but it doesn’t show up as much in the adjusted plots in 7.3. 8.2 and 8.3 - Plot SNV Counts, Mosaic Parental Non-Trans - There is a bit of a tail in the maternal calls with few outliers that are still high even in the adjusted plots. 9.2 and 9.3 - Plot SNV Counts, Mosaic Parental Trans - All the counts seem relatively low with no outliers but the members with 2 counts do also have lower coverage and they remain high in the adjusted plots. ",
    "url": "/docs/to_be_sorted/2021-07-06-post-0027.html",
    "relUrl": "/docs/to_be_sorted/2021-07-06-post-0027.html"
  },"27": {
    "doc": "Single Cell TBR1 ChromVAR with TSS > 2.7",
    "title": "Single Cell TBR1 ChromVAR with TSS > 2.7",
    "content": "Dir: /home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index/third_pass_filt_TSS2p7/chromvar Run: /home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index/third_pass_filt_TSS2p7/chromvar/chromvar.Rscript . ChromVAR was run with R v4.0.0 using the JASPAR 2020 motif database for mm10. This was performed on the data filtered at the TSS 2.7 threshold. Here are the variabilities plotted in order where the motifs NEUROD1 and NEUROG2 show considerably greater variation: Variability Figure . Here is the UMAP with the deviation scores of NEUROD1 overlaid: NEUROD1 Deviations UMAP . Here is another high variability motif, LHX9, that is found with a somewhat opposite distribution across the cells: LHX9 Deviations UMAP . ",
    "url": "/docs/to_be_sorted/2021-07-09-post-0028.html",
    "relUrl": "/docs/to_be_sorted/2021-07-09-post-0028.html"
  },"28": {
    "doc": "Single Cell TBR1 ChromVAR with TSS > 1.5",
    "title": "Single Cell TBR1 ChromVAR with TSS > 1.5",
    "content": "Dir: /home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index/chromvar Run: /home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index/chromvar/chromvar.Rscript . ChromVAR was run with R v4.0.0 using the JASPAR 2020 motif database for mm10. This was performed on the data filtered at the TSS 1.5 threshold. Here are the variabilities plotted in order where the motifs are slightly different from the 1.5 thresholded version: Variability FIgure . Motifs like NEUROD1 (Deviations UMAP) and LHX9 (Deviations UMAP) remain top hits with similar distributions as the 2.7 versions. We get enrichment of KLF9 (Deviations UMAP) motifs as well but it follows a similar distribution of motifs like CTCF (Deviations UMAP). These show enrichment in the high TSS enriched cells relative to low TSS enriched cells so I’m not convinced these are representative of anything interesting. We would really want to find a motif with the opposite distribution (high enrichment for a motif in the low TSS cells and low motif enrichment in the high TSS cells) to say those lower TSS cells had something worthwhile. ",
    "url": "/docs/to_be_sorted/2021-07-12-post-0029.html",
    "relUrl": "/docs/to_be_sorted/2021-07-12-post-0029.html"
  },"29": {
    "doc": "SPARK Preliminary Pass 5, Final Filtering",
    "title": "SPARK Preliminary Pass 5, Final Filtering",
    "content": "This is a final pass through the data for the purposes of filtering, collapsing, and relabeling for the quad simplex files. Here are the thresholds used to filter each category for the quad simplex calls. mosaic_c 45x 5%, adjusted &gt;=10 calls germline_c 45x 5%, adjusted &gt;=12 calls mosaic_nontrans 45x 5%, adjusted &gt;=14 calls mosaic_trans 45x 5%, adjusted &gt;= 6 calls . This eliminates the following four families: SF0087337, SF0035804, SF0054730, SF0081797. Complex events were addressed by hand. Events occuring in the same codon were run with their combined alternative genotype in VEP. Rows in the table were chosen by the following criteria: . IF variants are multi-allelic: * choose variant with more severe effect (NSS &gt; MIS &gt; TRANSVERSION_SYN &gt; TRANSITION_SYN) IF variants potentially in the same codon (w/in 3bp): * keep variant with left-most coordinate * combine genotype * update functional annotation to reflect VEP annotation run on the combined effect IF variants are nearby in different codons (w/in 100bp): * choose variant with more severe effect (NSS &gt; MIS &gt; SYN) * if same effect, keep nearest to a splice junction * if same splice junction distance, keep left-most . Link to markdown: Filtering and Collapsing Quad Simplex Calls, part 5 . ",
    "url": "/docs/to_be_sorted/2021-07-14-post-0030.html",
    "relUrl": "/docs/to_be_sorted/2021-07-14-post-0030.html"
  },"30": {
    "doc": "SPARK Preliminary Pass 6a and 6b, Simplex Trio Coverages, SNV Counts, and AFs",
    "title": "SPARK Preliminary Pass 6a and 6b, Simplex Trio Coverages, SNV Counts, and AFs",
    "content": "This is a first pass through the data for the simplex trio families for the purposes of outlier detection. Link to markdown: Preliminary Outlier Analysis for Trio Simplex Calls, part 6a Preliminary Outlier Analysis for Trio Simplex Calls, part 6b . Notes per section from 6b: 4.2 - Decile Plot for Joint Coverage Families - Appears similarly to simplex quads. There isn’t a tail. No filtering recommended again. 5.2 - Plot Genomic Coverage, Autosomal - Also similarily expected. To note, joint family coverages here for trios are going to be larger than simplex quad family coverages since there are fewer family members. 5.8 - Plot SNV Counts Jitter, Mosaic Child - There’s a single, clear outlier that would get filtered out with the same simplex quad threshold of &gt;= 10. 6.3 - Plot SNV Counts Jitter, Germline Child - No outliers. Nothing would be removed with the same simplex quad threshold of &gt;= 12. 7.3 - Plot SNV Counts Jitter, Mosaic Parental Non-Trans - There are a few clear outliers and a few ambiguous cases like in the simplex quads. 2 families are clear outliers and 5 are near the threshold but still fall above the simplex quad threshold of &gt;= 14. 8.3 - Plot SNV Counts Jitter, Mosaic Parental Trans - No outliers. Nothing would be removed with the same simplex quad threshold of &gt;= 6. 11.1 - Plot All Allele Fraction Densities - Looks as expected. The remainder of AF plots also look as expected and in line with the simplex quads. ",
    "url": "/docs/to_be_sorted/2021-07-17-post-0031.html",
    "relUrl": "/docs/to_be_sorted/2021-07-17-post-0031.html"
  },"31": {
    "doc": "SPARK Preliminary Pass 7a and 7b, Multiplex Quad Coverages, SNV Counts, and AFs",
    "title": "SPARK Preliminary Pass 7a and 7b, Multiplex Quad Coverages, SNV Counts, and AFs",
    "content": "This is a first pass through the data for the multiplex quad families for the purposes of outlier detection. Link to markdown: Preliminary Outlier Analysis for Quad Multiplex Calls, part 7a Preliminary Outlier Analysis for Quad Multiplex Calls, part 7b . Notes per section from 7b: 4.2 - Decile Plot for Joint Coverage Families - There are two outliers in the tail of the 5% fifthtile below 20% of the genome. These are the lowest representative families across all the data including simplex trios and quads. 4.5 - Decile Plot for Joint Coverage Families, Deciles 0-20% - Zoomed in from above to see the outliers better. 6.3 - Plot SNV Counts Jitter, Mosaic Child - There are a few families near the higher end, but still all below the threshold of &gt;= 10. The max counts is still only a value of 3 counts in a single family. 7.3 - Plot SNV Counts Jitter, Germline Child - There are four extreme outliers that should be removed and are well above our threshold of &gt;= 12. 7.4 - Plot SNV Counts Jitter, Germline Child Zoomed - There is still one more family just above our threshold of &gt;= 12 when we zoom in and ignore the extreme outliers. 8.3 - Plot SNV Counts Jitter, Mosaic Parental Non-Trans - There are two families just above the threshold of &gt;= 14. 9.3 - Plot SNV Counts Jitter, Mosaic Parental Trans - No outliers, the max raw count is 2. There is a family near the threshold of &gt;= 6 but it is just below and still only have 2 raw counts. 12.3 - Allele Fraction Densities, Mosaic Child - There is a bit of a bump in the AF distributions for mosaic sibling calls. This may go away with the above filtering of families but also is likely just due to the low number of calls. ",
    "url": "/docs/to_be_sorted/2021-07-17-post-0032.html",
    "relUrl": "/docs/to_be_sorted/2021-07-17-post-0032.html"
  },"32": {
    "doc": "Single Cell TBR1 BioCluster/Genotype/Line/Time DA with TSS > 2.7",
    "title": "Single Cell TBR1 BioCluster/Genotype/Line/Time DA with TSS > 2.7",
    "content": "Dir: /home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index/third_pass_filt_TSS2p7/DA Run: /home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index/third_pass_filt_TSS2p7/DA/run.txt . The DA information of where and what was run is left here for posterity. None of the comparisons yielded significant results using the raw p-value. The DA was performed after TF normalization using the Wilcoxon rank sum test. The following tests were performed: . # comparing genotypes within bioclusters excit_het vs excit_hom vs excit_wt inhibit_het vs inhibit_hom vs inhibit_wt prog_het vs prog_hom vs prog_wt # comparing lines within bioclusters excit_a136pft vs excit_tbr1ko inhibit_a136pft vs inhibit_tbr1ko prog_a136pft vs prog_tbr1ko # comparing progression from prog to excitatory progenitor_E12.5_a136pfs_het vs excitatory_E16.5_a136pfs_het progenitor_E12.5_a136pfs_hom vs excitatory_E16.5_a136pfs_hom progenitor_E12.5_a136pfs_wt vs excitatory_E16.5_a136pfs_wt progenitor_E12.5_tbr1_ko_het vs excitatory_E16.5_tbr1_ko_het progenitor_E12.5_tbr1_ko_hom vs excitatory_E16.5_tbr1_ko_hom progenitor_E12.5_tbr1_ko_wt vs excitatory_E16.5_tbr1_ko_wt . Here is a complete breakdown of cell numbers: . 177 excitatory_E12.5_a136pfs_het 42 excitatory_E12.5_a136pfs_hom 16 excitatory_E12.5_a136pfs_wt 31 excitatory_E12.5_tbr1_ko_het 9 excitatory_E12.5_tbr1_ko_hom 26 excitatory_E12.5_tbr1_ko_wt 1044 excitatory_E16.5_a136pfs_het 962 excitatory_E16.5_a136pfs_hom 902 excitatory_E16.5_a136pfs_wt 655 excitatory_E16.5_tbr1_ko_het 183 excitatory_E16.5_tbr1_ko_hom 354 excitatory_E16.5_tbr1_ko_wt 30 inhibitory_E12.5_a136pfs_het 31 inhibitory_E12.5_a136pfs_hom 11 inhibitory_E12.5_a136pfs_wt 4 inhibitory_E12.5_tbr1_ko_het 8 inhibitory_E12.5_tbr1_ko_hom 6 inhibitory_E12.5_tbr1_ko_wt 19 inhibitory_E16.5_a136pfs_het 21 inhibitory_E16.5_a136pfs_hom 37 inhibitory_E16.5_a136pfs_wt 15 inhibitory_E16.5_tbr1_ko_het 5 inhibitory_E16.5_tbr1_ko_hom 10 inhibitory_E16.5_tbr1_ko_wt 649 progenitor_E12.5_a136pfs_het 205 progenitor_E12.5_a136pfs_hom 117 progenitor_E12.5_a136pfs_wt 177 progenitor_E12.5_tbr1_ko_het 70 progenitor_E12.5_tbr1_ko_hom 102 progenitor_E12.5_tbr1_ko_wt 232 progenitor_E16.5_a136pfs_het 271 progenitor_E16.5_a136pfs_hom 365 progenitor_E16.5_a136pfs_wt 148 progenitor_E16.5_tbr1_ko_het 52 progenitor_E16.5_tbr1_ko_hom 115 progenitor_E16.5_tbr1_ko_wt 155 undetermined_E12.5_a136pfs_het 222 undetermined_E12.5_a136pfs_hom 138 undetermined_E12.5_a136pfs_wt 60 undetermined_E12.5_tbr1_ko_het 77 undetermined_E12.5_tbr1_ko_hom 40 undetermined_E12.5_tbr1_ko_wt 482 undetermined_E16.5_a136pfs_het 514 undetermined_E16.5_a136pfs_hom 467 undetermined_E16.5_a136pfs_wt 162 undetermined_E16.5_tbr1_ko_het 192 undetermined_E16.5_tbr1_ko_hom 293 undetermined_E16.5_tbr1_ko_wt . ",
    "url": "/docs/to_be_sorted/2021-07-18-post-0033.html",
    "relUrl": "/docs/to_be_sorted/2021-07-18-post-0033.html"
  },"33": {
    "doc": "Single Cell TBR1 Misc Figures - ChromVAR Compare, FDR Hists, 3D",
    "title": "Single Cell TBR1 Misc Figures - ChromVAR Compare, FDR Hists, 3D",
    "content": "Dir: /home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index/third_pass_filt_TSS2p7 Run: run_3D_plot.txt . Here are some of the UMAPs and how they were plot in 3d. They look as expected, similar to the 2D versions. The Bio Cluster one might indicate that one of the pg’s labeled as excitatory should be better labeled as undetermined. UMAP in 3D w/ TSS Enrichment UMAP in 3D w/ Pseudotime UMAP in 3D w/ Bio Cluster UMAP in 3D w/ Treatment . This markdown contains two parts for various figures. The first part shows the DA results from comparing pg 1 and pg 12 in the data filtered at TSS &gt; 1.5. The second part contains a comparison of the results from running ChromVAR on the two TSS &gt; 1.5 and 2.7 datasets. Link to Markdown: DA P-val/FDR Distributions and ChromVAR Comparisons . Markdown Notes: 1.2 - Plot PVALS - These are terribly skewed suggesting the test itself is not a good choice. 1.3 - Plot FDRS - These end up all as 1 due to the issue above. 2.3 - Plot Variability, Spearman - The overall variabilities are well correlated with a few outliers from the KLF family. 2.4 - Show KLF9 and CTCF Score Correlations - The deviation scores from ChromVAR run on the TSS &gt; 1.5 dataset are compared for KLF9 and CTCF. KLF9 is a variable motif under the 1.5 dataset but not the 2.7 dataset. It has a similar pattern and distribution to CTCF but this show the scores aren’t well correlated suggesting it isn’t simply an indication of quality like CTCF usually indicates. ",
    "url": "/docs/to_be_sorted/2021-07-19-post-0034.html",
    "relUrl": "/docs/to_be_sorted/2021-07-19-post-0034.html"
  },"34": {
    "doc": "Single Cell TBR1 BioCluster/Genotype/Line/Time DA with TSS > 2.7, Filtering Ambiguous Groups",
    "title": "Single Cell TBR1 BioCluster/Genotype/Line/Time DA with TSS > 2.7, Filtering Ambiguous Groups",
    "content": "Here’s the DA performed with removing the phenograph clusters 8 and 9 which are ambiguously between excitatory neurons and unidentified, low-TSS areas on the 3D UMAP. Dir: /home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index/third_pass_filt_TSS2p7/DA_v2_removeLowTSSFromDA Run: /home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index/third_pass_filt_TSS2p7/DA_v2_removeLowTSSFromDA/run.txt . Here’s the DA performed using the same groups but using the novel peaks called with macs3 on the data. Dir: /home/groups/oroaklab/nishida/sc_tmp1/novel_peaks/DA Run: /home/groups/oroaklab/nishida/sc_tmp1/novel_peaks/DA/run.txt . The DA was performed after TF normalization using the Wilcoxon rank sum test. The following tests were performed: . # comparing genotypes within bioclusters excit_het vs excit_hom vs excit_wt inhibit_het vs inhibit_hom vs inhibit_wt prog_het vs prog_hom vs prog_wt # comparing lines within bioclusters excit_a136pft vs excit_tbr1ko inhibit_a136pft vs inhibit_tbr1ko prog_a136pft vs prog_tbr1ko # comparing progression from prog to excitatory progenitor_E12.5_a136pfs_het vs excitatory_E16.5_a136pfs_het progenitor_E12.5_a136pfs_hom vs excitatory_E16.5_a136pfs_hom progenitor_E12.5_a136pfs_wt vs excitatory_E16.5_a136pfs_wt progenitor_E12.5_tbr1_ko_het vs excitatory_E16.5_tbr1_ko_het progenitor_E12.5_tbr1_ko_hom vs excitatory_E16.5_tbr1_ko_hom progenitor_E12.5_tbr1_ko_wt vs excitatory_E16.5_tbr1_ko_wt . Here is a complete breakdown of cell numbers with the: . 154 excitatory_E12.5_a136pfs_het 29 excitatory_E12.5_a136pfs_hom 11 excitatory_E12.5_a136pfs_wt 23 excitatory_E12.5_tbr1_ko_het 4 excitatory_E12.5_tbr1_ko_hom 22 excitatory_E12.5_tbr1_ko_wt 722 excitatory_E16.5_a136pfs_het 655 excitatory_E16.5_a136pfs_hom 674 excitatory_E16.5_a136pfs_wt 519 excitatory_E16.5_tbr1_ko_het 82 excitatory_E16.5_tbr1_ko_hom 208 excitatory_E16.5_tbr1_ko_wt 30 inhibitory_E12.5_a136pfs_het 31 inhibitory_E12.5_a136pfs_hom 11 inhibitory_E12.5_a136pfs_wt 4 inhibitory_E12.5_tbr1_ko_het 8 inhibitory_E12.5_tbr1_ko_hom 6 inhibitory_E12.5_tbr1_ko_wt 19 inhibitory_E16.5_a136pfs_het 21 inhibitory_E16.5_a136pfs_hom 37 inhibitory_E16.5_a136pfs_wt 15 inhibitory_E16.5_tbr1_ko_het 5 inhibitory_E16.5_tbr1_ko_hom 10 inhibitory_E16.5_tbr1_ko_wt 649 progenitor_E12.5_a136pfs_het 205 progenitor_E12.5_a136pfs_hom 117 progenitor_E12.5_a136pfs_wt 177 progenitor_E12.5_tbr1_ko_het 70 progenitor_E12.5_tbr1_ko_hom 102 progenitor_E12.5_tbr1_ko_wt 232 progenitor_E16.5_a136pfs_het 271 progenitor_E16.5_a136pfs_hom 365 progenitor_E16.5_a136pfs_wt 148 progenitor_E16.5_tbr1_ko_het 52 progenitor_E16.5_tbr1_ko_hom 115 progenitor_E16.5_tbr1_ko_wt 178 undetermined_E12.5_a136pfs_het 235 undetermined_E12.5_a136pfs_hom 143 undetermined_E12.5_a136pfs_wt 68 undetermined_E12.5_tbr1_ko_het 82 undetermined_E12.5_tbr1_ko_hom 44 undetermined_E12.5_tbr1_ko_wt 804 undetermined_E16.5_a136pfs_het 821 undetermined_E16.5_a136pfs_hom 695 undetermined_E16.5_a136pfs_wt 298 undetermined_E16.5_tbr1_ko_het 293 undetermined_E16.5_tbr1_ko_hom 439 undetermined_E16.5_tbr1_ko_wt . ",
    "url": "/docs/to_be_sorted/2021-07-26-post-0035.html",
    "relUrl": "/docs/to_be_sorted/2021-07-26-post-0035.html"
  },"35": {
    "doc": "SPARK First Pass, Synonymous SNV Splice Distances",
    "title": "SPARK First Pass, Synonymous SNV Splice Distances",
    "content": "This replicates Figure 5 from original paper using the now defunct final simplex quad list looking at synonymous SNVs and their distances from splice sites. Link to Markdown: Simplex Quad Synonymous SNV Splice Distances . Markdown Notes: 3.2 - Plot Densities, Match Fig 5 - The splice distances here show the opposite of what was observed before, they are further from splice sites. They are nonetheless different in distribution. ",
    "url": "/docs/to_be_sorted/2021-07-26-post-0036.html",
    "relUrl": "/docs/to_be_sorted/2021-07-26-post-0036.html"
  },"36": {
    "doc": "SPARK Preliminary Outlier Detection, Secondary Pass",
    "title": "SPARK Preliminary Outlier Detection, Secondary Pass",
    "content": "Figure showing the thresholds used before and currently with representative figures from all lists together. Outliers and Thresholds Side by Side . Link to Markdowns: Outlier Detection Prep, Simplex Quads Outlier Detection Figures, Simplex Quads Outlier Detection Prep, Simplex Trios Outlier Detection Figures, Simplex Trios Outlier Detection Prep, Multiplex Quads Outlier Detection Figures, Multiplex Quads . ",
    "url": "/docs/to_be_sorted/2021-07-26-post-0037.html",
    "relUrl": "/docs/to_be_sorted/2021-07-26-post-0037.html"
  },"37": {
    "doc": "SPARK Final Table Creation",
    "title": "SPARK Final Table Creation",
    "content": "This describes the full extent of outlier detection and final filtering of all three lists. Representative figure showing outliers and thresholds used: Final Outlier Detection Figures and Thresholds . Link to Markdowns: 01_QS, Organizing and Prefiltering 01_TS, Organizing and Prefiltering 01_QM, Organizing and Prefiltering 02_QS, Outlier Detection 02_TS, Outlier Detection 02_QM, Outlier Detection 03_QS, Final Table 03_TS, Final Table 03_QM, Final Table . ",
    "url": "/docs/to_be_sorted/2021-07-26-post-0038.html",
    "relUrl": "/docs/to_be_sorted/2021-07-26-post-0038.html"
  },"38": {
    "doc": "SPARK Mosaic Index, July 27",
    "title": "SPARK Mosaic Index, July 27",
    "content": "Compiled Writing and Figures: Google Doc Figures 1, Filtering Figures 2, HC List Metrics Figures 3, Burden . Final Mosaic Lists (July 27th): Simplex Quads, for Burden Analysis Simplex Quads, High Confidence Calls Simplex Trios, for Burden Analysis Simplex Trios, High Confidence Calls Multiplex Quads, for Burden Analysis Multiplex Quads, High Confidence Calls SSC List in SPARK List Format . Markdowns: 01_QS, Organizing and Prefiltering 01_TS, Organizing and Prefiltering 01_QM, Organizing and Prefiltering 02_QS, Outlier Detection 02_TS, Outlier Detection 02_QM, Outlier Detection 03_QS, Final Table 03_TS, Final Table 03_QM, Final Table 04, High Confidence Simplex Quad Allele Frequencies 05 High Confidence Simplex Quad Splice Distances 05 High Confidence All Lists Splice Distances 06 Burden Tables Autosomal 07_01 Burden Gene Sets 07_02 Burden Gene Sets 07_03 Burden Gene Sets 07_04 Burden Gene Sets 08 Concatenate High Confidence Lists 09 Generation of LGD and NS Lists 10 Summarize Final Lists 11 High Confidence AF Dists, QS 11 High Confidence AF Dists, QS and TS 11 High Confidence AF Dists, QS, TS, and QM 12 Burden Genesets, QS and missense 12 Burden Genesets, QS and synonymous 12 Burden Genesets, QS and nonsense-splicing 12 Burden Genesets, QS and TS and missense 12 Burden Genesets, QS and TS and synonymous 12 Burden Genesets, QS and TS and nonsense-splicing 13 Burden REVEL, QS and missense 13 Burden REVEL, QS+TS and missense 14 Parental Transmission Breakdown 15 SPARK 167 Intersection 16 Concat Variant Lists to DNV List 17 SSC List Formatting to Current SPARK 19 SSC Solo Burden Markdown 01 WES2_SQ Prep 01 WES2_MQ Prep 01 WES2_ST Prep 01 WES3_SQ Prep 01 WES3_MQ Prep 01 WES3_ST Prep 02 WES2_SQ Outlier Plots 02 WES2_MQ Outlier Plots 02 WES2_ST Outlier Plots 02 WES3_SQ Outlier Plots 02 WES3_MQ Outlier Plots 02 WES3_ST Outlier Plots WES2 and WES3 Combined Coverage Plots . Family Lists: Final Sample List Final filter list by IGV shots and concatenated cohort count LGD List NS List SSC Family and LGD/NS List . Mosaic Lists, Full Non-Analysis Sets (March 30th, 2022): Simplex Quads w/ Loose Filter Multiplex Quads w/ Loose Filter Simplex Trios w/ Loose Filter Simplex Quads w/ Strict Test Filter Multiplex Quads w/ Strict Test Filter Simplex Trios w/ Strict Test Filter Simplex Quads w/ Strict Test Filter, no Germline Parental Multiplex Quads w/ Strict Test Filter, no Germline Parental Simplex Trios w/ Strict Test Filter, no Germline Parental WES2, Simplex Quads w/ Loose Filter WES2, Multiplex Quads w/ Loose Filter WES2, Simplex Trios w/ Loose Filter WES2, Simplex Quads w/ Strict Test Filter WES2, Multiplex Quads w/ Strict Test Filter WES2, Simplex Trios w/ Strict Test Filter WES2, Simplex Quads w/ Strict Test Filter, no Germline Parental WES2, Multiplex Quads w/ Strict Test Filter, no Germline Parental WES2, Simplex Trios w/ Strict Test Filter, no Germline Parental WES3, Simplex Quads w/ Loose Filter WES3, Multiplex Quads w/ Loose Filter WES3, Simplex Trios w/ Loose Filter WES3, Simplex Quads w/ Strict Test Filter WES3, Multiplex Quads w/ Strict Test Filter WES3, Simplex Trios w/ Strict Test Filter WES3, Simplex Quads w/ Strict Test Filter, no Germline Parental WES3, Multiplex Quads w/ Strict Test Filter, no Germline Parental WES3, Simplex Trios w/ Strict Test Filter, no Germline Parental . SPARK Annotations Used, 20190820: Simplex Quad, Added Annotations Multiplex Quad, Added Annotations Simplex Trio, Added Annotations SPARK Annotations . Links to List of Gene Names with Alternate Names: SPARK list from https://sparkforautism.org/portal/page/spark-gene-list/ Essential.alt.genes Exac.Intol.alt.genes Exac.Mid.alt.genes Exac.Tol.alt.genes FUSIL.alt.genes . Supplemental Annotations: Supplemental Annotations, REVEL, trio simplex Supplemental Annotations, REVEL, quad simplex Supplemental Annotations, REVEL, quad simplex HC list Variants Intersecting w/ SPARK 167, Mosaic Child only HC list Variants Intersecting w/ SPARK 167 . Joint Coverage: Genomic Joint Coverage, SSC Joint Coverage Genomic Joint Coverage, WES1 Simplex Quads Genomic Joint Coverage, WES1 Multiplex Quads Genomic Joint Coverage, WES1 Simplex Trios Genomic Joint Coverage, WES2 Simplex Quads Genomic Joint Coverage, WES2 Multiplex Quads Genomic Joint Coverage, WES2 Simplex Trios Genomic Joint Coverage, WES3 Simplex Quads Genomic Joint Coverage, WES3 Multiplex Quads Genomic Joint Coverage, WES3 Simplex Trios . IGV Shots: IGV Shots of High Confidence Sites . Here are descriptions of all the columns in the table: 1/CHR, 2/START, 3/STOP, 4/REF, 5/ALT - general variant information 6/FAMILY, 7/SAMPLE, 8/FRACTION - SF family ID, SP sample ID, putative mosaic annotation 9/DP_MAIN, 10/DPALT_MAIN, 11/AF_MAIN - the depth of reads, depth of alt reads, and AF for the main person of the family 12/LOFREQ_STATS_NAMES, 13/LOFREQ_STATS, 14/MPUP_STATS_NAMES, 15/MPUP_STATS, 16/VARSCAN_STATS_NAMES, 17/VARSCAN_STATS - stats from the three variant callers with their descriptor fields 18/MISMATCH_REF_READS, 19/MISMATCH_ALT_READS, 20/MISMATCH_OTHER_READS, 21/MISMATCH_SPAN_DELS, 22/MISMATCH_MAPQ_REF_MEAN, 23/MISMATCH_MAPQ_ALT_MEAN, 24/MISMATCH_MAPQ_OTHER_MEAN, 25/MISMATCH_MAPQ_REF_MEDIAN, 26/MISMATCH_MAPQ_ALT_MEDIAN, 27/MISMATCH_MAPQ_OTHER_MEDIAN, 28/MISMATCH_MAPQ_REF_MODE, 29/MISMATCH_MAPQ_ALT_MODE, 30/MISMATCH_MAPQ_OTHER_MODE, 31/MISMATCH_XM_REF_MEAN, 32/MISMATCH_XM_ALT_MEAN, 33/MISMATCH_XM_OTHER_MEAN, 34/MISMATCH_XM_REF_MEDIAN, 35/MISMATCH_XM_ALT_MEDIAN, 36/MISMATCH_XM_OTHER_MEDIAN, 37/MISMATCH_XM_REF_MODE, 38/MISMATCH_XM_ALT_MODE, 39/MISMATCH_XM_OTHER_MODE - large collection of stats concerning mismatches across the region, only MISMATCH_XM_ALT_MEDIAN gets used downstream for another derived column 40/DP_FA, 41/DP_MO, 42/DP_PRO, 43/DP_SIB, 44/DPALT_FA, 45/DPALT_MO, 46/DPALT_PRO, 47/DPALT_SIB - depths across all family members 48/AF_EXAC, 49/AF_gnomAD - AFs from ExAC v0.3 and gnomAD 2.1 50/ERROR_VAR, 51/ERROR_ALL, 52/ERROR_VARMAX, 53/ERROR_RATE - error in the region calculated over a random subset of 1000 samples, only rate gets used downstream for another derived column 54/NUM_FAMILY_FOUND - number of families the variant is found before filtering 55/PHET_FA, 56/PHET_MO, 57/PHET_PRO, 58/PHET_SIB - pvalue of exact test given the depth and the depth of the alt read in each family member testing if it is less than 0.5 (heterogeneous) 59/PERSON - identity of the person 60/DPALT_BIN - binary column derived from DPALT_MAIN used for SCORE_400_RB3 61/ERROR_BIN_3 - categorical column (low, medium, high) derived from ERROR_RATE used for SCORE_400_RB3 62/AF_BIN_3 - categorical column (low, medium, high) derived from AF_MAIN used for SCORE_400_RB3 63/REF_CG - categorical column (C or G) derived from REF used for SCORE_400_RB3 64/XM_ALT_1 - binary column derived from MISMATCH_XM_ALT_MEDIAN used for SCORE_400_RB3 65/SCORE_400_RB3 - score from logistic regression model that takes into account many of the other columns 66/genomicSuperDupes, 67/rmsk, 68/simpleRepeat, 69/mutationType, 70/exonicAnnotation, 71/variantFunctionType, 72/variantFunctionGene - annotations with annovar-2018-06-15 73/filteredCohortCount - number of families the variant is found after preliminary filtering 74/AF_L90CI_AC_MAIN, 75/AF_U90CI_AC_MAIN - upper and lower 90% confidence intervals via Agresti-Coull method 76/FRACTION_ORIGINAL - old, erroneous annotations of the site for posterity, see May 9 update 77/FRACTION_MORE - a subset of column 8, FRACTION, with further granularity, see June 3 update 78/PSAME_FAxPRO, 79/PSAME_FAxSIB, 80/PSAME_MOxPRO, 81/PSAME_MOxSIB - Fisher’s exact test comparing depths and alt reads from parents versus children for the purposes of testing a transmission event. Final tables also contain: 82/MIN_DP - The minimum depth of all family members. 83/ACC_DIST, 84/DON_DIST, 85/ACC_TRANSCRIPT, 86/DON_TRANSCRIPT - The distances in basepairs to an acceptor or donor site and which transcript from which this distance is derived. 87/COMPLEX_EVENT - All FALSE in final tables representing collapsed complex events. 88/HGNCsymbol_to_ENSID, 89/RefSeq_to_ENSID - ENSEMBL IDs derived from both HGNC symbosl and RefSeq . dbNSFP Column Descriptions: Added dbNSFP Annotation Column Descriptions . ",
    "url": "/docs/to_be_sorted/2021-07-27-post-0039.html",
    "relUrl": "/docs/to_be_sorted/2021-07-27-post-0039.html"
  },"39": {
    "doc": "Single Cell TBR1 Bigwig Tracks",
    "title": "Single Cell TBR1 Bigwig Tracks",
    "content": "Tracks are here and made via: Dir: /home/groups/oroaklab/nishida/sc_tmp1/tracks Run: /home/groups/oroaklab/nishida/sc_tmp1/tracks/run.txt . Example Regions: Example Shot of HES5 Example Shot of NEUROD6 Example Shot of HMGA2 . Tracks: Box Link to Tracks . ",
    "url": "/docs/to_be_sorted/2021-07-29-post-0040.html",
    "relUrl": "/docs/to_be_sorted/2021-07-29-post-0040.html"
  },"40": {
    "doc": "SPARK High Confidence Allele Frequencies 01",
    "title": "SPARK High Confidence Allele Frequencies 01",
    "content": "These are the allele frequency densities but drawn for the high confidence data set. They look as expected and like previous distributions. These are just more final since they use the final tables. Markdown: 04 High Confidence Simplex Quad Allele Frequencies . ",
    "url": "/docs/to_be_sorted/2021-08-03-post-0041.html",
    "relUrl": "/docs/to_be_sorted/2021-08-03-post-0041.html"
  },"41": {
    "doc": "SPARK High Confidence Synonymous Splice Distances 01",
    "title": "SPARK High Confidence Synonymous Splice Distances 01",
    "content": "This is the analysis of the synonymous SNV’s and their splice distances split by FRACTION group. The first uses just the simplex quad data and the second combines all three lists. These both contain comparable figures to Figure 5D from the Krupp paper. By the same Wilcoxon rank sum test, we do not find any significant differences in splice site distances either using just simplex quads or using all the variants. Markdown: 05 High Confidence Simplex Quad Splice Distances 05 High Confidence All Lists Splice Distances . ",
    "url": "/docs/to_be_sorted/2021-08-03-post-0042.html",
    "relUrl": "/docs/to_be_sorted/2021-08-03-post-0042.html"
  },"42": {
    "doc": "SPARK Burden Tables Autosomal 01",
    "title": "SPARK Burden Tables Autosomal 01",
    "content": "This is the burden analysis using just the simplex quad burden table. I included the 45x/15%, 50/12.5%, and 65/10% thresholds. We probably won’t use the 65/10% threshold but I thought it helped with just plotting the figures out for perspective for now. The same two-sided Wilcoxon rank sum test is performed and finds no evidence of burden. Markdown: 06 Burden Tables Autosomal . Notes per section: 6.3 - Print Table of Wilcoxon Rank Sums - These are the Wilcoxon rank sum test p-values. None of them are significant at 0.05. 6.5 - Barplot SNV Counts, Normalized Mosaic Child per Functions - This is meant to match Figure 2 from the Krupp paper. ",
    "url": "/docs/to_be_sorted/2021-08-03-post-0043.html",
    "relUrl": "/docs/to_be_sorted/2021-08-03-post-0043.html"
  },"43": {
    "doc": "SPARK Burden Tables Gene Sets 01",
    "title": "SPARK Burden Tables Gene Sets 01",
    "content": "This is the gene set burden analysis using just the simplex quad burden table. This breaks the variants into categories dependent on if they are Germline LGD or Germline NS and looks at the gene sets and areas under the lists for EXINTOL and ESSENTIAL. The same one-sided Wilcoxon rank sum test is performed and does not find evidence of burden in the subsets. Markdown: 07 Burden Gene Sets . Notes per section: 7.4 - Print Table of Wilcoxon Rank Sums for All Genes - These are the one-sided Wilcoxon rank sum test p-values. None of them are significant at 0.05. 7.6 - Plot for All Genes - These are the Wilcoxon rank sum test p-values. None of them are significant at 0.05. 8.4 - Print Table of Wilcoxon Rank Sums for Essential Genes - These are the one-sided Wilcoxon rank sum test p-values. None of them are significant at 0.05. 8.6 - Plot for Essential Genes - These are the Wilcoxon rank sum test p-values. None of them are significant at 0.05. 9.4 - Print Table of Wilcoxon Rank Sums for Intolerant Genes - These are the one-sided Wilcoxon rank sum test p-values. None of them are significant at 0.05. 9.6 - Plot for Intolerant Genes - These are the Wilcoxon rank sum test p-values. None of them are significant at 0.05. ",
    "url": "/docs/to_be_sorted/2021-08-09-post-0044.html",
    "relUrl": "/docs/to_be_sorted/2021-08-09-post-0044.html"
  },"44": {
    "doc": "Single Cell TBR1 Cistopic Boxplots and UMAPs",
    "title": "Single Cell TBR1 Cistopic Boxplots and UMAPs",
    "content": "This shows the cistopic topics projected onto the UMAP. And it contains boxplots of the pertinent cell subsets and their topic scores per subset. UMAPS are also located here: /home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index/third_pass_filt_TSS2p7/tbr1_ko_encodeDHSindex_finalfilter.filt.cistopic.30.UMAP.matrix_plots. Markdown: Markdown of Topic Boxplot for Groups Zip of 30 UMAPs, 1 per Topic . ",
    "url": "/docs/to_be_sorted/2021-08-12-post-0045.html",
    "relUrl": "/docs/to_be_sorted/2021-08-12-post-0045.html"
  },"45": {
    "doc": "Single Cell TBR1 ChIP-Seq Peak DA",
    "title": "Single Cell TBR1 ChIP-Seq Peak DA",
    "content": "Directory: /home/groups/oroaklab/nishida/sc_tmp1/chip_peaks/DA Run: /home/groups/oroaklab/nishida/sc_tmp1/chip_peaks/DA/run.txt . This takes the peaks called from a ChIP-seq study of TBR1 and does the same differential accessibility tests as before with these peaks. The DA was performed after TF normalization using the Wilcoxon rank sum test with the same groups and tests as here: link . Peaks are taken from ChIP-seq study here: . https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE71384 https://pubmed.ncbi.nlm.nih.gov/27325115/ . ",
    "url": "/docs/to_be_sorted/2021-08-12-post-0046.html",
    "relUrl": "/docs/to_be_sorted/2021-08-12-post-0046.html"
  },"46": {
    "doc": "SPARK IGV Shots of High Confident Calls",
    "title": "SPARK IGV Shots of High Confident Calls",
    "content": "Directory: /home/groups/oroaklab/nishida/spark_mosaic/IGV Run: /home/groups/oroaklab/nishida/spark_mosaic/IGV/run.txt . IGV shots were taken with version 2.10.3. The update to the version and subsequent change to the creation of sessions and batch scripts is due to the use of CRAMs. Shots were made of all sites in the high confident call for all three lists (simplex quad, simplex trio, multiplex quad). Tracks are always in the order of: FATHER, MOTHER, PROBAND, SIBLING. Multiplex shots with divergent labels for children are listed in alphabetically order. Simplex trio shots include four tracks. This last real track comes from a random simplex quad family which can function as an additional reference for looking at sequencing error in the area. The shots are located here. There are also three spreadsheets for each of the list for hand-annotations and notes from looking at the IGV shots. I have looked at all of the MOSAIC_CHILD calls and will gradually parse through the other mosaic types over time. For the hand-annotation of the MOSAIC_CHILD calls only five shots were missing information and given an annotation of ‘NA’. The remaining shots all looked like true “MOSAIC_CHILD” calls and were given that annotation. While all of them look like mosaics, the following additional notes were made to explain potential issues with the region or call in general. In the column for notes the following notes were made depending on the shot with some shots receiving multiple notes. The common issues have a representative example of the issue. ‘mismatch in all’ - there visually apperas to be more mismatches than normal across all samples in the family, example ‘mismatch in sample’ - there visually appears to be more mismatches in this sample relative to other members of the family, example ‘mismatch in reads’ - there visually appears to be more mismatches in the specific reads with the variant, example ‘indel’ - this SNV is actually an INDEL or adjacent to an INDEL, example ‘multi-base’ - the variant is correlated to another variant found only in the sample, the other nearby variants may not be reported due to the collapsing of complex events choosing the most deleterious variant, example ‘correlated to other variants’ - this variant is found alongside an upstream or downstream variant found in other members of the family, example ‘edge of read’ - all variant reads are at the edge of reads, these generally have additional issues, example ‘repetitive region’ - this falls in what visually looks like repetitive region, these generally have additional issues ‘cohort count issue’ - this shows technical issues repeatedly at the same position across multiple families . These issues appear in a relatively minor number of variants and filtering them further on these issues would likely not change any other downstream analyses. I believe mismatches across the region are fine and we already are filtering on this across the family. We do not filter by mismatches per individual however and looking at individual mismatches relative to the family would help clean up some calls. Clear indels could be removed (and could be removed easily if we had a more full INDEL list). And we can probably recall the cohort counter with these final lists across all three lists to find regions of routine technical issue. ",
    "url": "/docs/to_be_sorted/2021-08-26-post-0047.html",
    "relUrl": "/docs/to_be_sorted/2021-08-26-post-0047.html"
  },"47": {
    "doc": "SPARK Burden Tables Gene Sets 02",
    "title": "SPARK Burden Tables Gene Sets 02",
    "content": "This is the gene set burden analysis using just the simplex quad burden table. This breaks the variants into categories dependent on if they are Germline LGD or Germline NS and looks at the gene sets and areas under the lists for EXINTOL and ESSENTIAL. The same one-sided Wilcoxon rank sum test is performed and does not find evidence of burden in the subsets. This differs from “SPARK Burden Tables Gene Sets 01” by using the most final non-hg19 version of the DNV call list. The burden results are roughly the same as expected and there is a quick comparison of our lists and theirs at the end. Markdown: 07_02 Burden Gene Sets . Notes per section: 7.4 - Print Table of Wilcoxon Rank Sums for All Genes - These are the one-sided Wilcoxon rank sum test p-values. None of them are significant at 0.05. 7.6 - Plot for All Genes - Barplots for all genes. None of them are significant at 0.05. 8.4 - Print Table of Wilcoxon Rank Sums for Essential Genes - These are the one-sided Wilcoxon rank sum test p-values. None of them are significant at 0.05. 8.6 - Plot for Essential Genes - Barplots for essential genes. None of them are significant at 0.05. 9.4 - Print Table of Wilcoxon Rank Sums for Intolerant Genes - These are the one-sided Wilcoxon rank sum test p-values. None of them are significant at 0.05. 9.6 - Plot for Intolerant Genes - Barplots for intolerant genes. None of them are significant at 0.05. 11.1 - Comparison of Lists, Mosaics - There are 82 DNV calls that we flag as mosaics. DNV calls that we call as mosaic are higher in AF than our mosaic child calls. 11.2 - Comparisons of Lists, Germline - 97% of our Germline calls in the high confidence list are also found in the DNV list. The ones that are unique in our list are slightly lower in depth. ",
    "url": "/docs/to_be_sorted/2021-09-08-post-0048.html",
    "relUrl": "/docs/to_be_sorted/2021-09-08-post-0048.html"
  },"48": {
    "doc": "SPARK Burden Tables Gene Sets 03",
    "title": "SPARK Burden Tables Gene Sets 03",
    "content": "This is the gene set burden analysis using just the simplex quad burden table. This breaks the variants into categories dependent on if they are Germline LGD or Germline NS and looks at the gene sets and areas under the lists for EXINTOL and ESSENTIAL. The same one-sided Wilcoxon rank sum test is performed and does not find evidence of burden in the subsets. This differs from “SPARK Burden Tables Gene Sets 02” by using the most final non-hg19 version of the DNV call list, applying a filter for sites called as indels in IGV screenshots, and recategorizing the calls into the LGD and NS groups. The burden results are roughly the same as before, with maybe a slight but non-significant enrichment for burden in Probands relative to Siblings for the YES_NS category when looking at all the calls. There is a quick comparison of our lists and theirs at the end and a technical comparisons of the Proband vs. Sibling stats. Markdown: 07_03 Burden Gene Sets . Notes per section: 7.4 - Print Table of Wilcoxon Rank Sums for All Genes - These are the one-sided Wilcoxon rank sum test p-values. None of them are significant at 0.05. 7.6 - Plot for All Genes - Barplots for all genes. The Probands show minor hints of enrichment in the “YES_NS” category. None of them are significant at 0.05. 8.4 - Print Table of Wilcoxon Rank Sums for Essential Genes - These are the one-sided Wilcoxon rank sum test p-values. None of them are significant at 0.05. 8.6 - Plot for Essential Genes - Barplots for essential genes. None of them are significant at 0.05. 9.4 - Print Table of Wilcoxon Rank Sums for Intolerant Genes - These are the one-sided Wilcoxon rank sum test p-values. None of them are significant at 0.05. 9.6 - Plot for Intolerant Genes - Barplots for intolerant genes. None of them are significant at 0.05. 11.1 - Comparison of Lists, Mosaics - There are 82 DNV calls that we flag as mosaics. DNV calls that we call as mosaic are higher in AF than our mosaic child calls. 11.2 - Comparisons of Lists, Germline - 97% of our Germline calls in the high confidence list are also found in the DNV list. The ones that are unique in our list are slightly lower in depth. 12 - Comparisons of Proband and Sibling calls Used - Siblings have slightly lower allele frequencies and perhaps a tiny bit more error relative to probands. ",
    "url": "/docs/to_be_sorted/2021-09-14-post-0049.html",
    "relUrl": "/docs/to_be_sorted/2021-09-14-post-0049.html"
  },"49": {
    "doc": "SPARK Concatenated High Confidence Table Checks 01",
    "title": "SPARK Concatenated High Confidence Table Checks 01",
    "content": "This combines the three high confidence lists to reasses cohort counts and compare them all in totality against the DNV list. There are five variant sites appearing in three different families when combining all the three lists together. The full comparison to the DNV list shows the same trends in the simplex quad only comparison. 97% of our Germline Child calls are found in their DNV list. 40% of our MOSAIC CHILD calls are called in the DNV list. Markdown: 08_01 Concatenate High Confidence Lists . Notes per section: 5.2 - Recount Cohort Counts, Plot - Histogram showing the re-counted, final cohort counts after combining the lists. There are very few sites appearing more than once. 5.3 - Recount Cohort Counts, List Counts - Table of counts. There are five variants called at the same place in three different families across the three lists. 7.1 - Their DNV Calls Flagged as Mosaic Child in Our List - Nearly half of our mosaic calls are called in the DNV list. These are expectingly higher in AF relative to all of the calls. 7.2 - Their DNV Calls Flagged as Germline Child in Our List - We find 97% of our Germline Child calls in the DNV list. The ones we don’t find have mildly less depth. ",
    "url": "/docs/to_be_sorted/2021-09-15-post-0050.html",
    "relUrl": "/docs/to_be_sorted/2021-09-15-post-0050.html"
  },"50": {
    "doc": "SPARK Final Sample List",
    "title": "SPARK Final Sample List",
    "content": "Here is a list of the final SP ID’s and their family that are ultimately used in our analysis. Final Sample List . These are the total number of families used in the analysis and where they disappear during our filtering. The first round of filtering is technical – either the variant calls failed or the family was missing a member to continue. The second round of filtering is based on the figure in this post based on read depths and variant call numbers. Simplex Quads: 2623 families on the list 2618 after first round of filtering: SF0096166, SF0096198, SF0096218, SF0137614, SF0136205 2616 after second round of filtering: SF0087337, SF0035804 Multiplex Quads: 559 families on the list 558 after first round of filtering: SF0139094 554 after second round of filtering: SF0096657, SF0113816, SF0086926, SF0132432 Simplex Trios: 2200 families on the list 2196 after first round of filtering: SF0128793, SF0130451, SF0136742, SF0138832 2192 after second round of filtering: SF0026651, SF0017418, SF0020602, SF0083949 . ",
    "url": "/docs/to_be_sorted/2021-10-01-post-0051.html",
    "relUrl": "/docs/to_be_sorted/2021-10-01-post-0051.html"
  },"51": {
    "doc": "SPARK Final IGV and Cohort Count Filter",
    "title": "SPARK Final IGV and Cohort Count Filter",
    "content": "Manual annotation of the mosaic child IGV shots indicated a few sites with complex indel regions we aren’t prepared to deal with or general technical issues in the region. We also merged the simplex quad, simplex trio, and multiple quad lists together to get a full table to count appearances at locations across the entirety. The following is a list of the sites removed and if they were removed via IGV screenshot annotation, the full cohort count, or if they fell in both categories. Link: Final filter list by IGV shots and concatenated cohort count . Quick copy of same text: . SITE_TO_REMOVE REASON_FOR_REMOVAL 11_95778825_T_C_SF0042377 IGV 19_48286404_C_T_SF0112781 IGV 4_148081486_A_T_SF0101498 IGV 17_76574443_C_A_SF0134227 IGV 14_71589107_T_G_SF0060222 IGV 1_53459711_C_T_SF0073768 IGV 20_37179396_A_G_SF0019290 IGV 2_233198214_A_C_SF0063467 IGV 12_102958355_C_A_SF0137371 IGV 17_8797852_TG_CC_SF0016664 IGV 19_1085852_G_A_SF0097088 IGV 4_40102620_T_G_SF0117039 IGV 5_93588053_G_C_SF0034314 IGV 6_26157023_A_C_SF0104693 IGV 8_76852146_A_C_SF0086715 IGV 9_89002090_T_G_SF0045205 IGV 7_44582167_G_C_SF0048613 IGV 18_47248089_G_C_SF0137308 IGV 19_900830_T_C_SF0020554 IGV 1_89378123_C_G_SF0045249 IGV 8_64581045_C_G_SF0022876 IGV 12_57224970_C_A_SF0127928 IGV 3_49111068_G_A_SF0019861 IGV 3_50275373_C_T_SF0077956 IGV 12_122183206_G_T_SF0144774 IGV 10_46549720_C_G_SF0055321 COHORT 10_46549720_C_G_SF0107639 COHORT 10_46549720_C_G_SF0114446 COHORT 15_41570092_C_G_SF0036574 COHORT 15_41570092_C_G_SF0064435 COHORT 15_41570092_C_G_SF0104849 COHORT 20_4221633_A_C_SF0061515 COHORT 20_4221633_A_C_SF0011974 COHORT 20_4221633_A_C_SF0126256 COHORT 22_30695060_A_C_SF0048393 COHORT 22_30695060_A_C_SF0043805 IGV_and_COHORT 22_30695060_A_C_SF0051712 COHORT 3_43032980_A_C_SF0080202 COHORT 3_43032980_A_C_SF0026635 COHORT 3_43032980_A_C_SF0113969 COHORT 7_87515256_A_C_SF0021487 COHORT 7_87515256_A_C_SF0086715 IGV_and_COHORT 7_87515256_A_C_SF0117039 IGV_and_COHORT . ",
    "url": "/docs/to_be_sorted/2021-10-01-post-0052.html",
    "relUrl": "/docs/to_be_sorted/2021-10-01-post-0052.html"
  },"52": {
    "doc": "SPARK LGD and NS List",
    "title": "SPARK LGD and NS List",
    "content": "This describes the generation of the LGD and NS family lists based on the De Novo and CNV lists. Of note, there are four families combined with an underscore, “SF0046231_SF0068802” and “SF0113969_SF0114107”. These are split for these lists and exist as split families in the mosaic variant lists. The LGD list includes 1157 families and the NS list includes 3933 families. Not all families are from the simple quads, simplex trios, or multiplex quad families we use in the mosaic list. Markdown: Generation of LGD and NS Lists . LGD List NS List . ",
    "url": "/docs/to_be_sorted/2021-10-06-post-0053.html",
    "relUrl": "/docs/to_be_sorted/2021-10-06-post-0053.html"
  },"53": {
    "doc": "SPARK Burden Tables Gene Sets 04",
    "title": "SPARK Burden Tables Gene Sets 04",
    "content": "This is the gene set burden analysis using just the simplex quad burden table. This breaks the variants into categories dependent on if they are Germline LGD or Germline NS and looks at the gene sets and areas under the lists for EXINTOL and ESSENTIAL. The same one-sided Wilcoxon rank sum test is performed and does not find evidence of mosaic burden in the subsets. This differs from “SPARK Burden Tables Gene Sets 03” by using the final filters from IGV shots and recalculated cohort counts. This also uses the more exact NS and LGD family lists. Markdown: 07_04 Burden Gene Sets . Notes per section: 10.4 - Print Table of Wilcoxon Rank Sums for Germline Missense - This indicates the statistical significant difference, p &lt; 0.001, with the NS list 10.6 - Plot for Germline Missense, All Genes - This shows the germline missense burden from the test above. This is similar for the other gene subsets. ",
    "url": "/docs/to_be_sorted/2021-10-06-post-0054.html",
    "relUrl": "/docs/to_be_sorted/2021-10-06-post-0054.html"
  },"54": {
    "doc": "Drosophilia Tau Preliminary DA",
    "title": "Drosophilia Tau Preliminary DA",
    "content": "Directory: /home/groups/oroaklab/nishida/sc_dm6_tau/DA_oct7 Run: /home/groups/oroaklab/nishida/sc_dm6_tau/DA_oct7/run.txt . There are 135 conditions so it is impossible to do pairwise comparisons between everything. Cluster comparisons were made between C_1 to C_9. And then for each of the individual 9 clusters, I did the treatments within time (same day but different strain) and between time (same strain but different day). This ignores cross strain and cross day comparisons (like CS_5 vs. WT_CS_30). The DA was performed after TF normalization using the Wilcoxon rank sum test. ",
    "url": "/docs/to_be_sorted/2021-10-07-post-0055.html",
    "relUrl": "/docs/to_be_sorted/2021-10-07-post-0055.html"
  },"55": {
    "doc": "SPARK Summary of Final Lists",
    "title": "SPARK Summary of Final Lists",
    "content": "UPDATE Oct 13 - Added full HC count tables. UPDATE Oct 12 - Modified labels and counting by affected status rather than ‘PRO’ and ‘SIB’ designations. This takes the high confidence and burden tables and summarizes them relative to Table 1 in the Krupp paper. Because we don’t have representation of mosaics at lower allele fractions the differences between the high confidence and burden tables is minimal until you begin thresholding on read depth. The final output is copy+pasted below in tab-delineated format for ease of use. Markdown: 10 Summarize Final Lists . Link: High Confidence Count Table . High Confidence . ## synonymous missense nonsense_splicing total ## Simplex Quad Aff 26 66 5 97 ## Simplex Quad Unaff 27 73 4 104 ## Multiplex Quad Aff 17 38 3 58 ## Multiplex Quad Unaff 0 7 0 7 ## Simplex Trio Aff 22 63 1 86 ## Total Aff 65 167 9 241 ## Total Unaff 27 80 4 111 . Burden, 15% and 45x . ## synonymous missense nonsense_splicing total ## Simplex Quad Aff 25 65 4 94 ## Simplex Quad Unaff 26 73 4 103 ## Multiplex Quad Aff 17 38 3 58 ## Multiplex Quad Unaff 0 7 0 7 ## Simplex Trio Aff 21 61 1 83 ## Total Aff 63 164 8 235 ## Total Unaff 26 80 4 110 . Burden, 12.5% and 50x . ## synonymous missense nonsense_splicing total ## Simplex Quad Aff 20 54 4 78 ## Simplex Quad Unaff 18 63 3 84 ## Multiplex Quad Aff 13 31 3 47 ## Multiplex Quad Unaff 0 6 0 6 ## Simplex Trio Aff 19 53 1 73 ## Total Aff 52 138 8 198 ## Total Unaff 18 69 3 90 . Burden, 10% and 65x . ## synonymous missense nonsense_splicing total ## Simplex Quad Aff 8 24 2 34 ## Simplex Quad Unaff 10 20 1 31 ## Multiplex Quad Aff 4 12 1 17 ## Multiplex Quad Unaff 0 2 0 2 ## Simplex Trio Aff 10 27 1 38 ## Total Aff 22 63 4 89 ## Total Unaff 10 22 1 33 . Burden, 7.5% and 85x . ## synonymous missense nonsense_splicing total ## Simplex Quad Aff 2 5 0 7 ## Simplex Quad Unaff 3 3 0 6 ## Multiplex Quad Aff 2 4 0 6 ## Multiplex Quad Unaff 0 2 0 2 ## Simplex Trio Aff 2 4 0 6 ## Total Aff 6 13 0 19 ## Total Unaff 3 5 0 8 . Burden, 5% and 130x . ## synonymous missense nonsense_splicing total ## Simplex Quad Aff 0 1 0 1 ## Simplex Quad Unaff 0 0 0 0 ## Multiplex Quad Aff 0 1 0 1 ## Multiplex Quad Unaff 0 0 0 0 ## Simplex Trio Aff 0 0 0 0 ## Total Aff 0 2 0 2 ## Total Unaff 0 0 0 0 . HC Table Breakdown . ## variant mutation quad_simplex trio_simplex ## quad_multiplex total ## 1 MOSAIC_CHILD missense 139 63 ## 1 45 247 ## 2 MOSAIC_CHILD synonymous 53 22 ## 2 17 92 ## 3 MOSAIC_CHILD nonsense_splicing 9 1 ## 3 3 13 ## 4 MOSAIC_CHILD stoploss 0 0 ## 4 0 0 ## 5 MOSAIC_CHILD unknown 0 0 ## 5 0 0 ## 6 MOSAIC_PARENTAL_NONTRANS missense 485 928 ## 6 167 1580 ## 7 MOSAIC_PARENTAL_NONTRANS synonymous 274 487 ## 7 99 860 ## 8 MOSAIC_PARENTAL_NONTRANS nonsense_splicing 15 47 ## 8 6 68 ## 9 MOSAIC_PARENTAL_NONTRANS stoploss 2 1 ## 9 0 3 ## 10 MOSAIC_PARENTAL_NONTRANS unknown 0 0 ## 10 1 1 ## 11 GERMLINE_CHILD missense 991 563 ## 11 275 1829 ## 12 GERMLINE_CHILD synonymous 392 215 ## 12 115 722 ## 13 GERMLINE_CHILD nonsense_splicing 57 42 ## 13 9 108 ## 14 GERMLINE_CHILD stoploss 1 0 ## 14 0 1 ## 15 GERMLINE_CHILD unknown 0 0 ## 15 1 1 ## 16 MOSAIC_PARENTAL_TRANS_MATERNAL missense 37 19 ## 16 8 64 ## 17 MOSAIC_PARENTAL_TRANS_MATERNAL synonymous 15 8 ## 17 4 27 ## 18 MOSAIC_PARENTAL_TRANS_MATERNAL nonsense_splicing 0 0 ## 18 2 2 ## 19 MOSAIC_PARENTAL_TRANS_MATERNAL stoploss 0 0 ## 19 0 0 ## 20 MOSAIC_PARENTAL_TRANS_MATERNAL unknown 0 0 ## 20 0 0 ## 21 MOSAIC_PARENTAL_TRANS_PATERNAL missense 30 21 ## 21 9 60 ## 22 MOSAIC_PARENTAL_TRANS_PATERNAL synonymous 23 9 ## 22 7 39 ## 23 MOSAIC_PARENTAL_TRANS_PATERNAL nonsense_splicing 1 1 ## 23 0 2 ## 24 MOSAIC_PARENTAL_TRANS_PATERNAL stoploss 0 0 ## 24 0 0 ## 25 MOSAIC_PARENTAL_TRANS_PATERNAL unknown 0 0 ## 25 0 0 . ",
    "url": "/docs/to_be_sorted/2021-10-10-post-0056.html",
    "relUrl": "/docs/to_be_sorted/2021-10-10-post-0056.html"
  },"56": {
    "doc": "SPARK Final List Allele Frequency Distributions",
    "title": "SPARK Final List Allele Frequency Distributions",
    "content": "UPDATE Oct 12 - Nothing changed but as a note, the multiplex quad labels are left as ‘PRO’ and ‘SIB’ despite being both affected for these plots since they are looking at the technical labels and details. These are the allele frequency distribution plots before with the final filters added. These are done with simplex quads individually, then adding the simplex trios, and then adding the multiplex quads. Markdown: 11 High Confidence AF Dists, QS 11 High Confidence AF Dists, QS and TS 11 High Confidence AF Dists, QS, TS, and QM . ",
    "url": "/docs/to_be_sorted/2021-10-10-post-0057.html",
    "relUrl": "/docs/to_be_sorted/2021-10-10-post-0057.html"
  },"57": {
    "doc": "SPARK Monozygotic Twins in Quad Families",
    "title": "SPARK Monozygotic Twins in Quad Families",
    "content": "There are 24 multiplex quad and 9 simplex quad monozygotic twin families in our analysis. If you check their upstream calls for “MULTI_MOSAIC” calls in just the proband and siblings you return 6 and 2 sites respectively from the multiplex and simplex families. These 8 IGV shots are uploaded but 7 of them show evidence of the variant also in the parent (visually it appears but isn’t technically called and retained in our lists as mosaic). There remains one mosaic (a synonymous mutation) from the multiplex quads that looks like a real mosaic in the proband and sibling. Here is a link to that shot: IGV Screenshot of Real Multi-Mosaic. These are the specific sites tested: . Simplex: 14 19433918 G A SF0027672 MULTI_MOSAIC 15 41565075 C T SF0099414 MULTI_MOSAIC Multiplex: 1 155660816 T C SF0028355 MULTI_MOSAIC 3 195784717 G A SF0051712 MULTI_MOSAIC 7 101000375 C T SF0051712 MULTI_MOSAIC 20 58840493 T C SF0054416 MULTI_MOSAIC 15 75682880 G C SF0064210 MULTI_MOSAIC 19 53351779 A G SF0080300 MULTI_MOSAIC . ",
    "url": "/docs/to_be_sorted/2021-10-11-post-0058.html",
    "relUrl": "/docs/to_be_sorted/2021-10-11-post-0058.html"
  },"58": {
    "doc": "SPARK Burden Tables Gene Sets, Final 01",
    "title": "SPARK Burden Tables Gene Sets, Final 01",
    "content": "Update Oct 13. Updated to add 0 counts for families with absent calls. Update Oct 12. The following was changed and this completely replaces the older results. Here are the main differences. - A big issue I had was that I had empty placeholder values for siblings for the trios that shouldn’t have been used in the statistical test. These are easily removed. The pvals were ultimately insignificant in all iterations so it doesn’t change any of our interpretations. - The summary of n’s now splits the family counts by proband and sibling. This is only relevant for trios. - Plotting of the SNV’s per Exome Base is now no longer additive but uses the average rates. This makes the plots look more reasonable and the y-axis closer to expectations. - SNV’s per Exome Base is now calculated as (# counts / 2*autosomal_bases_covered). I wasn’t use the 2 before. This doesn’t affect the test because it is ranked, it just changes the axis’ magnitude. This is the gene set burden analysis using the final burdens table. This breaks the variants into categories dependent on if they are Germline LGD or Germline NS and looks at the gene sets and areas under the lists for EXINTOL and ESSENTIAL. The same one-sided Wilcoxon rank sum test is performed and does not find evidence of mosaic burden in the subsets. This differs from previous passes in that I am using the complete final list and am plotting all categories of mutations for quad simplex lists alone and the quad simplex list with the trio simplex list like in the Krupp paper. When stacking the trio simplex probands onto the rest of the data like it is in the paper we do see a significant enrichment of burden in the probands. Markdown: 12 Burden Genesets, QS and missense 12 Burden Genesets, QS and synonymous 12 Burden Genesets, QS and nonsense-splicing 12 Burden Genesets, QS and TS and missense 12 Burden Genesets, QS and TS and synonymous 12 Burden Genesets, QS and TS and nonsense-splicing . ",
    "url": "/docs/to_be_sorted/2021-10-11-post-0059.html",
    "relUrl": "/docs/to_be_sorted/2021-10-11-post-0059.html"
  },"59": {
    "doc": "SPARK Burden w/ REVEL Scores Gene Sets, 01",
    "title": "SPARK Burden w/ REVEL Scores Gene Sets, 01",
    "content": "Update Oct 13. Updated to add 0 counts for families with absent calls. This is an extension of the burden analysis but here we are keeping only damaging missense calls by thresholding on REVEL scores &gt;= 0.50. This eliminates many of the calls but does produce a stronger signal in comparing probands to siblings. REVEL scores are available in the supplmental annotation folder. Markdown: 13 Burden REVEL, QS and missense 13 Burden REVEL, QS+TS and missense . Notes: Fig 3.1 - This contains the REVEL distributions which are left-skewed towards 0. Annotations: OUTDATED. Use full annotations on index page. Supplemental Annotations, REVEL, trio simplex Supplemental Annotations, REVEL, quad simplex Supplemental Annotations, REVEL, quad simplex . ",
    "url": "/docs/to_be_sorted/2021-10-13-post-0060.html",
    "relUrl": "/docs/to_be_sorted/2021-10-13-post-0060.html"
  },"60": {
    "doc": "SPARK Parental Trans Mosaics Breakdown",
    "title": "SPARK Parental Trans Mosaics Breakdown",
    "content": "This contains a quick look at how many mosaics are transmitted by the parents to their children. There is no evidence of preference for proband or sibling in these transmission events where 51% go to probands and 49% go to siblings. Markdown: 14 Parental Transmission Breakdown . Notes: 2.2 - Plot Father Transmitted Mosaics - Pro vs. Sib Allele Frequency Plot 2.3 - Plot Mother Transmitted Mosaics - Pro vs. Sib Allele Frequency Plot . Breakdown of transmission to children. ## PaternalTransMosaics MaternalTransMosaics ## trans to PRO 26 24 ## trans to SIB 24 22 ## trans to PRO and SIB 4 6 ## total 54 52 . ",
    "url": "/docs/to_be_sorted/2021-10-13-post-0061.html",
    "relUrl": "/docs/to_be_sorted/2021-10-13-post-0061.html"
  },"61": {
    "doc": "SPARK HC Tables Against SPARK 167",
    "title": "SPARK HC Tables Against SPARK 167",
    "content": "This intersects our lists with the SPARK 167. We find 20 mosaic child calls intersecting these genes. Breakdowns and the genes are below. Links: HC list Variants Intersecting w/ SPARK 167, Mosaic Child only HC list Variants Intersecting w/ SPARK 167 . Markdown: 15 SPARK 167 Intersection . Mutation types of the 20 overlapping mosaic child calls: . ## missense nonsense_splicing synonymous ## 16 1 3 . The 20 mosaic hits fell in the following genes: . 1 ADNP 1 AHDC1 1 ANKRD11 1 ARID1B 1 CASZ1 2 CIC 1 DNMT3A 1 GIGYF1 1 GRIN2A 1 NRXN2 2 PACS1 1 PHF3 1 POMGNT1 1 SETD5 1 SHANK3 1 SRCAP 1 SYNGAP1 1 TCF20 . List of origin for all overlapping calls: . ## multiplex_simplex quad_simplex trio_simplex ## 23 78 65 . Variant types for all overlapping calls: . ## GERMLINE_CHILD MOSAIC_CHILD ## 84 20 ## MOSAIC_PARENTAL_NONTRANS MOSAIC_PARENTAL_TRANS_MATERNAL ## 56 2 ## MOSAIC_PARENTAL_TRANS_PATERNAL ## 4 . ",
    "url": "/docs/to_be_sorted/2021-10-13-post-0062.html",
    "relUrl": "/docs/to_be_sorted/2021-10-13-post-0062.html"
  },"62": {
    "doc": "SPARK Concat Variant Lists to DNV List Comparison",
    "title": "SPARK Concat Variant Lists to DNV List Comparison",
    "content": "This compares our high confidence mosaic lists to the SPARK DNV lists. This shows that nearly all of our germline calls are called in their list (2588/2661 = 97%). The Venn shows there are still many germline calls we are not picking but this isn’t a surprise because we subject everything to harsher filtering while looking for mosaics. A large number of mosaics we call (145/352 = 41%) are flagged as de novo variants in the SPARK list. Boxplots, densities, and histograms of allele frequencies show that these are at intermediate AF’s. Link to Venn Diagrams (scaled and unscaled): Venn Diagram of List Comparisons . Markdown: 16 Concat Variant Lists to DNV List . Notes: 5.3 - Their DNV Calls Flagged as Mosaic Child in Our List - This shows their DNV calls that we call as mosaic are of expected higher AF. 5.4 - Their DNV Calls Flagged as Germline Child in Our List - This shows the Germline calls that make uniquely are at lower read depth. 5.5 - Combined Boxplot of AF’s - This is a more complete and non-overlapping way of looking at the AF distributions across all partitions. 6.2 - Densities with All 4 Groups - density plots of AF’s 6.3 - Hists with All 4 Groups - hists of AF’s 6.4 - Densities with 3 Relevant Groups - same as above but without germline calls specific to our list 6.5 - Hists with 3 Relevant Groups - same as above but without germline calls specific to our list . Breakdown of a Comparison of Our Calls w/ Theirs: . ## Our Mosaic Child Calls Our Germline Child Calls ## Total 352 2661 ## Found in DNV List 145 2588 ## Not Found in DNV List 207 73 . ",
    "url": "/docs/to_be_sorted/2021-10-14-post-0063.html",
    "relUrl": "/docs/to_be_sorted/2021-10-14-post-0063.html"
  },"63": {
    "doc": "Contamination References",
    "title": "Contamination References",
    "content": "This describes the maintence of O’Roak and Adey lab contamination references. Smaller contamination sequences are held here for use with FASTQC: *PENDING* Larger contermination sequences are held here for alignment: /home/groups/oroaklab/refs/contamination/refs . Please keep references in FA format, separated by individual names, named by their accession reference, and with this accession in the header. The totality of the FA’s are concatenated into a single BWA index. Here is a rough framework of an alignment and quick summary to these resources: . # refresh contamination references bash /home/groups/oroaklab/refs/contamination/setup.sh # copy demuxed reads ln -s /home/groups/oroaklab/demultiplex/211103_NS500556_0533_AHC7V5AFX3/*SA* . # align bwa mem -M -t 32 /home/groups/oroaklab/refs/contamination/contamination.fa 211103_NS500556_0533_AHC7V5AFX3.s3_10bp.SA.R1.fq.gz 211103_NS500556_0533_AHC7V5AFX3.s3_10bp.SA.R2.fq.gz &gt; align_to_contamination.sam # report cat align_to_contamination.sam | grep -v \"^@\" | cut -f 3 | sort | uniq -c # output #2331010 * #6024366 NC_000913.3 # 769709 NC_004718.3 . List of contamination sequences: . &gt;NC_000913.3 Escherichia coli str. K-12 substr. MG1655, complete genome &gt;NC_004718.3 SARS coronavirus Tor2, complete genome . ",
    "url": "/docs/to_be_sorted/2021-11-04-post-0064.html",
    "relUrl": "/docs/to_be_sorted/2021-11-04-post-0064.html"
  },"64": {
    "doc": "Single Cell TBR1 Pseudo-Bulk Depth Tests",
    "title": "Single Cell TBR1 Pseudo-Bulk Depth Tests",
    "content": "Directory: /home/groups/oroaklab/nishida/sc_tmp1/pseudo_bulk_example Run: /home/groups/oroaklab/nishida/sc_tmp1/pseudo_bulk_example/run.txt . This gives an example of how to take the single-cell data and transform it to bulk. I then subsampled the full BAM by increments of 5% and called macs3 on each subset. The plot shows a linear increase of the number of peaks called relative to the log number of reads present. This indicates that we are not at saturation of reads for calling peaks and gives a rough approximation of what we can expect. From my personal experience with bulk DNase data, saturation for peaks called needs ~500M reads. With single-cell data you get a lot more repetition of common open sites from each individual cell. Figure of peaks called from pseudo-bulk data: Number of Macs 3 peaks and Log Read Depth . ",
    "url": "/docs/to_be_sorted/2021-11-28-post-0065.html",
    "relUrl": "/docs/to_be_sorted/2021-11-28-post-0065.html"
  },"65": {
    "doc": "SPARK SSC List Formatting to Current SPARK",
    "title": "SPARK SSC List Formatting to Current SPARK",
    "content": "The SSC variant calls are taken from this Box file, https://ohsu.box.com/s/dqm3garunt0xobvgdz41onpexi87yqin, on this path, All Files/kruppd/Writing/SSC somatic pilot/data/Data Used for Mosaic Paper/High Confidence Variants/HighConfidence Variants Collapsed_2.csv. This appears to be a similar version of Table S5 from the Krupp 2017 paper with the columns with the statistics which are excluded from the paper. Unlike the table in the paper, this also collapses sites in overlapping genes into a single entry which is more in line with the SPARK lists where genes are combined in one entry separated by commas. All SSC columns are transformed to match the columns for the SPARK list. Here is the transformed SSC list. It has the same columns as the SPARK lists and has extra columns representing the SSC specific entries. The two important extra columns to consider that are unique to the SSC list are column 90 and 91 which are the ‘FILTER’ and ‘OLD_TYPE’ respectively. ‘FILTER’ is TRUE or FALSE. TRUE entries should be filtered from the analysis and their designation is explained below. In general they are calls that do not meet our criteria after reannotation in hg38 versus hg19. ‘OLD_TYPE’ designates whether the call comes from a quad or trio family which may or may not be important for us. SSC list in SPARK list format: SSC List in SPARK List Format . Markdown showing how the list was modified: 17 SSC List Formatting to Current SPARK . The column ‘FILTER’ designates calls to remove from downstream analysis. ‘TRUE’ calls should be removed and are given if: . - there are no FRACTION calls made (not labeled GERMLINE or MOSAIC, labeled 'NA') - the variant falls in a region that is annotated in either a non-exonic, super duplicate, or trf region - the variant does not have a predicted functional mutation type . The following columns were modified in the transformation: . Coordinates were changed via LiftOver with 100% of the sites found going from hg19 to hg38. All genomic and functional annotations were redone with AnnoVAR for hg38. FRACTION_MORE is derived from FRACTION with name changes to match the SPARK list (\"GERMLINE_C\" is changed to \"GERMLINE_CHILD\"). ACC_DIST and DON_DIST are the same value. The SSC list keeps only the closest wheras the SPARK list keeps both separate. COMPLEX_EVENT is descriptive in the SSC list and binary in the SPARK list. NUM_FAMILY_FOUND and filteredCohortCount represent cohort counts before and after filtering. In the SSC list, only the final count is kept so these are the same for the SSC list. HGNCsymbol_to_ENSID and RefSeq_to_ENSID are the ENSEMBL ID's determined from the hg38 annotations. The following columns were dropped and all set to ‘NA’: . There are no numerical sample IDs in the SSC list. SSC uses combined family stats from the variant callers whereas the SPARK list keeps them by individual so these are dropped. Mismatch stats for raw mismatch counts, 'other' read counts, and the means are not present in the SSC list. gnomAD allele fractions are not present in the earlier SSC table. The only error columns in the SSC list are the calculated rates. FRACTION_OLD is a legacy column in the SPARK list and does not have meaning in the SSC list. The splice site transcript IDs are not present just the distances. The following extra columns specific to the SSC list were added at the end. These are potentially important for analysis: . FILTER - TRUE or FALSE and represent variants that should be filtered out after the transformation of hg19 to hg38 OLD_TYPE - TRIO or QUAD OLD_SEGDUP, OLD_RMSK, OLD_TRF, OLD_FUNC_TYPE, OLD_TRANS_REF, OLD_CLASS_REF, OLD_GENE_REF - these are the original hg19 AnnoVAR annotations . The following SSC specific columns were kept and added at the end. These can likely be ignored. I’ve tried to describe them as best as possible without knowing their exact provenance: . OLD_STUDY - COHORT or PILOT24 or PILOT400 OLD_PUBLISHED - IOSSIFOV_2014 or KRUMM_2015 OLD_AF_ESP, OLD_AF_1KG - allele fractions from other databases OLD_PCTILE_CDS_AUTO_45X - 5% percentiles of CDS AUTO 45x OLD_FORMAT_VARSCAN, OLD_FORMAT_LOFREQ, OLD_FORMAT_SMOC, OLD_VARSCAN_232_FA, OLD_LOFREQ_211_FA, OLD_SMOC_FA, OLD_VARSCAN_232_MO, OLD_LOFREQ_211_MO, OLD_SMOC_MO, OLD_VARSCAN_232_PRO, OLD_LOFREQ_211_PRO, OLD_SMOC_PRO, OLD_VARSCAN_232_SIB, OLD_LOFREQ_211_SIB, OLD_SMOC_SIB - family-based variant calling output OLD_DIST_TO_PREV, OLD_DIST_TO_NEXT, OLD_PERSON_PREV, OLD_PERSON_NEXT - closest call and person OLD_QC_STATUS - at this stage they are all 'PASS', unknown criteria OLD_COHORT_DP, OLD_COHORT_DPALT, OLD_P400_COUNT_MOS, OLD_P400_COUNT_GERM, OLD_COHORT_COUNT_MOS, OLD_COHORT_COUNT_GERM, OLD_COHORT_MAX_AD, OLD_P400_COUNT_ALL - various counts within the cohort subsets OLD_AF_FA, OLD_AF_MO, OLD_AF_PRO, OLD_AF_SIB, OLD_CALLED_FA, OLD_CALLED_MO, OLD_CALLED_PRO, OLD_CALLED_SIB, OLD_DETECT_FA, OLD_DETECT_MO, OLD_DETECT_PRO, OLD_DETECT_SIB, OLD_PHET_MAIN, OLD_SITE_KEY, OLD_PARENTAL, OLD_GONADAL, OLD_CALLED_VARSCAN, OLD_CALLED_LOFREQ, OLD_CALLED_SMOC - these are all redundant derived columns . ",
    "url": "/docs/to_be_sorted/2021-11-30-post-0066.html",
    "relUrl": "/docs/to_be_sorted/2021-11-30-post-0066.html"
  },"66": {
    "doc": "SPARK Burden Tables Gene Sets, SPARK+SSC",
    "title": "SPARK Burden Tables Gene Sets, SPARK+SSC",
    "content": "This performs the burden analysis across the genesets using the combined and harmonized Spark and SSC lists. The SSC is transformed to hg38 but the joint coverages remain in hg19. Joint coverages were manually filtered for duplicate entries for two families, 13431 and 12839. Markdowns: 18 Burden Genesets, SPARK+SSC and missense 18 Burden Genesets, SPARK+SSC and synonymous 18 Burden Genesets, SPARK+SSC and nonsense-splicing . ",
    "url": "/docs/to_be_sorted/2021-11-30-post-0067.html",
    "relUrl": "/docs/to_be_sorted/2021-11-30-post-0067.html"
  },"67": {
    "doc": "SPARK VEP Annotations",
    "title": "SPARK VEP Annotations",
    "content": "VEP was used to annotate the high confidence lists. The following databases were used. There are redundant scores between the databases but they might possibly differ slightly due to the different versions of references each uses. | dbNSFP v4.1a from ftp://dbnsfp:dbnsfp@dbnsfp.softgenetics.com/dbNSFP4.1a.zip | gnomAD v3.0.1 from https://storage.googleapis.com/gcp-public-data–gnomad/release/3.0.1/coverage/genomes/gnomad.genomes.r3.0.1.coverage.summary.tsv.bgz | REVEL v1.3 from https://sites.google.com/site/revelgenomics/downloads | LoFtool scores (no version) from https://github.com/Ensembl/VEP_plugins | ExACpLI scores (no version) from https://github.com/Ensembl/VEP_plugins | blosum62 scores (no version) | . I am keeping this separated from the high confidence lists but these columns can be directly added to the highconfidence lists without any reordering (the rows are the same). These are available here. Simplex Quad, Added Annotations Multiplex Quad, Added Annotations Simplex Trio, Added Annotations . The dbNSFP columns are described here and then are followed by the other scores from the other annotation databases: Added Annotation Column Descriptions . ",
    "url": "/docs/to_be_sorted/2021-12-03-post-0068.html",
    "relUrl": "/docs/to_be_sorted/2021-12-03-post-0068.html"
  },"68": {
    "doc": "Drosophilia Tau Final DA",
    "title": "Drosophilia Tau Final DA",
    "content": "Directory: /home/groups/oroaklab/nishida/sc_dm6_tau/DA_jan7_2022 Run: /home/groups/oroaklab/nishida/sc_dm6_tau/DA_jan7_2022/run.txt . The DA was performed after TF normalization using the Wilcoxon rank sum test and creates the comparisons in ‘210712_DA_Comparisons.txt’. Mild name changes were made in the comparisons such as ‘Photoreceptor’ to ‘Photoreceptors’ to match the annotation file and using the correct annotation column for the biologically split subsets. The following comparisons are nonexistant because they have no cells with the annotation: . - Glia_WT_CS_5_C13 has no cells so all 6 comparisons are missing in 3_Glia_d5. - Glia_KI_CS_30_C21, Glia_dTaudel_30_C13, Glia_KI_CS_30_C13 in 3_Glia_d30. The following comparisons are deliberately empty because they have too few cells: . - DA.Glia_WT_CS_30_C11_Glia_PL_CS_30_C11.txt, DA.Glia_WT_CS_30_C13_Glia_CS_30_C13.txt - DA.Neuron_WT_CS_30_C14_Neuron_dTaudel_30_C14.txt, DA.Neuron_WT_CS_30_C14_Neuron_PL_CS_30_C14.txt - DA.Photoreceptors_WT_CS_30_C1_Photoreceptors_PL_CS_30_C1.txt, DA.Photoreceptors_WT_CS_30_C3_Photoreceptors_dTaudel_30_C3.txt, DA.Photoreceptors_WT_CS_30_C3_Photoreceptors_KI_CS_30_C3.txt, DA.Photoreceptors_WT_CS_30_C3_Photoreceptors_PL_CS_30_C3.txt, DA.Photoreceptors_WT_CS_30_C3_Photoreceptors_VM_CS_30_C3.txt . ",
    "url": "/docs/to_be_sorted/2022-01-08-post-0069.html",
    "relUrl": "/docs/to_be_sorted/2022-01-08-post-0069.html"
  },"69": {
    "doc": "SPARK SSC hg38 Transformed Burden, 01",
    "title": "SPARK SSC hg38 Transformed Burden, 01",
    "content": "The SSC list was transformed from hg19 to hg38 as described here. 20 sites were removed for having no original FRACTION assignment. 172 sites removed for falling into a SDTRF region in going from hg19 to hg38. 9 sites were removed for having no functional mutation type (both originally and after reannotation). There were 7 mosaic child sites lost in this fashion. 1 had no mutation type in both hg19 and hg38. The other 6 fell in super duplicate regions with 3 of them being within 100 bp of each other constituting a complex event. This recreates the burden analysis from the original SSC paper. The trends match but the n’s and signficance do not. This is due to the family list and potentially the LGD/NS lists. The family lists include hundreds more families than the original analysis and are taken from ‘cohort_all_families_list.table’. The LGD/NS lists were taken from ‘Family_Subcohort_Designations.xlsx’. These were found in our Box directory: /All Files/kruppd/Writing/SSC somatic pilot/data/Data Used for Mosaic Paper/High Confidence Variants/ . Markdown showing the SSC solo burden analysis: 19 SSC Solo Burden Markdown . ",
    "url": "/docs/to_be_sorted/2022-01-18-post-0070.html",
    "relUrl": "/docs/to_be_sorted/2022-01-18-post-0070.html"
  },"70": {
    "doc": "SPARK Pre Best Practices Filter, Model Scores",
    "title": "SPARK Pre Best Practices Filter, Model Scores",
    "content": "This markdown takes the pre-filtered data and plots out the metrics that are used for scoring by the logistic model. All variants are plotted and then just the subset of mosaic child calls. This data represents the simplex quads only. It uses the broad filter and removes parental germline calls. A broad filter to reduce computational load is used. - Frequent variants appearing 5 or more times are removed from further analysis. - Common variant allele frequencies determined from ExAC and gnomAD annotations must be less than 0.005. - Variants require at least 3 non-reference reads and at least 8 reads in all four family members. - Variants must also fall within exonic or splicing regions from RefSeq annotations. Markdown showing the error model metrics of the pre-filtered data: 20 Logistic Model Metrics Pre-Filter . ",
    "url": "/docs/to_be_sorted/2022-01-19-post-0071.html",
    "relUrl": "/docs/to_be_sorted/2022-01-19-post-0071.html"
  },"71": {
    "doc": "Drosophilia Tau DA Results Test Analysis",
    "title": "Drosophilia Tau DA Results Test Analysis",
    "content": "Directory: /home/groups/oroaklab/nishida/sc_dm6_tau/DA_jan7_2022/test_analysis Run: /home/groups/oroaklab/nishida/sc_dm6_tau/DA_jan7_2022/test_analysis/run.txt . This is an example rough pass through analyzing the results of the DA test. This focuses on the ‘3_Parent_d5’ comparisons as the example. Clusters are combined across treatments but kept separate. Thresholds for ‘significantly changing’ sites are &lt; 0.01 raw p-value and &gt; 1.5 Log2 FC. The significant results could be annotated by their motifs and nearest genes. 5.2-5.7 - P-value distributions are left-skewed. FDR does not work except maybe with WT_to_KI_KI. Volcano plots suggest global opening and closing in some conditions (WT_to_KI_KI shows a global decrease in accessibility across many sites). 8.8 - Heatmap shows groups of sites that are specific to the strains trending in the same direction. The most notable is the group for WT to KI_KI which shows large decreases specific to the biological cluster 3 (in yellow on the left). Markdown links: R Markdown HTML R Markdown . ",
    "url": "/docs/to_be_sorted/2022-01-21-post-0072.html",
    "relUrl": "/docs/to_be_sorted/2022-01-21-post-0072.html"
  },"72": {
    "doc": "Dropbox Upload and Download with Curl and API Key",
    "title": "Dropbox Upload and Download with Curl and API Key",
    "content": "These are the step to upload and download from the console to and from Dropbox. 1. Go to: https://www.dropbox.com/developers/apps 2. Create an App. Name is whatever you like but probably something like “Dropbox Access”. 3. Navigate to Permissions on the top tab. Check account_info.write, account_info.read, files.metadata.write, files.metadata.read, files.content.write, and files.content.read. 4. Navigate to Settings on the top tab. Generate your access token. If you change your permissions you must regenerate your access token. Always keep your API key secret or else anybody can use it to access everything in your Dropbox. ### . For files &lt; 150 Mb using the “2/files/upload” endpoint. Upload Instructions. This will upload file, ‘test.txt’, into your Dropbox folder ‘temp_upload’ under the name ‘uploaded_test_file.txt’. # create test file echo \"TEST THIS\" &gt; test.txt # fill these variables in API_KEY=\"keep your API key secret\" INPUT_PATH=\"test.txt\" DROPBOX_FILE_PATH=\"/temp_upload/uploaded_test_file.txt\" # run curl -X POST https://content.dropboxapi.com/2/files/upload \\ --header \"Authorization: Bearer ${API_KEY}\" \\ --header \"Dropbox-API-Arg: {\\\"path\\\": \\\"${DROPBOX_FILE_PATH}\\\"}\" \\ --header \"Content-Type: application/octet-stream\" \\ --data-binary @${INPUT_PATH} . Download Instructions. This will download ‘uploaded_test_file.txt’ in Dropbox directory ‘temp_upload’ as ‘downloaded_test_file.txt . # fill these variables in API_KEY=\"keep your API key secret\" DROPBOX_FILE_PATH=\"/temp_upload/uploaded_test_file.txt\" OUTPUT_PATH=\"downloaded_test_file.txt\" # run curl -X POST https://content.dropboxapi.com/2/files/download \\ --header \"Authorization: Bearer ${API_KEY}\" \\ --header \"Dropbox-API-Arg: {\\\"path\\\": \\\"${DROPBOX_FILE_PATH}\\\"}\" \\ -o \"${OUTPUT_PATH}\" . ### . For files &gt; 150 Mb using upload sessions. https://github.com/andreafabrizi/Dropbox-Uploader . ",
    "url": "/docs/to_be_sorted/2022-01-25-post-0073.html",
    "relUrl": "/docs/to_be_sorted/2022-01-25-post-0073.html"
  },"73": {
    "doc": "OneDrive Upload and Download with Rclone",
    "title": "OneDrive Upload and Download with Rclone",
    "content": "Here’s instructions for using rclone on our clusters specifically using a remote/headless machine. This requires more setup but skips the use of X11. | Download rclone on your personal home computer, https://rclone.org/downloads/. | Go to mays/mccovey/bonds and load the rclone modules, module load rclone. | Setup rclone on mays/mccovey/bonds, rclone config. | Inside rclone’s configuration, setup the following: . | ‘n’ for new remote at the ‘n/s/q’ prompt | a shortcut name for the storage at the ‘name’ prompt, I am just calling it ONEDRIVE | ‘onedrive’ for the ‘Storage’ prompt | press enter to skip the prompt ‘client_id’ | press enter to skip the prompt ‘client_secret’ | ‘global’ for the prompt ‘region’ | ‘n’ to not edit the advanced configurations at ‘y/n’ | ‘n’ to setup on the headless node at ‘y/n’ | leave this open for a moment | . | On your personal home computer run rclone authorize \"onedrive\". This will open your web browser and ask you to log into your OneDrive account. This then returns a long configuration string to copy. | Paste the configuration key back on the config in mays/mccovey/bonds. | Finish configuration: . | confirm the configuration as ‘onedrive’ at the prompt ‘config_type’ | confirm ‘y’ at the URL confirmation of ‘y/n’ | confirm ‘y’ for setup at the last prompt ‘y/n’ | ‘q’ to quit out and you should be set up | . | Send a test file. This should send the test file to your OneDrive account setup with the name “ONEDRIVE” to the directory Documents/ echo \"THIS IS A TEST FILE\" &gt; test.txt rclone copy test.txt ONEDRIVE:Documents/ . | . ",
    "url": "/docs/to_be_sorted/2022-03-01-post-0074.html",
    "relUrl": "/docs/to_be_sorted/2022-03-01-post-0074.html"
  },"74": {
    "doc": "Shotgun Sequencing of Amplicon Sequence, 220305",
    "title": "Shotgun Sequencing of Amplicon Sequence, 220305",
    "content": "Dir: /home/groups/oroaklab/nishida/amplicon_220305 Run: /home/groups/oroaklab/nishida/amplicon_220305/run.txt . This describes how to find our desired edit from shotgun sequencing of amplicon sequence. In lieu of standard amplicon input, we are taking the reads, aligning to hg38, and using GATK’s Haplotype Caller to identify the changes. Reads are being treated as paired-end and as a side-note about half the reads can be merged by overlap. Since this is being done relative to hg38 and not a specific amplicon sequence we have to identify what we are looking for relative to the genome. The region of interest in TBR1 is here: . # with the desired editing being designated with a '-' # and the NHEJ region from G4 defined by '*' &gt;chr2:161,416,779-161,416,834 ref - GTTCCCGTACCCCG*GCCAGCACGGACCGG*CGCACCCCGCCTTCTCCATCGGCAGCC edit - GTTCCCGTACCCCG*GCCAGCACGGACCGG*CGCA-CCCGCCTTCTCCATCGGCAGCC . This makes 161,416,811 the site where ACCCC becomes ACCC which will show up as AC to A in the VCFs from Haplotype Caller. For each sample, the following output is provided: . | SAMPLE - Sample ID. | EDIT_T_OR_F - True if the variant 161416811 AC to A is called. False if otherwise. | DEPTH - The depth at 161416811 if EDIT_T_OR_F is True. NA if False. | ALT_DEPTH - The depth of the edit at 161416811 if EDIT_T_OR_F is True. NA if False. | EDIT_FREQ - ALT_DEPTH / DEPTH | NUM_VARS_IN_NHEJ_REGION - The number of other variants called in the NHEJ region, 161416793-161416808. | NUM_VARS_WITHIN_10_BP - The number of other variants called +/- 10bp from 161416811 (161416801-161416821). | NUM_VARS_WITHIN_25_BP - The number of other variants called +/- 25bp from 161416811 (161416786-161416836). | NUM_VARS_WITHIN_50_BP - The number of other variants called +/- 50bp from 161416811 (161416761-161416861). | READ_DEPTH_AT_161416811 - Number of reads at the site via GATK DepthOfCoverage (not going to be the same as the depths counted via Haplotype Caller due to local alignment) | . This output is copy+pasted below here. This indicates the edit was found in 62 of the 156 samples. It was also found in the NTC3 sample which I am assuming is a control so there might be issues. #SAMPLE EDIT_T_OR_F DEPTH ALT_DEPTH EDIT_FREQ NUM_VARS_IN_NHEJ_REGION NUM_VARS_WITHIN_10_BP NUM_VARS_WITHIN_25_BP NUM_VARS_WITHIN_50_BP READ_DEPTH_AT_161416811 100 FALSE NA NA NA 1 0 1 1 10296 101 FALSE NA NA NA 1 0 1 1 6196 102 TRUE 2782 908 0.326383896477354 0 0 0 0 6618 103 TRUE 2176 877 0.403033088235294 2 0 2 2 3364 104 TRUE 2892 1362 0.470954356846473 0 0 0 1 4995 105 FALSE NA NA NA 2 0 2 2 5074 106 TRUE 2697 1457 0.540229885057471 0 0 0 0 6571 107 TRUE 2793 1057 0.378446115288221 0 0 0 0 7373 108 FALSE NA NA NA 1 0 1 1 5867 109 TRUE 2738 1123 0.410153396639883 0 0 0 0 6667 110 FALSE NA NA NA 1 0 1 1 4203 111 FALSE NA NA NA 1 0 1 1 4760 112 FALSE NA NA NA 1 0 1 1 3917 113 TRUE 2827 1168 0.413158825610187 0 0 0 0 9585 114 FALSE NA NA NA 0 0 0 0 1927 115 TRUE 2579 1374 0.532764637456378 0 0 0 0 5415 116 TRUE 3050 914 0.299672131147541 0 0 0 1 8658 117 TRUE 2793 1314 0.47046186895811 0 0 0 0 7584 118 FALSE NA NA NA 1 0 1 1 8982 119 FALSE NA NA NA 1 0 1 1 9123 120 FALSE NA NA NA 0 0 0 0 0 121 FALSE NA NA NA 1 0 1 1 7319 122 TRUE 2806 1297 0.462223806129722 0 0 0 0 7244 123 TRUE 2802 1235 0.440756602426838 0 0 0 0 7008 124 TRUE 2191 1994 0.910086718393428 0 0 0 0 3191 125 TRUE 2794 1191 0.426270579813887 0 0 0 0 7752 126 TRUE 2648 1064 0.401812688821752 0 0 0 0 5297 127 TRUE 2757 879 0.318824809575626 0 0 0 0 6590 128 TRUE 2674 1037 0.387808526551982 0 0 0 0 5252 129 FALSE NA NA NA 1 0 1 1 6935 130 TRUE 2614 1936 0.740627390971691 0 0 0 0 5507 131 TRUE 2638 1099 0.416603487490523 1 0 1 1 8718 132 FALSE NA NA NA 1 0 1 1 1 133 FALSE NA NA NA 3 1 3 3 7580 134 TRUE 2566 913 0.355806703039751 0 0 0 0 4057 135 FALSE NA NA NA 1 0 1 1 8615 136 FALSE NA NA NA 1 0 1 1 6476 137 TRUE 2772 754 0.272005772005772 0 0 0 0 7440 138 FALSE NA NA NA 1 0 1 1 3651 139 FALSE NA NA NA 1 0 1 1 6580 140 FALSE NA NA NA 2 0 2 2 60 141 FALSE NA NA NA 0 0 0 0 0 142 TRUE 2541 1668 0.656434474616293 2 0 2 2 6482 143 TRUE 3159 834 0.264007597340931 0 0 0 0 7610 144 TRUE 2837 1366 0.4814945364822 0 0 0 1 5891 145 FALSE NA NA NA 1 0 1 1 7478 146 FALSE NA NA NA 1 0 1 1 7069 147 FALSE NA NA NA 3 1 3 3 4833 148 FALSE NA NA NA 1 0 1 1 4689 149 FALSE NA NA NA 1 0 1 1 3455 150 TRUE 2832 1124 0.396892655367232 1 0 1 1 4757 151 FALSE NA NA NA 1 0 1 1 7004 152 TRUE 1700 1522 0.895294117647059 2 0 2 2 2767 153 TRUE 2832 1176 0.415254237288136 0 0 0 0 9232 154 FALSE NA NA NA 1 0 1 1 8615 155 FALSE NA NA NA 1 0 1 1 4943 156 FALSE NA NA NA 1 0 1 1 1483 157 FALSE NA NA NA 1 0 1 1 8740 158 FALSE NA NA NA 1 0 1 1 4472 159 FALSE NA NA NA 0 0 0 0 0 160 TRUE 143 89 0.622377622377622 0 0 0 0 93 161 TRUE 2278 2135 0.937225636523266 0 0 0 0 3544 162 FALSE NA NA NA 1 0 1 1 10034 163 FALSE NA NA NA 1 0 1 1 8007 164 FALSE NA NA NA 1 0 1 1 8149 165 FALSE NA NA NA 1 0 1 1 2059 166 TRUE 2050 1824 0.889756097560976 2 0 2 2 6024 167 FALSE NA NA NA 1 0 1 1 8825 168 FALSE NA NA NA 3 1 3 3 3551 169 TRUE 1531 398 0.259960809928152 0 0 0 0 1461 170 FALSE NA NA NA 2 0 2 2 2909 171 FALSE NA NA NA 1 0 1 1 7104 172 TRUE 1775 555 0.312676056338028 1 0 1 1 2754 173 TRUE 2795 1408 0.503756708407871 2 0 2 2 8365 174 FALSE NA NA NA 1 0 1 1 4731 175 TRUE 2331 686 0.294294294294294 1 0 1 1 8228 176 FALSE NA NA NA 0 0 0 0 7518 177 TRUE 2382 985 0.413518052057095 0 0 0 0 4829 178 FALSE NA NA NA 3 1 3 3 3881 179 TRUE 2827 1336 0.472585779978776 0 0 0 0 8273 180 TRUE 2283 2001 0.876478318002628 2 0 2 2 6998 181 FALSE NA NA NA 1 0 1 1 5274 182 FALSE NA NA NA 0 0 0 0 132 183 FALSE NA NA NA 0 0 0 0 88 184 FALSE NA NA NA 2 0 2 2 6233 185 TRUE 2740 1786 0.651824817518248 0 0 0 0 7204 186 FALSE NA NA NA 3 1 3 3 3485 187 FALSE NA NA NA 3 1 3 3 5168 188 TRUE 2789 1109 0.39763356041592 0 0 0 0 8810 189 FALSE NA NA NA 2 1 3 3 7601 190 TRUE 2770 1361 0.491335740072202 0 0 0 0 7554 191 FALSE NA NA NA 1 0 1 1 5427 192 TRUE 2149 1926 0.896230805025593 0 0 0 0 2857 193 FALSE NA NA NA 1 0 1 1 596 194 FALSE NA NA NA 1 0 1 1 39 195 TRUE 212 92 0.433962264150943 0 0 0 0 153 196 TRUE 7 5 0.714285714285714 0 0 0 0 7 197 FALSE NA NA NA 1 0 1 1 32 198 TRUE 89 44 0.49438202247191 0 0 0 0 75 199 FALSE NA NA NA 1 0 1 1 250 200 FALSE NA NA NA 0 0 0 0 117 201 FALSE NA NA NA 1 0 1 1 39 202 FALSE NA NA NA 3 1 3 3 324 203 FALSE NA NA NA 0 0 0 0 0 204 TRUE 13 9 0.692307692307692 0 0 0 0 11 205 TRUE 477 125 0.262054507337526 0 0 0 0 314 206 FALSE NA NA NA 1 0 1 1 398 207 FALSE NA NA NA 1 0 1 1 258 208 TRUE 212 154 0.726415094339623 0 0 0 0 156 209 FALSE NA NA NA 1 0 1 1 12 210 FALSE NA NA NA 1 0 1 1 383 211 FALSE NA NA NA 0 0 0 0 1 212 FALSE NA NA NA 1 0 1 1 130 213 TRUE 17 10 0.588235294117647 2 1 2 3 16 214 FALSE NA NA NA 1 0 1 1 494 215 FALSE NA NA NA 0 0 0 0 107 216 FALSE NA NA NA 1 0 1 1 294 217 FALSE NA NA NA 1 0 1 1 105 218 TRUE 47 43 0.914893617021277 2 0 2 2 39 219 FALSE NA NA NA 1 0 1 1 150 220 TRUE 583 166 0.284734133790738 0 0 0 0 474 221 FALSE NA NA NA 1 0 1 1 200 222 TRUE 452 230 0.508849557522124 0 0 0 0 400 223 FALSE NA NA NA 0 0 0 0 394 224 FALSE NA NA NA 0 0 0 0 162 225 TRUE 441 398 0.90249433106576 0 0 0 0 347 226 TRUE 675 220 0.325925925925926 0 0 0 0 571 227 TRUE 55 39 0.709090909090909 0 0 0 0 38 228 FALSE NA NA NA 0 0 0 0 0 229 FALSE NA NA NA 3 1 3 3 19 230 FALSE NA NA NA 1 0 1 1 6 231 TRUE 311 142 0.456591639871383 2 0 2 2 226 232 FALSE NA NA NA 1 0 1 1 220 233 FALSE NA NA NA 1 0 1 1 194 234 TRUE 116 17 0.146551724137931 0 0 0 0 86 235 FALSE NA NA NA 0 0 0 0 0 236 FALSE NA NA NA 0 0 0 0 286 237 FALSE NA NA NA 1 0 1 1 281 238 FALSE NA NA NA 2 0 2 2 425 239 FALSE NA NA NA 0 0 0 0 0 240 TRUE 357 125 0.350140056022409 0 0 0 0 266 241 FALSE NA NA NA 1 0 1 1 123 242 FALSE NA NA NA 1 0 1 1 543 243 TRUE 186 155 0.833333333333333 0 0 0 1 169 244 FALSE NA NA NA 2 0 2 2 739 245 FALSE NA NA NA 1 0 1 1 256 246 FALSE NA NA NA 3 1 3 3 289 247 TRUE 245 60 0.244897959183673 0 0 0 0 163 97 FALSE NA NA NA 1 0 1 1 7129 98 FALSE NA NA NA 1 0 1 1 4407 99 TRUE 2542 526 0.206923682140047 1 0 1 1 7855 A136P TRUE 1003 348 0.346959122632104 0 0 0 0 890 CIRM87 FALSE NA NA NA 0 0 0 0 850 NTC1 FALSE NA NA NA 0 0 0 0 0 NTC2 FALSE NA NA NA 0 0 0 0 1 NTC3 TRUE 94 10 0.106382978723404 0 0 0 0 85 . Here is a list of all the variants/edit appearing more than once and their count. 62 chr2 161416811 AC A 61 chr2 161416756 GCGGCCACTGCTCCCAGTGCCATGTTCCCGTACCCCGGCCAGCA G 43 chr2 161416799 ACGGACCGGCGCAC *,A 17 chr2 161416582 G T 12 chr2 161416799 ACGGACCGGCGCAC A 11 chr2 161416796 AGCACGGACCGGC A 10 chr2 161416798 C CGCCG 9 chr2 161416800 CGG *,C 8 chr2 161416803 ACCGGCGCAC *,A 8 chr2 161416799 A C 7 chr2 161416994 C CGGTCATAG 6 chr2 161416796 AGCACGGACCGGCGCAC A 6 chr2 161416581 G T 5 chr2 161416799 ACGGACCGGCGCAC *,AGGCGCAC 5 chr2 161416782 CCCGTACCCCGGCCAGCA C 3 chr2 161416798 CACGG C 2 chr2 161416995 C T 2 chr2 161416994 C CGG 2 chr2 161416990 T TC 2 chr2 161416988 C CTCCACGGTCATAG 2 chr2 161416799 ACGGACCGGCGCAC A,CCGGACCGGCGCAC . ",
    "url": "/docs/to_be_sorted/2022-03-07-post-0075.html",
    "relUrl": "/docs/to_be_sorted/2022-03-07-post-0075.html"
  },"75": {
    "doc": "SPARK WES2 and WES3 List Inconsistencies",
    "title": "SPARK WES2 and WES3 List Inconsistencies",
    "content": "I have ~50 or so families that need to be redone in the multiplex quad lists which will require regeneration of those lists for both WES2 and WES3. There were two main issues. The first was that SPARK provides a sample file and a family file and there are contradictions between these two files. The second was that the family structures of some multiplex families becomes overly complex. I programatically tried to create the order of samples of FATHER, MOTHER, PROBAND, SIBLING but these more complex families require hand-annotation. This ends up being a problematic bug since there is no technical failure of any of the jobs but they end up in the wrong order and position so it wasn’t apparent that these were wrong until inspection at the end. Here is a list of the problems I found across all lists and what I am did and/or will do with them. There are issues in all the lists but the only ones that will require redoing are the MQ lists. The following families appeared labeled correctly but were ultimately missing files. They were dropped from the analysis and will remained dropped. WES2_ST - SF0190153 WES3_ST - SF0253552 . The following families were labeled Simplex Trio but none of the samples have ASD status. They were dropped and will remained dropped. WES3_ST - SF0358078, SF0351957, SF0344946, SF0321531, SF0283195, SF0253518, SF0200056, SF0171179, SF0171139, SF0166437, SF0148696, SF0141603, SF0122929, SF0120746, SF0084012, SF0067409 . The following families were labeled Simplex Quad but their ASD status has both children labeled with ASD suggesting they are Multiplex Quad. This is a direct inconsistency so I dropped them from the analysis and they will remain dropped. WES3_SQ - SF0350957, SF0348964, SF0340130, SF0166951, SF0143732 . The following families were labeled as Multiplex Quad but they have different and missing parents. I originally attempted to run them in the analysis but they obviously were not in any correct order due to missing parents so they will now be dropped. WES2_MQ - SF0053074, SF0073546, SF0164478, SF0167673, SF0205284, SF0213830, SF0241143, SF0176436 WES3_MQ - SF0300521, SF0305993, SF0319527, SF0320184, SF0332525, SF0341237, SF0353370, SF0356342, SF0358008, SF0360603, SF0360758, SF0370516 . The following families were labeled as Multiplex Quad but there is only a single member of the family with ASD. These likely seem to be truly multiplex at one time but now appear simplex due to samples being withdrawn (in many cases the family is named after a proband that is now not in the sample list). I attempted to run them in the analysis originally but their absent ASD status made me use the same sample for PROBAND and SIBLING so these need to be redone and will remain in the MQ lists. WES2_MQ - SF0098597, SF0098964, SF0106001, SF0130318, SF0130371, SF0149268, SF0152204, SF0159371, SF0161279, SF0188795, SF0199871, SF0214031, SF0226577, SF0237413, SF0242905 WES3_MQ - SF0074135, SF0074515, SF0155097, SF0193489, SF0207524, SF0258739, SF0272438, SF0275179, SF0283627, SF0299378, SF0302698, SF0305333, SF0319187, SF0326812, SF0331244, SF0334339, SF0335377, SF0335741, SF0336045, SF0337997, SF0342038, SF0344737, SF0348492, SF0352528, SF0353104, SF0356933, SF0359024, SF0364215 . The following families were labeled as Multiplex Quad with a single child and one parent being ASD. My code was not looking for these cases explicitly so they did not work. They will be redone and included with the MQ lists. WES2_MQ - SF0133991, SF0162300, SF0165487, SF0166107, SF0170398, SF0181224 WES3_MQ - SF0015593, SF0255352, SF0256311, SF0270752, SF0271749, SF0290684, SF0301815, SF0301902, SF0323745, SF0332469, SF0335332, SF0352810, SF0367074 . There were two 6+ member families that are now labeled “Multiplex Quad”. Presumably there were grandparent samples that were withdrawn bringing them back down to quads but the labels are all different due to the original presence of the grandparent samples. These were attempted but also not put in the correct order. They will be redone. WES3_MQ - SF0301871, SF0356076 . ",
    "url": "/docs/to_be_sorted/2022-03-19-post-0076.html",
    "relUrl": "/docs/to_be_sorted/2022-03-19-post-0076.html"
  },"76": {
    "doc": "scRNA-seq First Pass Pipeline - 220324_HB_Coassay_RNA",
    "title": "scRNA-seq First Pass Pipeline - 220324_HB_Coassay_RNA",
    "content": "Here is a rough, first pass processing pipeline for sc-RNAseq. In general, it works by turning the FASTQ into a BAM and adding the barcodes, UMIs, alignment, and annotation to that BAM. The purpose is creating a complete BAM that can then be filtered, de-duped, and counted on the fly. This means there’s only one single BAM with all the information and one can pull out what they need from it without having to go back steps. The broad steps are adapted from the following pipeline: https://github.com/epigen/scifiRNA-seq. Here are some issues with the technical side of the pipeline. | The barcodes are saved in the BC tag and the UMIs are saved in the XU tag. These are appropriate, standardized parent: to_be_sorted nav_order: 2 | Deduplication technically does what it is supposed to do, it looks at the combination of barcode+umi+annotatedGene and keeps only unique results. It is written in with just bash sort and uniq commands parsing the BAM. This is a nice shortcut but it is likely we will want to save an entirely new BAM for the purposes of visualization. | In this one test pass I am not filtering for alignment quality but this would be simple to add in with the samtools view command. | I ran deduplication with scitools rmdup and picard MarkDuplicates. There is a part of me that thinks scitools rmdup should just work for this but I would need to dig into why or why not more specifically. To get picard MarkDuplicates to be barcode and UMI aware I believe we would need to make a new tag that combines the two together. It’s worth testing this out and comparing but the existing solution works for now. | . Pipeline: . # setup cd /home/groups/oroaklab/nishida/test_scrna/test_scrna_mar29/ module load picard/2.26.2 module load STAR/2.7.9a module load subread/2.0.3 # link file ln -s /home/groups/oroaklab/demultiplex/220324_VH00711_12_AAAV7VKM5/220324_VH00711_12_AAAV7VKM5.scRNA.SL.220324_HB_Coassay_RNA.R1.fq.gz . FASTQ_FILE=\"220324_VH00711_12_AAAV7VKM5.scRNA.SL.220324_HB_Coassay_RNA.R1.fq.gz\" # transform FASTQs to unaligned single-read BAMS picard FastqToSam F1=$FASTQ_FILE OUTPUT=$FASTQ_FILE.bam SM=$FASTQ_FILE # move bc to BC tag and umi to XU tag samtools view -h $FASTQ_FILE.bam | awk '/^@/ {print;next} {N=split($1,n,\":\"); O=split(n[2],o,\"=\"); print $0 \"\\tBC:Z:\" n[1] \"\\tXU:Z:\" o[2]}' | samtools view -bS - &gt; temp.bam # STAR alignment of unaligned BAM to reference STAR --runThreadN 24 --genomeDir /home/groups/oroaklab/refs/STAR/hg38 --readFilesCommand samtools view -h --readFilesType SAM SE --readFilesIn temp.bam --outSAMtype BAM Unsorted --outFilterScoreMinOverLread 0 --outFilterMatchNminOverLread 0 --outFileNamePrefix aligned # sort samtools sort alignedAligned.out.bam -o alignedAligned.out.sort.bam # use subread's featurecounts to add in 'XT' parent: to_be_sorted nav_order: 2 featureCounts -a /home/groups/oroaklab/refs/STAR/Homo_sapiens.GRCh38.104.gtf -R BAM -g gene_id -Q 30 -s 0 -T 24 -o alignedAligned.out.sort.annot.bam alignedAligned.out.sort.bam # make sparse # open SAM, pull out columns, use only uniquely mapping annotated reads, strip labels, keep only unique combinations, remove UMI info, count, format to sparse samtools view alignedAligned.out.sort.bam.featureCounts.bam | cut -f 12,17,18,21 | awk '$1 == \"NH:i:1\" &amp;&amp; $4 != \"\"' | sed -e 's/..:Z://g' | sort | uniq | cut -f 2,4 | uniq -c | sed -e 's/^[ ]*//g' | awk '{print $3,$2,$1}' | tr ' ' '\\t' &gt; z.hg38.txt cat z.hg38.txt | cut -f 1 | sort -n | uniq &gt; sparse.hg38.rows cat z.hg38.txt | cut -f 2 | sort -n | uniq &gt; sparse.hg38.cols perl make_sparse.pl sparse.hg38.rows sparse.hg38.cols z.hg38.txt | sort -n -k 1,2 &gt; sparse.hg38.values # make fake rows with BED positions and not gene names to trick cistopics # cistopics on sparse matrix and plot scitools matrix-cistopic3 -X 220324_HB_Coassay_RNA.sparseMatrix.values scitools matrix-umap 220324_HB_Coassay_RNA.cistopic.50.matrix scitools matrix-pg 220324_HB_Coassay_RNA.cistopic.50.matrix scitools plot-dims -A 220324_HB_Coassay_RNA.cistopic.50.k50.pg.annot 220324_HB_Coassay_RNA.cistopic.50.UMAP.dims # for future reference... #scitools bam-rmdup -t 24 temp_tag.hg38Aligned.sorted.out.bam #picard MarkDuplicates I=temp_tag.hg38Aligned.sorted.out.bam REMOVE_DUPLICATES=true O=temp_tag.hg38Aligned.sorted.rmdup.out.bam M=rmdup_metrics.txt . Here are some metrics with the output which might identify some problems. In general, the amount of usable data at the end seems too low but I also don’t know all the expectations. | Uniquely aligning reads is high at ~80% | The number of reads that were even annotated was low. ~10M reads which is ~18% of the total. This includes every read too so also multi-mapping reads. The annotation currently does not include rRNA which might be where all the reads are going? | The number of annotated, uniquely mapping, and deduplicated reads is similarly low at less than 1 million reads. | . # number of initial reads $ zcat 220324_VH00711_12_AAAV7VKM5.scRNA.SL.220324_HB_Coassay_RNA.R1.fq.gz | wc -l | awk '{print $1/4}' 55,896,785 # alignment percentages $ cat alignedLog.final.out | grep \"%\" Uniquely mapped reads % | 79.59% Mismatch rate per base, % | 1.41% Deletion rate per base | 0.02% Insertion rate per base | 0.03% % of reads mapped to multiple loci | 18.33% % of reads mapped to too many loci | 1.80% % of reads unmapped: too many mismatches | 0.00% % of reads unmapped: too short | 0.00% % of reads unmapped: other | 0.28% % of chimeric reads | 0.00% # number of annotated reads $ cat alignedAligned.out.sort.annot.bam.summary | grep \"Assigned\" Assigned 9926854 # number of de-deduplicated annotated reads $ cat 220324_HB_Coassay_RNA.sparseMatrix.values | awk '{sum+=$3}END{print sum}' 603194 . And here is a shot of the data gone through dimensionality reduction with cistopics. There’s structure but a lot of messy, diverse clusters. I think the messiness makes sense given the extra sparseness of the matrix. UMAP of scRNA-seq . ",
    "url": "/docs/to_be_sorted/2022-04-03-post-0077.html",
    "relUrl": "/docs/to_be_sorted/2022-04-03-post-0077.html"
  },"77": {
    "doc": "Shotgun Sequencing of Amplicon Sequence, 220406",
    "title": "Shotgun Sequencing of Amplicon Sequence, 220406",
    "content": "Dir: /home/groups/oroaklab/nishida/amplicon_220406 Run: /home/groups/oroaklab/nishida/amplicon_220406/run.txt . This describes how to find our desired edit from shotgun sequencing of amplicon sequence. In lieu of standard amplicon input, we are taking the reads, aligning to hg38, and using GATK’s Haplotype Caller to identify the changes. Reads are being treated as paired-end and as a side-note about half the reads can be merged by overlap. The description of the reference creation, interpretation, and format of the summary is described here: first amplicon sequencing results. For each sample, the following output is provided: . | SAMPLE - Sample ID. | EDIT_T_OR_F - True if the variant 161416811 AC to A is called. False if otherwise. | DEPTH - The depth at 161416811 if EDIT_T_OR_F is True. NA if False. | ALT_DEPTH - The depth of the edit at 161416811 if EDIT_T_OR_F is True. NA if False. | EDIT_FREQ - ALT_DEPTH / DEPTH | NUM_VARS_IN_NHEJ_REGION - The number of other variants called in the NHEJ region, 161416793-161416808. | NUM_VARS_WITHIN_10_BP - The number of other variants called +/- 10bp from 161416811 (161416801-161416821). | NUM_VARS_WITHIN_25_BP - The number of other variants called +/- 25bp from 161416811 (161416786-161416836). | NUM_VARS_WITHIN_50_BP - The number of other variants called +/- 50bp from 161416811 (161416761-161416861). | READ_DEPTH_AT_161416811 - Number of reads at the site via GATK DepthOfCoverage (not going to be the same as the depths counted via Haplotype Caller due to local alignment) | . This output is copy+pasted below here. The edit was found in the A136P controls and all the other non-control samples with at least 1000 reads of coverage. It was also found in the HDR7_NTC control but it and the HDR6_NTC control had nearly no reads. #SAMPLE EDIT_T_OR_F DEPTH ALT_DEPTH EDIT_FREQ NUM_VARS_IN_NHEJ_REGION NUM_VARS_WITHIN_10_BP NUM_VARS_WITHIN_25_BP NUM_VARS_WITHIN_50_BP READ_DEPTH_AT_161416811 HDR6_A136P_Control TRUE 2648 1280 0.483383685800604 0 0 0 0 5652 HDR6_CIRM87 FALSE NA NA NA 0 0 0 0 6117 HDR6_NTC FALSE NA NA NA 0 0 0 0 16 HDR6_sg4_SYN88_1 TRUE 2721 1004 0.368981991914737 1 0 1 1 6791 HDR6_sg4_SYN88_2 TRUE 2772 1038 0.374458874458874 1 0 1 1 6219 HDR6_sg4_SYN88_3 TRUE 2708 974 0.359675036927622 1 0 1 1 5567 HDR6_sg4_WT88_1 TRUE 2794 1128 0.403722261989979 0 0 0 0 7411 HDR6_sg4_WT88_2 TRUE 2841 1019 0.358676522351285 0 0 0 0 6783 HDR6_sg4_WT88_3 TRUE 2798 959 0.342744817726948 0 0 0 0 6720 HDR7_A136P_Control TRUE 2768 1299 0.469291907514451 0 0 0 0 7322 HDR7_CIRM87 FALSE NA NA NA 0 0 0 0 5979 HDR7_NTC TRUE 49 27 0.551020408163265 0 0 0 0 30 HDR7_sg4M_SYN88_1 TRUE 2798 1245 0.444960686204432 0 0 0 0 7936 HDR7_sg4M_SYN88_2 TRUE 2795 1229 0.439713774597496 0 0 0 0 7049 HDR7_sg4M_SYN88_3 TRUE 2797 1256 0.449052556310332 0 0 0 0 7418 HDR7_sg4M_SYN88_4 TRUE 2814 1187 0.42181947405828 0 0 0 0 8328 HDR7_sg4M_WT88_1 TRUE 2760 1315 0.476449275362319 0 0 0 0 6757 HDR7_sg4M_WT88_2 TRUE 2706 1189 0.439393939393939 0 0 0 0 6162 HDR7_sg4M_WT88_3 TRUE 2708 1206 0.445347119645495 0 0 0 0 6155 HDR7_sg4M_WT88_4 TRUE 2758 1292 0.468455402465555 0 0 0 0 6581 HDR7_sg4_SYN88_1 TRUE 2813 1230 0.437255599004621 0 0 0 0 7298 HDR7_sg4_SYN88_2 TRUE 2735 1294 0.473126142595978 0 0 0 0 6037 HDR7_sg4_SYN88_3 TRUE 2682 1159 0.43214019388516 0 0 0 0 6421 HDR7_sg4_SYN88_4 TRUE 2790 1198 0.429390681003584 0 0 0 0 6627 HDR7_sg4_WT88_1 TRUE 2758 1237 0.448513415518492 0 0 0 0 8276 HDR7_sg4_WT88_2 TRUE 2853 1251 0.438485804416404 0 0 0 0 7712 HDR7_sg4_WT88_3 TRUE 1572 637 0.405216284987277 0 0 0 0 1715 HDR7_sg4_WT88_4 TRUE 2767 1310 0.473436935308999 0 0 0 0 7281 . Here is a list of all the variants/edit appearing more than once and their count. 25 chr2 161416811 AC A 5 chr2 161416993 ACCCAGC A 5 chr2 161416990 TC T 5 chr2 161416582 G T 3 chr2 161416794 C A 3 chr2 161416581 G T 2 chr2 161417380 G A 2 chr2 161416993 A AGGT . ",
    "url": "/docs/to_be_sorted/2022-04-06-post-0078.html",
    "relUrl": "/docs/to_be_sorted/2022-04-06-post-0078.html"
  },"78": {
    "doc": "SPARK WES2 and WES3 Outliers by Counts and Coverage",
    "title": "SPARK WES2 and WES3 Outliers by Counts and Coverage",
    "content": "These markdowns represent the data preparation and figure generation for identifying outliers. Coverages are merged across lists in a separate markdown. Markdowns: WES2_SQ Prep WES2_MQ Prep WES2_ST Prep WES3_SQ Prep WES3_MQ Prep WES3_ST Prep WES2_SQ Outlier Plots WES2_MQ Outlier Plots WES2_ST Outlier Plots WES3_SQ Outlier Plots WES3_MQ Outlier Plots WES3_ST Outlier Plots WES2 and WES3 Combined Coverage Plots . Relevant plots for outlier detection here: outlier figures. From the combination of the coverages, the lowest 0-5% of families in coverage came from the following lists showing the worse coverages in WES3: . # Num Families in Lowest Fifth-Tile by List WES2_MQ - 4, WES2_SQ - 2, WES2_ST - 9 WES3_MQ - 19, WES3_SQ - 52, WES3_ST - 38 . There were 32 outliers calls using the same count thresholds as the WES1 list. As contrast, the WES1 lists had only 10 outlying calls with ~33% more families. All family outliers by list and FRACTION annotation: . 6, MOSAIC_CHILD, WES2.MQ ## FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE ## 72 SF0158322 SIB 0.3928909 6 15.27141 ## 183 SF0075609 PRO 0.5239183 14 26.72173 ## 265 SF0151665 PRO 0.5931233 6 10.11594 ## 376 SF0202052 SIB 0.7676529 9 11.72405 1, MOSAIC_CHILD, WES3.ST ## FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE ## 357 SF0323152 PRO 0.7481966 74 98.90449 3, GERMLINE_CHILD, WES2.MQ ## FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE ## 4 SF0149123 SIB 0.1322793 2 15.11953 ## 6 SF0163256 SIB 0.1918058 10 52.13608 ## 342 SF0223942 SIB 0.7000389 77 109.99389 2, GERMLINE_CHILD, WES3.MQ ## FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE ## 2 SF0358698 SIB 0.0892429 5 56.02686 ## 230 SF0283718 SIB 0.6034980 59 97.76337 3, MOSAIC_PARENTAL_NONTRANS, WES2.SQ ## FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE ## 3 SF0170260 FA 0.2105921 3 14.24555 ## 29 SF0228054 FA 0.3018997 9 29.81122 ## 129 SF0153456 FA 0.6423237 27 42.03488 1, MOSAIC_PARENTAL_NONTRANS, WES2.MQ ## FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE ## 204 SF0181472 MO 0.5424785 39 71.89225 5, MOSAIC_PARENTAL_NONTRANS, WES2.ST ## FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE ## 11 SF0149922 FA 0.2254580 9 39.91874 ## 313 SF0199636 FA 0.4987807 82 164.40092 ## 580 SF0245361 MO 0.5896181 8 13.56810 ## 601 SF0161221 FA 0.5944195 8 13.45851 ## 1164 SF0151784 MO 0.7809484 57 72.98818 ## 1201 SF0042891 FA 0.7965546 23 28.87436 3, MOSAIC_PARENTAL_NONTRANS, WES3.SQ ## FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE ## 63 SF0336708 FA 0.2639459 4 15.15462 ## 78 SF0342265 MO 0.2768700 4 14.44721 ## 159 SF0324757 FA 0.3945041 2808 7117.79595 2, MOSAIC_PARENTAL_NONTRANS, WES2.MQ ## FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE ## 12 SF0350442 MO 0.1662686 2 12.02873 ## 20 SF0319187 MO 0.1995900 3 15.03081 5, MOSAIC_PARENTAL_NONTRANS, WES3.ST ## FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE ## 4 SF0360546 MO 0.1294841 7 54.06067 ## 28 SF0288445 MO 0.2055009 3 14.59847 ## 59 SF0197166 FA 0.2550314 100 392.10863 ## 104 SF0364547 MO 0.3277593 9 27.45917 ## 157 SF0363100 FA 0.3803137 7 18.40586 1, MOSAIC_PARENTAL_TRANS, WES3.MQ ## FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE ## 57 SF0369960 FA 0.3092882 2 6.466462 . ",
    "url": "/docs/to_be_sorted/2022-04-08-post-0079.html",
    "relUrl": "/docs/to_be_sorted/2022-04-08-post-0079.html"
  },"79": {
    "doc": "scRNA-seq Second Pass Pipeline - 220324_HB_Coassay_RNA",
    "title": "scRNA-seq Second Pass Pipeline - 220324_HB_Coassay_RNA",
    "content": "This describes a second pass at the processing pipeline for sc-RNAseq. The main changes from the first pass are the name changes to the parent: to_be_sorted nav_order: 2 . | built around snakemake paired with SLURM jobs | uses condaenvs instead of modules since they are on exacloud | uses XC, XM, XG parent: to_be_sorted nav_order: 2 | performs read adapter trimming | uses cellbender(?) for background removal | uses DropSeq tools(?) for cell calling (some method to choose cell filtering thresholds rather than arbitrary thresholds) | . # setup cd /home/groups/oroaklab/nishida/test_scrna/test_scrna_mar29/ module load picard/2.26.2 module load STAR/2.7.9a module load subread/2.0.3 # link file ln -s /home/groups/oroaklab/demultiplex/220324_VH00711_12_AAAV7VKM5/220324_VH00711_12_AAAV7VKM5.scRNA.SL.220324_HB_Coassay_RNA.R1.fq.gz . FASTQ_FILE=\"220324_VH00711_12_AAAV7VKM5.scRNA.SL.220324_HB_Coassay_RNA.R1.fq.gz\" # transform FASTQs to unaligned single-read BAMS time picard FastqToSam F1=$FASTQ_FILE OUTPUT=$FASTQ_FILE.bam SM=$FASTQ_FILE #real 9m41.929s # move bc to XC tag and umi to XM tag time samtools view -h $FASTQ_FILE.bam | awk '/^@/ {print;next} {N=split($1,n,\":\"); O=split(n[2],o,\"=\"); print $0 \"\\tXC:Z:\" n[1] \"\\tXM:Z:\" o[2]}' | samtools view -bS - &gt; temp.bam #real 7m11.938s # STAR alignment of unaligned BAM to reference time STAR --runThreadN 24 --genomeDir /home/groups/oroaklab/refs/STAR/hg38 --readFilesCommand samtools view -h --readFilesType SAM SE --readFilesIn temp.bam --outSAMtype BAM Unsorted --outFilterScoreMinOverLread 0 --outFilterMatchNminOverLread 0 --outFileNamePrefix aligned #real 7m16.440s # sort time samtools sort alignedAligned.out.bam -o alignedAligned.out.sort.bam #real 15m23.468s # use subread's featurecounts to add in 'XT' parent: to_be_sorted nav_order: 2 time featureCounts -a /home/groups/oroaklab/refs/STAR/Homo_sapiens.GRCh38.104.gtf -R BAM -g gene_id -Q 30 -s 0 -T 24 -o alignedAligned.out.sort.annot.bam alignedAligned.out.sort.bam #real 0m28.182s # open SAM, filter for Q, pull out columns, use only uniquely mapping annotated reads, strip labels QFILTER=\"20\" samtools view -q ${QFILTER} alignedAligned.out.sort.bam.featureCounts.bam | cut -f 12,17,18,21 | awk '$1 == \"NH:i:1\" &amp;&amp; $4 != \"\"' | awk '$1 == \"NH:i:1\" &amp;&amp; $4 != \"\"' | sed -e 's/..:Z://g' &gt; TEMP #real 2m21.242s # count cell info from TEMP file time perl count_cell_info.pl TEMP &gt; metrics_cell_counts.txt #real 0m15.108s # example header of output # CELL TOTAL_READS UNIQUE_UMIS UNIQUE_UMIS_ANNOTS PERCENT_UNIQ # CCGGTATCGTGGTACCGGCTAAGAGACT 7 7 7 100 # CCGGTATCGTCCAATTCCATGGTTCAGC 5142 328 352 6.84558537534033 # CCGGTATCGTATAATCGCGGTCATATAG 1354 163 165 12.1861152141802 # make sparse, keep only unique combinations, remove UMI info, count, format to sparse time cat TEMP | sort | uniq | cut -f 2,4 | uniq -c | sed -e 's/^[ ]*//g' | awk '{print $3,$2,$1}' | tr ' ' '\\t' &gt; TEMP2 #real 1m54.927s cat TEMP2 | cut -f 1 | sort -n | uniq &gt; 220324_HB_Coassay_RNA.sparseMatrix.rows # make list of cells to use UMI_PER_CELL_CUTOFF=100 UNIQ_PER_CUTOFF=10 cat metrics_cell_counts.txt | awk -v umicut=$UMI_PER_CELL_CUTOFF -v uniqcut=$UNIQ_PER_CUTOFF '$3 &gt; umicut &amp;&amp; $5 &lt; uniqcut' | cut -f 1 | sort -n &gt; 220324_HB_Coassay_RNA.sparseMatrix.cols # make sparse perl make_sparse.pl 220324_HB_Coassay_RNA.sparseMatrix.rows 220324_HB_Coassay_RNA.sparseMatrix.cols TEMP2 | sort -n -k 1,2 &gt; 220324_HB_Coassay_RNA.sparseMatrix.values # make fake rows with BED positions not gene names to trick cistopics mv 220324_HB_Coassay_RNA.sparseMatrix.rows 220324_HB_Coassay_RNA.sparseMatrix.rows_save cat /home/groups/oroaklab/refs/hg38/masterlistDHS/DHS_Index_and_Vocabulary_hg38_WM20190703.non_overlap.bed | head -n 20446 &gt; 220324_HB_Coassay_RNA.sparseMatrix.rows # cistopics on sparse matrix and plot scitools matrix-cistopic3 -X 220324_HB_Coassay_RNA.sparseMatrix.values scitools matrix-umap 220324_HB_Coassay_RNA.cistopic.30.matrix scitools matrix-pg 220324_HB_Coassay_RNA.cistopic.30.matrix scitools plot-dims -A 220324_HB_Coassay_RNA.cistopic.30.k50.pg.annot 220324_HB_Coassay_RNA.cistopic.30.UMAP.dims . And here is a shot of the data gone through dimensionality reduction with cistopics. Relatively cleaned up despite very few reads being used. UMAP of scRNA-seq . ",
    "url": "/docs/to_be_sorted/2022-04-11-post-0080.html",
    "relUrl": "/docs/to_be_sorted/2022-04-11-post-0080.html"
  },"80": {
    "doc": "scRNA-seq and scATAC-seq Data Analysis DREAM Challenge - Dataset 2 Data Generation",
    "title": "scRNA-seq and scATAC-seq Data Analysis DREAM Challenge - Dataset 2 Data Generation",
    "content": "Program Versions: . macs2 v2.1.1.20160309 samtools v1.10 bedtools v2.22.0 python v2.7.9 perl v5.16.3 R v3.5.1 . R Packages: . &gt; sessionInfo() R version 3.5.1 (2018-07-02) Platform: x86_64-pc-linux-gnu (64-bit) Running under: CentOS Linux 7 (Core) Matrix products: default BLAS: /home/groups/oroaklab/src/R/R-3.5.1/lib/libRblas.so LAPACK: /home/groups/oroaklab/src/R/R-3.5.1/lib/libRlapack.so locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] grid stats graphics grDevices utils datasets methods [8] base other attached packages: [1] ComplexHeatmap_1.20.0 Matrix_1.2-18 cisTopic_0.3.0 [4] Rphenograph_0.99.1 igraph_1.2.4.2 ggplot2_3.2.1 . STEP 1 - CALLING PEAKS INPUT FILE(s): full_dataset.bam, downsampled_40.bam OUTPUT FILE(s): full_dataset.peaks.bed, downsampled_40.peaks.bed . # call peaks, full $ time macs2 callpeak --keep-dup all -t full_dataset.bam -n test1 real 8m37.638s user 8m30.649s sys 0m10.417s # merge and filter peaks, full $ perl 01_filter_peaks.pl test1_peaks.narrowPeak test1 500 # call peaks, downsampled $ time macs2 callpeak --keep-dup all -t downsampled_40.bam -n test2 real 6m16.453s user 5m54.677s sys 0m7.381s # merge and filter peaks, downsampled $ perl 01.filter_peaks.pl test2_peaks.narrowPeak test2 500 $ md5sum *bed c18d03f4d22e6938202e9578b2086dad downsampled_40.500.bed 018e2e40df7f998d19df2f340bbb207c full_dataset.peaks.bed 018e2e40df7f998d19df2f340bbb207c test1.500.bed c18d03f4d22e6938202e9578b2086dad test2.500.bed . STEP 2 - MATRIX GENERATION INPUT FILE(s): downsampled_40.bam, downsampled_40.500.bed OUTPUT FILE(s): downsampled_40.500.counts.sparseMatrix.cols.gz, downsampled_40.500.counts.sparseMatrix.rows.gz, downsampled_40.500.counts.sparseMatrix.values.gz . time perl 02.make_count_matrix.pl downsampled_40.bam downsampled_40.500.bed test2 real 3m25.788s user 5m30.598s sys 0m8.572s $ zcat downsampled_40.500.counts.sparseMatrix.values.gz &gt; temp1 $ zcat test2.counts.sparseMatrix.values.gz &gt; temp2 $ md5sum temp* 708ad4f6aabbbfed78771e3bc29fd5da temp1 708ad4f6aabbbfed78771e3bc29fd5da temp2 . STEP 3 - DIMENSIONALITY REDUCTION WITH CISTOPICS3 INPUT FILE(s): downsampled_40.500.counts.sparseMatrix.values.gz OUTPUT FILE(s): downsampled_40.500.counts.cistopic.15.matrix, downsampled_40.500.counts.cistopic.20.matrix, downsampled_40.500.counts.cistopic.25.matrix . $ time Rscript downsampled_40.500.counts.cistopic.r real 29m28.503s user 29m16.418s sys 0m9.162s # not similar by md5sum . STEP 4 - CISTOPIC3 MATRIX TO UMAP DIMS INPUT FILE(s): downsampled_40.500.counts.cistopic.15.matrix, downsampled_40.500.counts.cistopic.20.matrix, downsampled_40.500.counts.cistopic.25.matrix OUTPUT FILE(s): downsampled_40.500.counts.cistopic.15.UMAP.dims, downsampled_40.500.counts.cistopic.20.UMAP.dims, downsampled_40.500.counts.cistopic.25.UMAP.dims . $ time Rscript downsampled_40.500.counts.cistopic.15.UMAP.R real 1m1.257s user 0m59.971s sys 0m1.055s $ time Rscript downsampled_40.500.counts.cistopic.20.UMAP.R real 1m0.584s user 0m59.771s sys 0m0.673s $ time Rscript downsampled_40.500.counts.cistopic.25.UMAP.R real 1m5.051s user 1m3.943s sys 0m0.939s # not similar by md5sum . STEP 5 - CLUSTERING WITH PHENOGRAPHS INPUT FILE(s): downsampled_40.500.counts.cistopic.15.matrix, downsampled_40.500.counts.cistopic.20.matrix, downsampled_40.500.counts.cistopic.25.matrix OUTPUT FILE(s): downsampled_40.500.counts.cistopic.15.k50.pg.annot, downsampled_40.500.counts.cistopic.20.k50.pg.annot, downsampled_40.500.counts.cistopic.25.k50.pg.annot . $ time Rscript test2.15.k50.phenograph.R real 0m24.443s user 0m23.771s sys 0m0.549s $ time Rscript test2.20.k50.phenograph.R real 0m26.302s user 0m25.649s sys 0m0.594s $ time Rscript test2.25.k50.phenograph.R real 0m25.757s user 0m25.171s sys 0m0.504s $ md5sum *annot af37ea4bec6586681b1c814c93a256ce downsampled_40.500.counts.cistopic.15.k50.pg.annot bedc6d7799fc618654e63450691cc9b7 downsampled_40.500.counts.cistopic.20.k50.pg.annot 4915ad625b38b70ac7d3f969c4159a97 downsampled_40.500.counts.cistopic.25.k50.pg.annot af37ea4bec6586681b1c814c93a256ce test2.15.k50.pg.annot bedc6d7799fc618654e63450691cc9b7 test2.20.k50.pg.annot 4915ad625b38b70ac7d3f969c4159a97 test2.25.k50.pg.annot . ",
    "url": "/docs/to_be_sorted/2022-04-21-post-0081.html",
    "relUrl": "/docs/to_be_sorted/2022-04-21-post-0081.html"
  },"81": {
    "doc": "SPARK Mosaic Index, 22-04-28",
    "title": "SPARK Mosaic Index, 22-04-28",
    "content": "Compiled Writing and Figures: Google Doc . High Confidence Lists: WES1, Mutliplex Quads, High Confidence Calls WES1, Simplex Quads, High Confidence Calls WES1, Simplex Trios, High Confidence Calls WES2, Mutliplex Quads, High Confidence Calls WES2, Simplex Quads, High Confidence Calls WES2, Simplex Trios, High Confidence Calls WES3, Mutliplex Quads, High Confidence Calls WES3, Simplex Quads, High Confidence Calls WES3, Simplex Trios, High Confidence Calls . Burden Lists: WES1, Multiplex Quads, High Confidence Calls WES1, Simplex Trios, High Confidence Calls WES1, Simplex Quads, High Confidence Calls WES2, Multiplex Quads, High Confidence Calls WES2, Simplex Trios, High Confidence Calls WES2, Simplex Quads, High Confidence Calls WES3, Multiplex Quads, High Confidence Calls WES3, Simplex Quads, High Confidence Calls WES3, Simplex Trios, High Confidence Calls . Full Lists: WES1, Multiplex Quads w/ Strict Test Filter, no Germline Parental WES1, Simplex Quads w/ Strict Test Filter, no Germline Parental WES1, Simplex Trios w/ Strict Test Filter, no Germline Parental WES2, Multiplex Quads w/ Strict Test Filter, no Germline Parental WES2, Simplex Quads w/ Strict Test Filter, no Germline Parental WES2, Simplex Trios w/ Strict Test Filter, no Germline Parental WES3, Multiplex Quads w/ Strict Test Filter, no Germline Parental WES3, Simplex Quads w/ Strict Test Filter, no Germline Parental WES3, Simplex Trios w/ Strict Test Filter, no Germline Parental WES1, Multiplex Quads w/ Strict Test Filter WES1, Simplex Quads w/ Strict Test Filter WES1, Simplex Trios w/ Strict Test Filter WES2, Multiplex Quads w/ Strict Test Filter WES2, Simplex Quads w/ Strict Test Filter WES2, Simplex Trios w/ Strict Test Filter WES3, Multiplex Quads w/ Strict Test Filter WES3, Simplex Quads w/ Strict Test Filter WES3, Simplex Trios w/ Strict Test Filter WES1, Multiplex Quads w/ Loose Filter WES1, Simplex Quads w/ Loose Filter WES1, Simplex Trios w/ Loose Filter WES2, Multiplex Quads w/ Loose Filter WES2, Simplex Quads w/ Loose Filter WES2, Simplex Trios w/ Loose Filter WES3, Multiplex Quads w/ Loose Filter WES3, Simplex Quads w/ Loose Filter WES3, Simplex Trios w/ Loose Filter . Markdowns: 00, Report Coverage Outliers 01, WES1, Multiplex Quad Pre-Filtering 01, WES1, Simplex Quad Pre-Filtering 01, WES1, Simplex Trio Pre-Filtering 01, WES2, Multiplex Quad Pre-Filtering 01, WES2, Simplex Quad Pre-Filtering 01, WES2, Simplex Trio Pre-Filtering 01, WES3, Multiplex Quad Pre-Filtering 01, WES3, Simplex Quad Pre-Filtering 01, WES3, Simplex Trio Pre-Filtering 02, WES1, Multiplex Quad Variant Count Outliers 02, WES1, Simplex Quad Variant Count Outliers 02, WES1, Simplex Trio Variant Count Outliers 02, WES2, Multiplex Quad Variant Count Outliers 02, WES2, Simplex Quad Variant Count Outliers 02, WES2, Simplex Trio Variant Count Outliers 02, WES3, Multiplex Quad Variant Count Outliers 02, WES3, Simplex Quad Variant Count Outliers 02, WES3, Simplex Trio Variant Count Outliers 03, WES1, Multiplex Quad HC and Burden Tables 03, WES1, Simplex Quad HC and Burden Tables 03, WES1, Simplex Trio HC and Burden Tables 03, WES2, Multiplex Quad HC and Burden Tables 03, WES2, Simplex Quad HC and Burden Tables 03, WES2, Simplex Trio HC and Burden Tables 03, WES3, Multiplex Quad HC and Burden Tables 03, WES3, Simplex Quad HC and Burden Tables 03, WES3, Simplex Trio HC and Burden Tables 04, Post-Hoc Cohort, IGV, and iWES Filter Lists 05, Joined Splice Distances 06, Joined Allele Frequencies . Reference Lists and Files: Final Families WES1 Table WES2 Table WES2 Table Info WES2 Family Info WES2 Spreadsheet WES3 Table WES3 Family Info WES3 Table Spreadsheet WES3 Family Spreadsheet iWES1 IDs Post-hoc Filter Sites Post-hoc Filter Families Probe Targets, Padded 10bp hg38 Loci Coverages Person to Role Ref SSC Mosaic List . IGV Shots: IGV Shots of High Confidence Sites . Joint Coverages: Genomic Joint Coverage, WES1 Multiplex Quads Genomic Joint Coverage, WES1 Simplex Quads Genomic Joint Coverage, WES1 Simplex Trios Genomic Joint Coverage, WES2 Multiplex Quads Genomic Joint Coverage, WES2 Simplex Quads Genomic Joint Coverage, WES2 Simplex Trios Genomic Joint Coverage, WES3 Multiplex Quads Genomic Joint Coverage, WES3 Simplex Quads Genomic Joint Coverage, WES3 Simplex Trios SSC Transformed Joint Coverage SSC Transformed Joint Coverage, ESS SCC Transformed Joint Coverage, EXINTOL Exintol Joint Coverage, WES1, Mutliplex Quads Exintol Joint Coverage, WES1, Simplex Quads Exintol Joint Coverage, WES1, Simplex Trio Exintol Joint Coverage, WES2, Mutliplex Quads Exintol Joint Coverage, WES2, Simplex Quads Exintol Joint Coverage, WES2, Simplex Trio Exintol Joint Coverage, WES3, Mutliplex Quads Exintol Joint Coverage, WES3, Simplex Quads Exintol Joint Coverage, WES3, Simplex Trio Essential Joint Coverage, WES1, Mutliplex Quads Exmid Joint Coverage, WES1, Mutliplex Quads Extol Joint Coverage, WES1, Mutliplex Quads Fusil Joint Coverage, WES1, Mutliplex Quads Essential Joint Coverage, WES1, Simplex Quads Exmid Joint Coverage, WES1, Simplex Quads Extol Joint Coverage, WES1, Simplex Quads Fusil Joint Coverage, WES1, Simplex Quads Essential Joint Coverage, WES1, Simplex Trios Exmid Joint Coverage, WES1, Simplex Trios Extol Joint Coverage, WES1, Simplex Trios Fusil Joint Coverage, WES1, Simplex Trios . Splice Distances: WES1, Multiplex Quads, High Confidence Calls WES1, Simplex Quads, High Confidence Calls WES1, Simplex Trios, High Confidence Calls WES2, Multiplex Quads, High Confidence Calls WES2, Simplex Quads, High Confidence Calls WES2, Simplex Trios, High Confidence Calls WES3, Multiplex Quads, High Confidence Calls WES3, Simplex Quads, High Confidence Calls WES3, Simplex Trios, High Confidence Calls . Annotations: Added dbNSFP Annotation Column Descriptions . ",
    "url": "/docs/to_be_sorted/2022-04-28-post-0082.html",
    "relUrl": "/docs/to_be_sorted/2022-04-28-post-0082.html"
  },"82": {
    "doc": "SPARK IGV HC List Screenshots, 2022",
    "title": "SPARK IGV HC List Screenshots, 2022",
    "content": "Dir: /home/groups/oroaklab/nishida/spark_mosaic/IGV_2022 Run: run.make_batches.txt . IGV screenshots for the high-confidence lists across WES1, WES2, and WES3 are here: AT THIS DROPBOX URL AT THIS DROPBOX COPIED LINK . There are nine Numbers spreadsheets in the folder, one for each of the lists. As a refresher to how the original set was manually annotated, we both only annotated the MOSAIC_CHILD calls and you created four specific categories for the ones that were removed. The categories are largely describing instances of indels and where they are found. There’s a slide on the post with examples of the four categories and your specific note added on to it. Examples of Four Annotation Categories . ",
    "url": "/docs/to_be_sorted/2022-05-03-post-0083.html",
    "relUrl": "/docs/to_be_sorted/2022-05-03-post-0083.html"
  },"83": {
    "doc": "Celsee and Docker Info",
    "title": "Celsee and Docker Info",
    "content": "Dir: /home/groups/oroaklab/nishida/celsee Run: notes.txt . Here is the copy of the steps for using Docker on our cluster and running the Celsee pipeline. You do need sudo privileges to run this and/or setup from ACC to get Docker running. Celsee Analysis Steps 1. Start Docker I would suggest not normally having Docker running in the background, only bring it up when you want to use it. Installed via convenience scripts. Theoretically(?) this is the only step that requires sudo privileges OR a sudo user to grant privileges to run Docker: `sudo usermod -aG docker lowensev`. $ sudo service docker start 2. Verify that Docker is running $ systemctl status docker 3. Import in the Celsee pipeline as a Docker image I have it just living in my directories. $ cd /home/groups/oroaklab/nishida/celsee/celsee_analysis $ bash import.sh 4. Verify that the image was imported $ docker images 5. Run Celsee pipeline - The output location is also used as a temp directory which is a problem. - But also Docker requires the drives be mounted into Docker and we can't mount anything in /home/groups/. Instead go to /tmp and copy everything over. - You also need sudo privileges to write the output (this is how it is in the manual and I still can't believe this). - When running as sudo, acc does weird things to group/user privileges so you need to copy EVERYTHING into the /tmp directory. - Copy over the config file, the fastqs, all reference files, and the entirety of the celsee-analysis script folder (I think you only need some of these copied but do everything to be safe). - Also, in the config file, the optional fields are actually required to run and FASTQ files MUST end with either '.fastq' or '.fastq.gz'. $ # move ALL files to a directory in /tmp $ sudo python3 run_celsee.py eve_test.config . output Human_GRCh38_genomeSAsparseD3 6. Copy output folder back to /home/groups and delete the /tmp directory 7. Remove the Celsee analysis pipeline image $ docker image rm celsee-analysis 8. And then shut down Docker (also needs sudo privileges) $ sudo service docker stop . ",
    "url": "/docs/to_be_sorted/2022-05-18-post-0084.html",
    "relUrl": "/docs/to_be_sorted/2022-05-18-post-0084.html"
  },"84": {
    "doc": "Example of HDR Processing via BWA Alignment",
    "title": "Example of HDR Processing via BWA Alignment",
    "content": "Dir: /home/groups/oroaklab/nishida/example_brooke_amplican Run: README.txt . This was a small demo sent to Brooke to go over how the amplicon analysis was performed outside of CRISPResso and amplican. CRISPresso was aligning reads improperly and this problem is addressed directly by the program, amplican. But in between the switch of these programs we independently made a few scripts to process the alignment cigars of the amplicons. These were compared to results from amplican and similar results were retrieved. I would suggest using amplican going forward but this goes over what we did in that liminal time. Here is the copy of the readme of instructions sent to Brooke. # Example of HDR processing via BWA alignment cd /home/groups/oroaklab/nishida/test_brooke # array of sample names array=(A136P-iPS2_sgRNA-4_Rep1 A136P-iPS2_sgRNA-4_Rep2 A136P-iPS2_sgRNA-4_Rep3 A136P-iPS2_sgRNA-3_Rep1 A136P-iPS2_sgRNA-3_Rep2 A136P-iPS2_sgRNA-3_Rep3 A136P-iPS2_A136P-WT_CON CIRM87_WT-WT_CON) # 1. Obtain your FASTQs for your samples # This directory has the FASTQ files from the sequencing run from 200215 for HDR after demultiplexing with 8 samples making 16 FASTQs fastq_dir=\"/home/groups/oroaklab/nishida/test_brooke/1_fastqs\" # 2. Merge paired FASTQs into a single FASTQ with PEAR merged_dir=\"/home/groups/oroaklab/nishida/test_brooke/2_merged\" for i in \"${array[@]}\" do /home/groups/oroaklab/src/PEAR/pear-0.9.6/pear -y 20G -j 4 -f $fastq_dir/split.$i.R1.fq.gz -r $fastq_dir/split.$i.R2.fq.gz -o $merged_dir/$i.merge.fq done # 3. Make a BWA index with just the desired reference sequence. reference=\"/home/groups/oroaklab/nishida/test_brooke/ref/ref_amp.fa\" bwa index $reference # 4. Align with BWA align_dir=\"/home/groups/oroaklab/nishida/test_brooke/3_alignment\" for i in \"${array[@]}\" do bwa mem $reference $merged_dir/$i.merge.fq.assembled.fastq &gt; $align_dir/$i.sam done # I make a little guide like with whitespaces in a text editor for reference and counting. AMPLICONREF GCTACCTCCTCTCTCAGTCCAGCCAGCCACAGTCTGCGGCCACTGCTCCCAGTGCCATGTTCCCGTACCCCGGCCAGCACGGACCGGCGCA-CCCGCCTTCTCCATCGGCAGCCCTAGCCGCTACATGGC EXAMPLE_MERGEDREAD GCTACCTCCTCTCTCAGTCCAGCCAGCCACAGTCTGCGGCCACTGCTCCCAGTGCCATGTTCCCGTACCCCGGCCAGCACGGACCGGCGCACCCCGCCTTCTGCATCGTCAGCGCTAGCCGCTACATGGC EXAMPLE_R1 GCTACCTCCTCTCTCAGTCCAGCCAGCCACAGTCTGCGGCCACTGCTCCCAGTGCCATGTTCCCGTACCCCGGC EXAMPLE_REVCOMP_R2 ATGTTCCCGTACCCCGGCCAGCACGGACCGGCGCACCCCGCCTTCTTCATCCTCAGCGCGAGCCGCTACATGGC BADQUALREGION_R2 GCCTTCTTCATCCTCAGCGCGAGCCGCTAC GUIDE3 AGTGCCATGTTCCCGTACCC GUIDE4 GCACGGACCGGCGCACCCCG GUIDE3_NHEJ_REGION TTCCCGTACCCCGGC GUIDE4_NHEJ_REGION GCCAGCACGGACCGG # 5. Summarize CIGARS and bin them into groups. The 7 following inputs go into the script and depend on the size of your reads, the guides used, location of the cutsite, etc. and you will want to edit these. # a. the SAM alignment file, i.e. A136P-iPS2_sgRNA-4_Rep1.sam # b. the number of bases that must match at the start, i.e. 20 means the first 20 bases must match for the sequence to be considered # c. start bp for a window for NHEJ, i.e. 50 means the window for NHEJ counting starts at 50 # d. stop bp for a window for NHEJ, i.e. 75 means the window for NHEJ counting ends at 75 # e. the position of the HDR site, i.e. 92 means the 92nd base is deleted # f. the size of deletions to ignore, i.e. 20 means a deletion of 20bp or larger will not be considered # g. the full literal pure HDR sequence, i.e. GCTACCTCCTCTCTCAGTCCAGCCAGCCACAGTCTGCGGCCACTGCTCCCAGTGCCATGTTCCCGTACCCCGGCCAGCACGGACCGGCGCACCCGCCTTCTCCATCGGCAGCCCTAGCCGCTACATGGC # guide 3 parameters for i in \"${array[@]}\" do perl /home/groups/oroaklab/nishida/test_brooke/hdr_parse_cigar.pl $align_dir/$i.sam 20 50 75 92 20 GCTACCTCCTCTCTCAGTCCAGCCAGCCACAGTCTGCGGCCACTGCTCCCAGTGCCATGTTCCCGTACCCCGGCCAGCACGGACCGGCGCACCCGCCTTCTCCATCGGCAGCCCTAGCCGCTACATGGC done &gt; summary_g3.txt # guide 4 parameters for i in \"${array[@]}\" do perl /home/groups/oroaklab/nishida/test_brooke/hdr_parse_cigar.pl $align_dir/$i.sam 20 72 87 92 20 GCTACCTCCTCTCTCAGTCCAGCCAGCCACAGTCTGCGGCCACTGCTCCCAGTGCCATGTTCCCGTACCCCGGCCAGCACGGACCGGCGCACCCGCCTTCTCCATCGGCAGCCCTAGCCGCTACATGGC done &gt; summary_g4.txt # I personally like to keep header information separate from the data itself so I append it to the file here. cat header.txt summary_g3.txt &gt; temp1; mv temp1 summary_g3.txt cat header.txt summary_g4.txt &gt; temp2; mv temp2 summary_g4.txt # The files, 'summary_g3.txt' and 'summary_g4.txt', would be files I would then pass off to you. # I run everything with both g3 and g4 parameters because the controls need to be evaluated under both different circumstances. Older amplicon sequencing directories with less coherent examples by date are: /home/groups/oroaklab/nishida/crispr_amplicon. ",
    "url": "/docs/to_be_sorted/2022-05-18-post-0085.html",
    "relUrl": "/docs/to_be_sorted/2022-05-18-post-0085.html"
  },"85": {
    "doc": "Cron Info for Automatically Running bcl2fastq",
    "title": "Cron Info for Automatically Running bcl2fastq",
    "content": "The cron job scheduler is currently setup on mccovey only. Sudo permissions would be required to set it up on bonds and mays if desired. This just involves fiddling with the files, /var/spool/cron/ and /etc/cron.allow. Here is the one cron job scheduled to look for new obnix runs. SHELL=/bin/bash 0 * * * * source /home/groups/oroaklab/Modules/default/init/bash; source /home/groups/oroaklab/nishida/cron/setup/profile; /home/groups/oroaklab/nishida/scripts/check_obnix.sh &gt; /home/groups/oroaklab/nishida/cron/check_obnix.cronlog . The 0 * * * * part signifies to run this at the top of every hour. The source /home/groups/oroaklab/Modules/default/init/bash; source /home/groups/oroaklab/nishida/cron/setup/profile part is needed to find the modules and setup a proper bash environment for the job. The last part, /home/groups/oroaklab/nishida/scripts/check_obnix.sh, is the script being run every hour. The comments should explain everything but it looks for new folders, validates the names, checks for the RTAcomplete.txt file, runs /home/groups/oroaklab/nishida/scripts/NextSeq2fastq (this should be identical to what is in the github but not what is hooked up to our module because I don’t have permissions to change the module), and validates it made the output. I had it make a lot of logs but it has been running without errors for months now so you can turn off some of the extra output going forward. # !/usr/bin/bash # get date DATE=$(date +\"%y%m%d_%H_%M\") # move to cron folder cd /home/groups/oroaklab/nishida/cron # check the last 5 directories created with the machine name ls -dt /home/groups/oroaklab/seq/obnix/* | head -n 5 | grep \"_VH00711_\" &gt; obnix.$DATE.check.txt # for each of the names... while read i; do # run name run=$(echo $i | sed -e 's/.*\\///g') # count underscore deliminated parts in name, should be four namecount=$(echo $i | sed -e 's/.*\\///g' | tr '_' '\\n' | wc -l) # second member of the name should be the machine, \"VH00711\" name=$(echo $i | sed -e 's/.*\\///g' | tr '_' '\\t' | cut -f 2) # if the name is valid... if [[ $name == 'VH00711' &amp;&amp; $namecount == '4' ]]; then # check for RTA.complete and absence of FASTQ folder if [[ -f \"/home/groups/oroaklab/seq/obnix/$run/RTAComplete.txt\" &amp;&amp; ! -d \"/home/groups/oroaklab/fastq/$run\" ]]; then # run sleep 600 # wait in case the RTA complete shows up earlier than it should echo -e \"Attempting to run NextSeq2fastq for $run\" &gt;&gt; obnix.$DATE.log perl /home/groups/oroaklab/nishida/scripts/NextSeq2fastq -N -R $run echo -e \"Finished running NextSeq2fastq for $run\" &gt;&gt; obnix.$DATE.log # check that backup was made if [[ ! -d \"/home/groups/oroakdata/fastq/$run\" ]]; then echo -e \"Backup FASTQ folder was not made. Check manually.\" &gt;&gt; obnix.$DATE.err fi fi fi done &lt; obnix.$DATE.check.txt # save for now #rm obnix.$DATE.check.txt . The only part that needs to change when someone takes over is just changing this directory to something of one’s own. The directory just holds the logs from the cron jobs. # move to cron folder cd /home/groups/oroaklab/nishida/cron . ",
    "url": "/docs/to_be_sorted/2022-05-18-post-0086.html",
    "relUrl": "/docs/to_be_sorted/2022-05-18-post-0086.html"
  },"86": {
    "doc": "SRA Download Info for 'TBR1 Regulates Autism Risk Genes in the Developing Neocortex'",
    "title": "SRA Download Info for 'TBR1 Regulates Autism Risk Genes in the Developing Neocortex'",
    "content": "Dir: /home/groups/oroaklab/nishida/marissa_tbr1_sra Run: run.txt . This is info for snagging some files from SRA/GEO related to TBR1 analysis. Copy of the run file with the references: . /home/groups/oroaklab/nishida/marissa_tbr1_sra # download sra dataset module load sra-toolkit/2.8.2 fastq-dump --split-files SRR2130305 fastq-dump --split-files SRR2130304 # mm9 bed file is from SRA # mm10 bed file is lifted over with 100% fidelity closest-features --dist --closest --delim '\\t' published_coordinates.mm10.bed /home/groups/oroaklab/refs/mm10/ensembl_tss/ensembl.mm10.tss.chr.bed | cut -f 1-4,8-10 &gt; published_coordinates.mm10.annotated.bed # https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE71384 # https://pubmed.ncbi.nlm.nih.gov/27325115/ ####### module load sra-toolkit/2.8.2 fastq-dump --split-files SRR12082772 fastq-dump --split-files SRR12082773 fastq-dump --split-files SRR12082774 . ",
    "url": "/docs/to_be_sorted/2022-05-18-post-0087.html",
    "relUrl": "/docs/to_be_sorted/2022-05-18-post-0087.html"
  },"87": {
    "doc": "SPARK Post-Hoc Cohort, IGV, and iWES Filter Lists",
    "title": "SPARK Post-Hoc Cohort, IGV, and iWES Filter Lists",
    "content": "Markdown: 04, Post-Hoc Cohort, IGV, and iWES Filter Lists . This describes the creation of the lists for post-hoc filtering of the high-confidence and burden lists. The criteria for removal include having a combined cohort count 3 or greater, flagged for removal by manual IGV inspection, or an absence of the downstream iWES lists. Post-hoc Filter Lists: Post-hoc Filter Sites Post-hoc Filter Families . ",
    "url": "/docs/to_be_sorted/2022-05-20-post-0088.html",
    "relUrl": "/docs/to_be_sorted/2022-05-20-post-0088.html"
  },"88": {
    "doc": "Final O'Roak Lab Data Locations",
    "title": "Final O'Roak Lab Data Locations",
    "content": "There are a few folders left on /home/exacloud/gscratch/radpantry. These are all copies of scripts, software, or empty folders that I do not have permission to delete. There is no data in any of these however and they can be deleted whenever. None of my files exist on lustre1. But I took down the sizes of the directories remaining on lustre1: /home/groups/oroaklab/nishida/dirsizes.lustre1.nov42021.txt. The only directory copied from lustre1 was the kruppd directory which is copied here: /home/groups/oroakdata/lustre1_kruppd. No other files of mine exist on /home/groups/oroakdata/. The largest sets of files available for deletion are the intermediate SPARK mosaic files, mpileups and coverages. These can be deleted for space whenever and can always be regenerated from the CRAMs. The WES1 locations are here: /home/groups/oroakdata/TEMP_SPARK. The WES2/3 locations are here: /home/groups/oroaklab/nishida/spark_mosaic/TEMP/. All of my files remain solely in: /home/groups/oroaklab/nishida/. There should be files with labels like run.txt that describe the provenance of the data in that directory. Nearly all of them should be represented in blog posts except for older directories that are for defunct projects. Here’s some more information about the parent: to_be_sorted nav_order: 2 - environment - These are directories with environments for use for other projects. If people are still using them they should copy or recreate them in their directories. These can eventually be deleted. - libraries - These are libraries I’ve maintained for use by other software. Again, if people are using these they should copy them for themselves but otherwise they can be deleted. - plasmid - An abanonded approach but the tarball of the processing is left there. - paternity - The output should be the Mendellian error tables and I’m pretty sure we finished fixing all the sample mixups. I know I sent Hadley a final summary but the Slack/email is too old to directly find. - ntd - These are all compressed by their sequence date and the last one was done by Sally and is a direct copy of her directory. - spark_validations - There are two folders of data from the NYGC. The output for these are the variant calls and IGV screenshots of the sites. Below is the full list of directories: . Directory Tag Size Notes amplicon_220305 amplicon 8.8G amplicon analysis using shotgun approach and variant calling amplicon_220406 amplicon 3.6G amplicon analysis using shotgun approach and variant calling ArchR libraries 251M complete ArchR libraries with input reading bugfix, likely obsolete now celsee environment 34G celsee and docker information for celsee analysis by Eve crispr_amplicon amplicon 130G old runs of amplicon sequencing by date using CRISPresso, parsing BWA CIGARs, amplican crispr_capture crisprcap 69G final output for crisprcapture paper cron environment 6.5K location for holding temp logs and environment for cron dirsizes.lustre1.nov42021.txt . sizes of files remaining on lustre1 dirsizes.oroaklab_nishida.may22_2022.txt . sizes of files in this directory env environment 1.7G miscellaneous python environments example_brooke_amplican amplicon 1.6G tutorial dataset sent to Brooke to describe amplicon processing fimo_scans motif 32G fimo scans across hg38 and mm10 github libraries 2.1M personal scitools-dev build, anything new has been included in the main scitools-dev branch happy environment 181M python environment for happy jupyter environment 1.1G jupyter notebook environment marissa_tbr1_sra tbr1 6.7G download of fastqs and beds from GEO, https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE71384 miniconda3 environment 6.8G personal miniconda install with nextstrain environments mosaic_confirmations_Project_FEL_13640_B01_NAN_Custom spark_validations 167G mosaic confirmation project with variant calls and IGV shots mosaic_confirmations_Project_FEL_13640_B01_NAN_Custom.2020-01-10 spark_validations 18G mosaic confirmation project with variant calls and IGV shots motifsim motif 38M attempt at defining motif families by pwm via motifsim nextseq_organization_may4 seq 88K records of the accounting checking nextseq runs between drives ntd ntd 209G tarballs of ntd analysis by sequence, last one was copied from Sally’s directories paternity_190726 paternity 17G first sequence run for checking paternity of samples via mendellian error paternity_200130 paternity 21G second and final sequence run for checking paternity of samples via mendellian error pilot24.deepmosaic_exacloud_results.tar.gz deepmosaic 6.7G tarball of deepmosaic modified source code and results from running on exacloud pilot24_deepmosaic_results deepmosaic 6.9G results and IGV shots for Anna’s rotation using deepmosaic plasmid_assembly.tar.gz plasmid 131M tarball of plasmid assembly attempt R_4.0.0_arsn libraries 4.2G split of the R 4.0.0 libraries for the purposes of monocle3 sc_dm6_tau dm6_tau 5.0G Eve’s DA results run on exacloud scitools_env environment 2.0G environment for scitools work scitools_tests scitools 254G misc. tests with scitools scripts seq 104K misc. personal scripts sc_tmp1 tbr1 162G ArchR and DA results from Marissa’s TBR1 SC data spark_mosaic SPARK 11T intermediate data from the spark mosaic analysis, the entire size comes solely the temporary mpileups and coverages ssc ssc 123G ssc MIP processing split by pools stamp motif 14M attempt at defining motif families by pwm via stamp taylor_ashg crisprcap 80G preliminary analysis done for Taylor’s presentation at ASHG taylor_vars crisprcap 117G initial pass at crispr-capture analysis test_scrna_mar29 scrna 39G test scrna pipeline . ",
    "url": "/docs/to_be_sorted/2022-05-20-post-0089.html",
    "relUrl": "/docs/to_be_sorted/2022-05-20-post-0089.html"
  },"89": {
    "doc": "Global Installs - Initial",
    "title": "Global Installs - Initial",
    "content": "Install major base installs (C libs, etc.) individually with sudo on ajani, liliana, nissa, and teferi. # general stuff, most for specific other software downstream sudo apt-get install emacs autoconf automake make gcc perl zlib1g-dev libbz2-dev liblzma-dev libcurl4-gnutls-dev libssl-dev gfortran tcl-dev libssl-dev libbz2-dev liblzma-dev libncurses5-dev libhdf5-dev xorg-dev git build-essential libreadline-dev libxml2-dev libgsl-dev libtiff-dev libharfbuzz-dev libfribidi-dev libopenblas-dev libcairo2-dev # set python as python3 symlink sudo apt install python-is-python3 # update sudo apt-get update . Install Modules. curl -LJO https://github.com/cea-hpc/modules/releases/download/v5.2.0/modules-5.2.0.tar.gz tar xfz modules-5.2.0.tar.gz mkdir modules-5.2.0-install cd modules-5.2.0/ ./configure --prefix=/home/groups/ravnica/src/Modules/modules-5.2.0-install --modulefilesdir=/home/groups/ravnica/modulefiles . Setup Modules individually on ajani, liliana, nissa, and teferi. This lets each of them find Modules. sudo ln -s /home/groups/ravnica/src/Modules/modules-5.2.0-install/init/profile.sh /etc/profile.d/modules.sh sudo ln -s /home/groups/ravnica/src/Modules/modules-5.2.0-install/init/profile.csh /etc/profile.d/modules.csh . Setup cron on teferi only. This seems already go to go on Ubuntu relative to centOS. # use sudo to add users to /etc/cron.allow: root, nishidaa, adey # but everybody seems allowed natively? . ",
    "url": "/docs/ravnica/2022-12-05-ravnica-global_install_initial.html",
    "relUrl": "/docs/ravnica/2022-12-05-ravnica-global_install_initial.html"
  },"90": {
    "doc": "Local Installs - Initial",
    "title": "Local Installs - Initial",
    "content": "Install cmake . tar xfz cmake-3.24.3.tar.gz cd cmake-3.24.3/ ./bootstrap --prefix=/home/groups/ravnica/src/cmake/cmake-3.24.3 make make install . Install boost . tar xfz boost_1_80_0.tar.gz cd boost_1_80_0 ./bootstrap.sh --prefix=/home/groups/ravnica/src/boost/boost_1_80_0 ./b2 install . Install bedtools . wget https://github.com/arq5x/bedtools2/releases/download/v2.29.1/bedtools-2.29.1.tar.gz tar -zxvf bedtools-2.29.1.tar.gz mv bedtools2/ bedtools2.29.1 cd bedtools2.29.1/ make . Install bedops . bzip2 -dk bedops_linux_x86_64-v2.4.41.tar.bz2 tar xf bedops_linux_x86_64-v2.4.41.tar rm bedops_linux_x86_64-v2.4.41.tar mkdir 2.4.41 mv bin 2.4.41 . Install samtools . bzip2 -dk samtools-1.16.1.tar.bz2 tar xf samtools-1.16.1.tar rm samtools-1.16.1.tar cd samtools-1.16.1 ./configure --prefix=/home/groups/ravnica/src/samtools/samtools-1.16.1 make make install . Install htslib . bzip2 -dk htslib-1.16.tar.bz2 tar xf htslib-1.16.tar rm htslib-1.16.tar cd htslib-1.16 ./configure --prefix=/home/groups/ravnica/src/htslib/htslib-1.16/ make make install . Install bcftools . bzip2 -dk bcftools-1.16.tar.bz2 tar xf bcftools-1.16.tar rm bcftools-1.16.tar cd bcftools-1.16 ./configure --prefix=/home/groups/ravnica/src/bcftools/bcftools-1.16 make make install . Install install sratoolkit . tar xfz sratoolkit.3.0.0-ubuntu64.tar.gz . Install subread . tar xfz subread-2.0.3-source.tar.gz cd subread-2.0.3-source/src make -f Makefile.Linux . Install STAR . wget https://github.com/alexdobin/STAR/archive/2.7.10b.tar.gz tar -xzf 2.7.10b.tar.gz cd STAR-2.7.10b/source make STAR . Install bwa, pulled nov14 from master branch 139f68f on Sep 22. There’s a bug with gcc versions that the tagged release cannot handle. git clone https://github.com/lh3/bwa.git mv bwa bwa-139f68f-0.7.17 cd bwa-139f68f-0.7.17 make . Install BLAST . tar xvf ncbi-blast-2.13.0+-src.tar.gz cd ncbi-blast-2.13.0+-src/c++ ./configure --prefix=/home/groups/ravnica/src/blast/ncbi-blast-2.13.0+-src make make install . Install kraken2 . tar xvf kraken2-2.1.2.tar.gz module load blast ./install_kraken2.sh /home/groups/ravnica/src/kraken/kraken2-2.1.2 . Install GMP . tar xf gmp-6.1.0.tar make make install . Install MPFR ./configure --prefix=/home/groups/ravnica/src/mpfr/mpfr-3.1.4 --with-gmp-build=/home/groups/ravnica/src/gmp/gmp-6.1.0 make make install . Install MPC . tar xf mpc-1.0.3.tar ./configure --prefix=/home/groups/ravnica/src/mpc/mpc-1.0.3 --with-gmp=/home/groups/ravnica/src/gmp/gmp-6.1.0 --with-mpfr=/home/groups/ravnica/src/mpfr/mpfr-3.1.4 make make install . Install this older version of gcc for bcl2fastq. tar xfz gcc-8.1.0.tar.gz ./configure --prefix=/home/groups/ravnica/src/gcc/gcc-8.1.0 --with-gmp=/home/groups/ravnica/src/gmp/gmp-6.1.0 --with-mpfr=/home/groups/ravnica/src/mpfr/mpfr-3.1.4 --with-mpc=/home/groups/ravnica/src/mpc/mpc-1.0.3 --disable-multilib --disable-libsanitizer make make install . Separetely install older cmake also for bcl2fastq. There’s a minor issue with the order in which the module should be loaded. I think it has to be done after bootstrapping, not before like on my notes. tar xfz cmake-2.8.9.tar.gz cd cmake-2.8.9/ module load gcc/8.1.0 export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:/home/groups/ravnica/src/gmp/gmp-6.1.0/lib:/home/groups/ravnica/src/mpfr/mpfr-3.1.4/lib:/home/groups/ravnica/src/mpc/mpc-1.0.3/lib:/home/groups/ravnica/src/gcc/gcc-8.1.0/lib64 ./bootstrap make make install . Install bcl2fastq. bcl2fastq will try to install its specific versions of cmake and boost. cmake-2.8.9 needs an older version of gcc so install separately. But let it install its own version of boost. Add an explicit path to C libraries since cmake-2.8.9 is needed but all its C libraries won’t work. tar xfz bcl2fastq2-v2.20.0.422-Source.tar.gz mv bcl2fastq bcl2fastq-v2.20.0.422 module load cmake/2.8.9 export C_INCLUDE_PATH=/usr/include/x86_64-linux-gnu ./src/configure --prefix=/home/groups/ravnica/src/bcl2fastq2/bcl2fastq2-v2.20.0.422 make make install . Install older autoconf . curl -O http://ftp.gnu.org/gnu/autoconf/autoconf-2.69.tar.gz tar zxvf autoconf-2.69.tar.gz cd autoconf-2.69 ./configure &amp;&amp; make &amp;&amp; sudo make install . Install pcre2 . tar xfz pcre2-10.40.tar.gz ./configure --prefix=\"\" make make install . Install Java . tar xfz openjdk-11.0.2_linux-x64_bin.tar.gz # that’s it . Install R, 4.2.2 . tar xfz R-4.2.2.tar.gz cd R-4.2.2/ module load pcre2/10.40 ./configure --prefix=\"/home/groups/ravnica/src/R/R-4.2.2\" --with-cairo --with-libpng --with-libtiff --with-jpeglib make make install . Install R, 4.2.1 . tar xfz R-4.2.1.tar.gz cd R-4.2.1/ module load pcre2/10.40 ./configure --prefix=\"/home/groups/ravnica/src/R/R-4.2.1\" --with-cairo --with-libpng --with-libtiff --with-jpeglib make make install . Install JAGS . tar xfz JAGS-4.3.1.tar.gz cd JAGS-4.3.1 ./configure --prefix=\"/home/groups/ravnica/src/jags/JAGS-4.3.1\" make make install . ",
    "url": "/docs/ravnica/2022-12-05-ravnica-local_install_initial.html",
    "relUrl": "/docs/ravnica/2022-12-05-ravnica-local_install_initial.html"
  },"91": {
    "doc": "Mamba Install - Initial",
    "title": "Mamba Install - Initial",
    "content": "Install mambaforge . cd /home/groups/ravnica/src/mamba bash Mambaforge-Linux-x86_64.sh conda config --set auto_activate_base false # restart shell # set envs_dirs, pkgs_dirs, and channel and other stuff in global mambarc mamba update --all mamba info # check this . mamba info should look like this: . active environment : None shell level : 0 user config file : /home/users/nishidaa/.condarc populated config files : /home/groups/ravnica/src/mamba/mambaforge/.condarc conda version : 22.9.0 conda-build version : not installed python version : 3.10.7.final.0 virtual packages : __linux=5.15.0=0 __glibc=2.35=0 __unix=0=0 __archspec=1=x86_64 base environment : /home/groups/ravnica/src/mamba/mambaforge (writable) conda av data dir : /home/groups/ravnica/src/mamba/mambaforge/etc/conda conda av metadata url : None channel URLs : https://conda.anaconda.org/conda-forge/linux-64 https://conda.anaconda.org/conda-forge/noarch https://conda.anaconda.org/bioconda/linux-64 https://conda.anaconda.org/bioconda/noarch https://repo.anaconda.com/pkgs/main/linux-64 https://repo.anaconda.com/pkgs/main/noarch https://repo.anaconda.com/pkgs/r/linux-64 https://repo.anaconda.com/pkgs/r/noarch package cache : /home/groups/ravnica/src/mamba/mambaforge/pkgs envs directories : /home/groups/ravnica/env /home/groups/ravnica/src/mamba/mambaforge/envs /home/users/nishidaa/.conda/envs platform : linux-64 user-agent : conda/22.9.0 requests/2.28.1 CPython/3.10.7 Linux/5.15.0-52-generic ubuntu/22.04.1 glibc/2.35 UID:GID : 5417:3010 netrc file : None offline mode : False . Set up scitools py env in a slightly older version of python so all the libraries are actually found. mamba create --name scitools python=\"3.9\" mamba activate scitools mamba install numpy mamba install scipy mamba install pandas mamba install jupyter mamba install git mamba install matplotlib mamba install exrex mamba install seaborn mamba install pysam mamba install Cython mamba install zarr mamba install pybedtools mamba install bx-python mamba install tensorflow mamba install snakemake mamba install macs2 mamba update --all . ",
    "url": "/docs/ravnica/2022-12-05-ravnica-mamba_install_initial.html",
    "relUrl": "/docs/ravnica/2022-12-05-ravnica-mamba_install_initial.html"
  },"92": {
    "doc": "Mamba Setup",
    "title": "Mamba Setup",
    "content": ". | Initialize mamba: /home/groups/ravnica/src/mamba/mambaforge/bin/mamba init bash | Restart your shell. | Check mamba info. It should look something like this with your username replacing mine ‘nishidaa’. active environment : None shell level : 0 user config file : /home/users/nishidaa/.condarc populated config files : /home/groups/ravnica/src/mamba/mambaforge/.condarc conda version : 22.9.0 conda-build version : not installed python version : 3.10.7.final.0 virtual packages : __linux=5.15.0=0 __glibc=2.35=0 __unix=0=0 __archspec=1=x86_64 base environment : /home/groups/ravnica/src/mamba/mambaforge (writable) conda av data dir : /home/groups/ravnica/src/mamba/mambaforge/etc/conda conda av metadata url : None channel URLs : https://conda.anaconda.org/conda-forge/linux-64 https://conda.anaconda.org/conda-forge/noarch https://conda.anaconda.org/bioconda/linux-64 https://conda.anaconda.org/bioconda/noarch https://repo.anaconda.com/pkgs/main/linux-64 https://repo.anaconda.com/pkgs/main/noarch https://repo.anaconda.com/pkgs/r/linux-64 https://repo.anaconda.com/pkgs/r/noarch package cache : /home/groups/ravnica/src/mamba/mambaforge/pkgs envs directories : /home/groups/ravnica/env /home/groups/ravnica/src/mamba/mambaforge/envs /home/users/nishidaa/.conda/envs platform : linux-64 user-agent : conda/22.9.0 requests/2.28.1 CPython/3.10.7 Linux/5.15.0-52-generic ubuntu/22.04.1 glibc/2.35 UID:GID : 5417:3010 netrc file : None offline mode : False . | Try loading an environment: mamba activate scitools. | Deactivate: mamba deactivate. | . ",
    "url": "/docs/ravnica/2022-12-05-ravnica-mamba_setup.html",
    "relUrl": "/docs/ravnica/2022-12-05-ravnica-mamba_setup.html"
  },"93": {
    "doc": "R 4.2.2 Library Info",
    "title": "R 4.2.2 Library Info",
    "content": "I installed libraries in R either through CRAN or Bioconductor. These base libraries were chosen to fulfill a contemporary processing downstream analysis pipeline that Ryan uses for scATAC-seq. These were then copied to /home/groups/ravnica/env/R_library_backups/R-4.2.2_copy and set to write-only. This represents a frozen set of libraries that one could use. I’d suggest people copy these to a new environment directory or their own working directory and build on top of them rather than installing directly into the main R library location. But you are otherwise free to install libraries with R however individually desired. R will find libraries on this path: . export R_LIBS_USER='/home/groups/ravnica/env/R_library_backups/R-4.2.2_copy' . R will then use the default path AND the new path. If you want to make sure something installs only to your path you should set it to just your path and check to make sure only your path shows up. # check path to make sure it only shows up $ .libPaths() ... # assign a single specific path $ assign(\".lib.loc\", \"/home/groups/ravnica/env/R_library_backups/R-4.2.2_copy\", envir = environment(.libPaths)) # check path to make sure it only shows up $ .libPaths() . The libraries for the pipeline are: . # major library(ArchR) library(Seurat) library(SeuratWrappers) library(Signac) library(chromVAR) library(ggplot2) library(cisTopic) library(infercnv) # minor library(grid) library(patchwork) library(reshape2) library(parallel) library(stringr) library(ggrepel) library(dplyr) library(viridis) library(Matrix) library(BiocParallel) library(SummarizedExperiment) library(AUCell) library(TFBSTools) # bio refs library(rtracklayer) library(GenomeInfoDb) library(EnsDb.Hsapiens.v86) library(org.Hs.eg.db) library(BSgenome.Hsapiens.UCSC.hg38) library(TxDb.Hsapiens.UCSC.hg38.knownGene) library(JASPAR2020) # extra plotting library(ggdendro) library(circlize) library(dendextend) library(dendsort) library(ComplexHeatmap) library(motifmatchr) . ",
    "url": "/docs/ravnica/2022-12-05-ravnica-r_4.2.2_library_info.html",
    "relUrl": "/docs/ravnica/2022-12-05-ravnica-r_4.2.2_library_info.html"
  },"94": {
    "doc": "Home",
    "title": "Home",
    "content": "HELLO! Search works well! ^^^ . ",
    "url": "/",
    "relUrl": "/"
  },"95": {
    "doc": "ravnica",
    "title": "ravnica",
    "content": " ",
    "url": "/docs/ravnica/",
    "relUrl": "/docs/ravnica/"
  },"96": {
    "doc": "to_be_sorted",
    "title": "to_be_sorted",
    "content": " ",
    "url": "/docs/to_be_sorted/",
    "relUrl": "/docs/to_be_sorted/"
  }
}
