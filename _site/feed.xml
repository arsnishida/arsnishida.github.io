<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-03-30T23:23:39-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">ARSN Lab Notebook</title><subtitle>ARSN Lab notebook.</subtitle><entry><title type="html">SPARK WES2 and WES3 List Inconsistencies</title><link href="http://localhost:4000/2022/03/19/post-0076.html" rel="alternate" type="text/html" title="SPARK WES2 and WES3 List Inconsistencies" /><published>2022-03-19T00:00:00-07:00</published><updated>2022-03-19T00:00:00-07:00</updated><id>http://localhost:4000/2022/03/19/post-0076</id><content type="html" xml:base="http://localhost:4000/2022/03/19/post-0076.html">&lt;p&gt;I have ~50 or so families that need to be redone in the multiplex quad lists which will require regeneration of those lists for both WES2 and WES3. There were two main issues. The first was that SPARK provides a sample file and a family file and there are contradictions between these two files. The second was that the family structures of some multiplex families becomes overly complex. I programatically tried to create the order of samples of FATHER, MOTHER, PROBAND, SIBLING but these more complex families require hand-annotation. This ends up being a problematic bug since there is no technical failure of any of the jobs but they end up in the wrong order and position so it wasn’t apparent that these were wrong until inspection at the end.&lt;/p&gt;

&lt;p&gt;Here is a list of the problems I found across all lists and what I am did and/or will do with them. There are issues in all the lists but the only ones that will require redoing are the MQ lists.&lt;/p&gt;

&lt;p&gt;The following families appeared labeled correctly but were ultimately missing files. They were dropped from the analysis and will remained dropped.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;WES2_ST - SF0190153
WES3_ST - SF0253552
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The following families were labeled Simplex Trio but none of the samples have ASD status. They were dropped and will remained dropped.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;WES3_ST - SF0358078, SF0351957, SF0344946, SF0321531, SF0283195, SF0253518, SF0200056, SF0171179, SF0171139, SF0166437, SF0148696, SF0141603, SF0122929, SF0120746, SF0084012, SF0067409
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The following families were labeled Simplex Quad but their ASD status has both children labeled with ASD suggesting they are Multiplex Quad. This is a direct inconsistency so I dropped them from the analysis and they will remain dropped.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;WES3_SQ - SF0350957, SF0348964, SF0340130, SF0166951, SF0143732
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The following families were labeled as Multiplex Quad but they have different and missing parents. I originally attempted to run them in the analysis but they obviously were not in any correct order due to missing parents so they will now be dropped.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;WES2_MQ - SF0053074, SF0073546, SF0164478, SF0167673, SF0205284, SF0213830, SF0241143, SF0176436
WES3_MQ - SF0300521, SF0305993, SF0319527, SF0320184, SF0332525, SF0341237, SF0353370, SF0356342, SF0358008, SF0360603, SF0360758, SF0370516
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The following families were labeled as Multiplex Quad but there is only a single member of the family with ASD. These likely seem to be truly multiplex at one time but now appear simplex due to samples being withdrawn (in many cases the family is named after a proband that is now not in the sample list). I attempted to run them in the analysis originally but their absent ASD status made me use the same sample for PROBAND and SIBLING so these need to be redone and will remain in the MQ lists.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;WES2_MQ - SF0098597, SF0098964, SF0106001, SF0130318, SF0130371, SF0149268, SF0152204, SF0159371, SF0161279, SF0188795, SF0199871, SF0214031, SF0226577, SF0237413, SF0242905
WES3_MQ - SF0074135, SF0074515, SF0155097, SF0193489, SF0207524, SF0258739, SF0272438, SF0275179, SF0283627, SF0299378, SF0302698, SF0305333, SF0319187, SF0326812, SF0331244, SF0334339, SF0335377, SF0335741, SF0336045, SF0337997, SF0342038, SF0344737, SF0348492, SF0352528, SF0353104, SF0356933, SF0359024, SF0364215
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The following families were labeled as Multiplex Quad with a single child and one parent being ASD. My code was not looking for these cases explicitly so they did not work. They will be redone and included with the MQ lists.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;WES2_MQ - SF0133991, SF0162300, SF0165487, SF0166107, SF0170398, SF0181224
WES3_MQ - SF0015593, SF0255352, SF0256311, SF0270752, SF0271749, SF0290684, SF0301815, SF0301902, SF0323745, SF0332469, SF0335332, SF0352810, SF0367074
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There were two 6+ member families that are now labeled “Multiplex Quad”. Presumably there were grandparent samples that were withdrawn bringing them back down to quads but the labels are all different due to the original presence of the grandparent samples. These were attempted but also not put in the correct order. They will be redone.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;WES3_MQ - SF0301871, SF0356076
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><category term="SPARK" /><summary type="html">I have ~50 or so families that need to be redone in the multiplex quad lists which will require regeneration of those lists for both WES2 and WES3. There were two main issues. The first was that SPARK provides a sample file and a family file and there are contradictions between these two files. The second was that the family structures of some multiplex families becomes overly complex. I programatically tried to create the order of samples of FATHER, MOTHER, PROBAND, SIBLING but these more complex families require hand-annotation. This ends up being a problematic bug since there is no technical failure of any of the jobs but they end up in the wrong order and position so it wasn’t apparent that these were wrong until inspection at the end.</summary></entry><entry><title type="html">Shotgun Sequencing of Amplicon Sequence, 220305</title><link href="http://localhost:4000/2022/03/07/post-0075.html" rel="alternate" type="text/html" title="Shotgun Sequencing of Amplicon Sequence, 220305" /><published>2022-03-07T00:00:00-08:00</published><updated>2022-03-07T00:00:00-08:00</updated><id>http://localhost:4000/2022/03/07/post-0075</id><content type="html" xml:base="http://localhost:4000/2022/03/07/post-0075.html">&lt;p&gt;Dir: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/amplicon_220305&lt;/code&gt;
&lt;br /&gt;Run: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/amplicon_220305/run.txt&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This describes how to find our desired edit from shotgun sequencing of amplicon sequence. In lieu of standard amplicon input, we are taking the reads, aligning to hg38, and using GATK’s Haplotype Caller to identify the changes. Reads are being treated as paired-end and as a side-note about half the reads can be merged by overlap.&lt;/p&gt;

&lt;p&gt;Since this is being done relative to hg38 and not a specific amplicon sequence we have to identify what we are looking for relative to the genome. The region of interest in TBR1 is here:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# with the desired editing being designated with a '-'
# and the NHEJ region from G4 defined by '*'
&amp;gt;chr2:161,416,779-161,416,834
ref  - GTTCCCGTACCCCG*GCCAGCACGGACCGG*CGCACCCCGCCTTCTCCATCGGCAGCC
edit - GTTCCCGTACCCCG*GCCAGCACGGACCGG*CGCA-CCCGCCTTCTCCATCGGCAGCC
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This makes 161,416,811 the site where ACCCC becomes ACCC which will show up as AC to A in the VCFs from Haplotype Caller.&lt;/p&gt;

&lt;p&gt;For each sample, the following output is provided:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;SAMPLE - Sample ID.&lt;/li&gt;
  &lt;li&gt;EDIT_T_OR_F - True if the variant 161416811 AC to A is called. False if otherwise.&lt;/li&gt;
  &lt;li&gt;DEPTH - The depth at 161416811 if EDIT_T_OR_F is True. NA if False.&lt;/li&gt;
  &lt;li&gt;ALT_DEPTH - The depth of the edit at 161416811 if EDIT_T_OR_F is True. NA if False.&lt;/li&gt;
  &lt;li&gt;EDIT_FREQ - ALT_DEPTH / DEPTH&lt;/li&gt;
  &lt;li&gt;NUM_VARS_IN_NHEJ_REGION - The number of other variants called in the NHEJ region, 161416793-161416808.&lt;/li&gt;
  &lt;li&gt;NUM_VARS_WITHIN_10_BP - The number of other variants called +/- 10bp from 161416811 (161416801-161416821).&lt;/li&gt;
  &lt;li&gt;NUM_VARS_WITHIN_25_BP - The number of other variants called +/- 25bp from 161416811 (161416786-161416836).&lt;/li&gt;
  &lt;li&gt;NUM_VARS_WITHIN_50_BP - The number of other variants called +/- 50bp from 161416811 (161416761-161416861).&lt;/li&gt;
  &lt;li&gt;READ_DEPTH_AT_161416811 - Number of reads at the site via GATK DepthOfCoverage (not going to be the same as the depths counted via Haplotype Caller due to local alignment)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This output is copy+pasted below here. This indicates the edit was found in 62 of the 156 samples. It was also found in the NTC3 sample which I am assuming is a control so there might be issues.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#SAMPLE	EDIT_T_OR_F	DEPTH	ALT_DEPTH	EDIT_FREQ	NUM_VARS_IN_NHEJ_REGION	NUM_VARS_WITHIN_10_BP	NUM_VARS_WITHIN_25_BP	NUM_VARS_WITHIN_50_BP	READ_DEPTH_AT_161416811
100	FALSE	NA	NA	NA	1	0	1	1	10296
101	FALSE	NA	NA	NA	1	0	1	1	6196
102	TRUE	2782	908	0.326383896477354	0	0	0	0	6618
103	TRUE	2176	877	0.403033088235294	2	0	2	2	3364
104	TRUE	2892	1362	0.470954356846473	0	0	0	1	4995
105	FALSE	NA	NA	NA	2	0	2	2	5074
106	TRUE	2697	1457	0.540229885057471	0	0	0	0	6571
107	TRUE	2793	1057	0.378446115288221	0	0	0	0	7373
108	FALSE	NA	NA	NA	1	0	1	1	5867
109	TRUE	2738	1123	0.410153396639883	0	0	0	0	6667
110	FALSE	NA	NA	NA	1	0	1	1	4203
111	FALSE	NA	NA	NA	1	0	1	1	4760
112	FALSE	NA	NA	NA	1	0	1	1	3917
113	TRUE	2827	1168	0.413158825610187	0	0	0	0	9585
114	FALSE	NA	NA	NA	0	0	0	0	1927
115	TRUE	2579	1374	0.532764637456378	0	0	0	0	5415
116	TRUE	3050	914	0.299672131147541	0	0	0	1	8658
117	TRUE	2793	1314	0.47046186895811	0	0	0	0	7584
118	FALSE	NA	NA	NA	1	0	1	1	8982
119	FALSE	NA	NA	NA	1	0	1	1	9123
120	FALSE	NA	NA	NA	0	0	0	0	0
121	FALSE	NA	NA	NA	1	0	1	1	7319
122	TRUE	2806	1297	0.462223806129722	0	0	0	0	7244
123	TRUE	2802	1235	0.440756602426838	0	0	0	0	7008
124	TRUE	2191	1994	0.910086718393428	0	0	0	0	3191
125	TRUE	2794	1191	0.426270579813887	0	0	0	0	7752
126	TRUE	2648	1064	0.401812688821752	0	0	0	0	5297
127	TRUE	2757	879	0.318824809575626	0	0	0	0	6590
128	TRUE	2674	1037	0.387808526551982	0	0	0	0	5252
129	FALSE	NA	NA	NA	1	0	1	1	6935
130	TRUE	2614	1936	0.740627390971691	0	0	0	0	5507
131	TRUE	2638	1099	0.416603487490523	1	0	1	1	8718
132	FALSE	NA	NA	NA	1	0	1	1	1
133	FALSE	NA	NA	NA	3	1	3	3	7580
134	TRUE	2566	913	0.355806703039751	0	0	0	0	4057
135	FALSE	NA	NA	NA	1	0	1	1	8615
136	FALSE	NA	NA	NA	1	0	1	1	6476
137	TRUE	2772	754	0.272005772005772	0	0	0	0	7440
138	FALSE	NA	NA	NA	1	0	1	1	3651
139	FALSE	NA	NA	NA	1	0	1	1	6580
140	FALSE	NA	NA	NA	2	0	2	2	60
141	FALSE	NA	NA	NA	0	0	0	0	0
142	TRUE	2541	1668	0.656434474616293	2	0	2	2	6482
143	TRUE	3159	834	0.264007597340931	0	0	0	0	7610
144	TRUE	2837	1366	0.4814945364822	0	0	0	1	5891
145	FALSE	NA	NA	NA	1	0	1	1	7478
146	FALSE	NA	NA	NA	1	0	1	1	7069
147	FALSE	NA	NA	NA	3	1	3	3	4833
148	FALSE	NA	NA	NA	1	0	1	1	4689
149	FALSE	NA	NA	NA	1	0	1	1	3455
150	TRUE	2832	1124	0.396892655367232	1	0	1	1	4757
151	FALSE	NA	NA	NA	1	0	1	1	7004
152	TRUE	1700	1522	0.895294117647059	2	0	2	2	2767
153	TRUE	2832	1176	0.415254237288136	0	0	0	0	9232
154	FALSE	NA	NA	NA	1	0	1	1	8615
155	FALSE	NA	NA	NA	1	0	1	1	4943
156	FALSE	NA	NA	NA	1	0	1	1	1483
157	FALSE	NA	NA	NA	1	0	1	1	8740
158	FALSE	NA	NA	NA	1	0	1	1	4472
159	FALSE	NA	NA	NA	0	0	0	0	0
160	TRUE	143	89	0.622377622377622	0	0	0	0	93
161	TRUE	2278	2135	0.937225636523266	0	0	0	0	3544
162	FALSE	NA	NA	NA	1	0	1	1	10034
163	FALSE	NA	NA	NA	1	0	1	1	8007
164	FALSE	NA	NA	NA	1	0	1	1	8149
165	FALSE	NA	NA	NA	1	0	1	1	2059
166	TRUE	2050	1824	0.889756097560976	2	0	2	2	6024
167	FALSE	NA	NA	NA	1	0	1	1	8825
168	FALSE	NA	NA	NA	3	1	3	3	3551
169	TRUE	1531	398	0.259960809928152	0	0	0	0	1461
170	FALSE	NA	NA	NA	2	0	2	2	2909
171	FALSE	NA	NA	NA	1	0	1	1	7104
172	TRUE	1775	555	0.312676056338028	1	0	1	1	2754
173	TRUE	2795	1408	0.503756708407871	2	0	2	2	8365
174	FALSE	NA	NA	NA	1	0	1	1	4731
175	TRUE	2331	686	0.294294294294294	1	0	1	1	8228
176	FALSE	NA	NA	NA	0	0	0	0	7518
177	TRUE	2382	985	0.413518052057095	0	0	0	0	4829
178	FALSE	NA	NA	NA	3	1	3	3	3881
179	TRUE	2827	1336	0.472585779978776	0	0	0	0	8273
180	TRUE	2283	2001	0.876478318002628	2	0	2	2	6998
181	FALSE	NA	NA	NA	1	0	1	1	5274
182	FALSE	NA	NA	NA	0	0	0	0	132
183	FALSE	NA	NA	NA	0	0	0	0	88
184	FALSE	NA	NA	NA	2	0	2	2	6233
185	TRUE	2740	1786	0.651824817518248	0	0	0	0	7204
186	FALSE	NA	NA	NA	3	1	3	3	3485
187	FALSE	NA	NA	NA	3	1	3	3	5168
188	TRUE	2789	1109	0.39763356041592	0	0	0	0	8810
189	FALSE	NA	NA	NA	2	1	3	3	7601
190	TRUE	2770	1361	0.491335740072202	0	0	0	0	7554
191	FALSE	NA	NA	NA	1	0	1	1	5427
192	TRUE	2149	1926	0.896230805025593	0	0	0	0	2857
193	FALSE	NA	NA	NA	1	0	1	1	596
194	FALSE	NA	NA	NA	1	0	1	1	39
195	TRUE	212	92	0.433962264150943	0	0	0	0	153
196	TRUE	7	5	0.714285714285714	0	0	0	0	7
197	FALSE	NA	NA	NA	1	0	1	1	32
198	TRUE	89	44	0.49438202247191	0	0	0	0	75
199	FALSE	NA	NA	NA	1	0	1	1	250
200	FALSE	NA	NA	NA	0	0	0	0	117
201	FALSE	NA	NA	NA	1	0	1	1	39
202	FALSE	NA	NA	NA	3	1	3	3	324
203	FALSE	NA	NA	NA	0	0	0	0	0
204	TRUE	13	9	0.692307692307692	0	0	0	0	11
205	TRUE	477	125	0.262054507337526	0	0	0	0	314
206	FALSE	NA	NA	NA	1	0	1	1	398
207	FALSE	NA	NA	NA	1	0	1	1	258
208	TRUE	212	154	0.726415094339623	0	0	0	0	156
209	FALSE	NA	NA	NA	1	0	1	1	12
210	FALSE	NA	NA	NA	1	0	1	1	383
211	FALSE	NA	NA	NA	0	0	0	0	1
212	FALSE	NA	NA	NA	1	0	1	1	130
213	TRUE	17	10	0.588235294117647	2	1	2	3	16
214	FALSE	NA	NA	NA	1	0	1	1	494
215	FALSE	NA	NA	NA	0	0	0	0	107
216	FALSE	NA	NA	NA	1	0	1	1	294
217	FALSE	NA	NA	NA	1	0	1	1	105
218	TRUE	47	43	0.914893617021277	2	0	2	2	39
219	FALSE	NA	NA	NA	1	0	1	1	150
220	TRUE	583	166	0.284734133790738	0	0	0	0	474
221	FALSE	NA	NA	NA	1	0	1	1	200
222	TRUE	452	230	0.508849557522124	0	0	0	0	400
223	FALSE	NA	NA	NA	0	0	0	0	394
224	FALSE	NA	NA	NA	0	0	0	0	162
225	TRUE	441	398	0.90249433106576	0	0	0	0	347
226	TRUE	675	220	0.325925925925926	0	0	0	0	571
227	TRUE	55	39	0.709090909090909	0	0	0	0	38
228	FALSE	NA	NA	NA	0	0	0	0	0
229	FALSE	NA	NA	NA	3	1	3	3	19
230	FALSE	NA	NA	NA	1	0	1	1	6
231	TRUE	311	142	0.456591639871383	2	0	2	2	226
232	FALSE	NA	NA	NA	1	0	1	1	220
233	FALSE	NA	NA	NA	1	0	1	1	194
234	TRUE	116	17	0.146551724137931	0	0	0	0	86
235	FALSE	NA	NA	NA	0	0	0	0	0
236	FALSE	NA	NA	NA	0	0	0	0	286
237	FALSE	NA	NA	NA	1	0	1	1	281
238	FALSE	NA	NA	NA	2	0	2	2	425
239	FALSE	NA	NA	NA	0	0	0	0	0
240	TRUE	357	125	0.350140056022409	0	0	0	0	266
241	FALSE	NA	NA	NA	1	0	1	1	123
242	FALSE	NA	NA	NA	1	0	1	1	543
243	TRUE	186	155	0.833333333333333	0	0	0	1	169
244	FALSE	NA	NA	NA	2	0	2	2	739
245	FALSE	NA	NA	NA	1	0	1	1	256
246	FALSE	NA	NA	NA	3	1	3	3	289
247	TRUE	245	60	0.244897959183673	0	0	0	0	163
97	FALSE	NA	NA	NA	1	0	1	1	7129
98	FALSE	NA	NA	NA	1	0	1	1	4407
99	TRUE	2542	526	0.206923682140047	1	0	1	1	7855
A136P	TRUE	1003	348	0.346959122632104	0	0	0	0	890
CIRM87	FALSE	NA	NA	NA	0	0	0	0	850
NTC1	FALSE	NA	NA	NA	0	0	0	0	0
NTC2	FALSE	NA	NA	NA	0	0	0	0	1
NTC3	TRUE	94	10	0.106382978723404	0	0	0	0	85
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here is a list of all the variants/edit appearing more than once and their count.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;     62 chr2	161416811	AC	A
     61 chr2	161416756	GCGGCCACTGCTCCCAGTGCCATGTTCCCGTACCCCGGCCAGCA	G
     43 chr2	161416799	ACGGACCGGCGCAC	*,A
     17 chr2	161416582	G	T
     12 chr2	161416799	ACGGACCGGCGCAC	A
     11 chr2	161416796	AGCACGGACCGGC	A
     10 chr2	161416798	C	CGCCG
      9 chr2	161416800	CGG	*,C
      8 chr2	161416803	ACCGGCGCAC	*,A
      8 chr2	161416799	A	C
      7 chr2	161416994	C	CGGTCATAG
      6 chr2	161416796	AGCACGGACCGGCGCAC	A
      6 chr2	161416581	G	T
      5 chr2	161416799	ACGGACCGGCGCAC	*,AGGCGCAC
      5 chr2	161416782	CCCGTACCCCGGCCAGCA	C
      3 chr2	161416798	CACGG	C
      2 chr2	161416995	C	T
      2 chr2	161416994	C	CGG
      2 chr2	161416990	T	TC
      2 chr2	161416988	C	CTCCACGGTCATAG
      2 chr2	161416799	ACGGACCGGCGCAC	A,CCGGACCGGCGCAC
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><category term="amplicon" /><summary type="html">Dir: /home/groups/oroaklab/nishida/amplicon_220305 Run: /home/groups/oroaklab/nishida/amplicon_220305/run.txt</summary></entry><entry><title type="html">OneDrive Upload and Download with Rclone</title><link href="http://localhost:4000/2022/03/01/post-0074.html" rel="alternate" type="text/html" title="OneDrive Upload and Download with Rclone" /><published>2022-03-01T00:00:00-08:00</published><updated>2022-03-01T00:00:00-08:00</updated><id>http://localhost:4000/2022/03/01/post-0074</id><content type="html" xml:base="http://localhost:4000/2022/03/01/post-0074.html">&lt;p&gt;Here’s instructions for using rclone on our clusters specifically using a remote/headless machine. This requires more setup but skips the use of X11.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Download rclone on your personal home computer, https://rclone.org/downloads/.&lt;/li&gt;
  &lt;li&gt;Go to mays/mccovey/bonds and load the rclone modules, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;module load rclone&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Setup rclone on mays/mccovey/bonds, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rclone config&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Inside rclone’s configuration, setup the following:
    &lt;ul&gt;
      &lt;li&gt;‘n’ for new remote at the ‘n/s/q’ prompt&lt;/li&gt;
      &lt;li&gt;a shortcut name for the storage at the ‘name’ prompt, I am just calling it ONEDRIVE&lt;/li&gt;
      &lt;li&gt;‘onedrive’ for the ‘Storage’ prompt&lt;/li&gt;
      &lt;li&gt;press enter to skip the prompt ‘client_id’&lt;/li&gt;
      &lt;li&gt;press enter to skip the prompt ‘client_secret’&lt;/li&gt;
      &lt;li&gt;‘global’ for the prompt ‘region’&lt;/li&gt;
      &lt;li&gt;‘n’ to not edit the advanced configurations at ‘y/n’&lt;/li&gt;
      &lt;li&gt;‘n’ to setup on the headless node at ‘y/n’&lt;/li&gt;
      &lt;li&gt;leave this open for a moment&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;On your personal home computer run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rclone authorize &quot;onedrive&quot;&lt;/code&gt;. This will open your web browser and ask you to log into your OneDrive account. This then returns a long configuration string to copy.&lt;/li&gt;
  &lt;li&gt;Paste the configuration key back on the config in mays/mccovey/bonds.&lt;/li&gt;
  &lt;li&gt;Finish configuration:
    &lt;ul&gt;
      &lt;li&gt;confirm the configuration as ‘onedrive’ at the prompt ‘config_type’&lt;/li&gt;
      &lt;li&gt;confirm ‘y’ at the URL confirmation of ‘y/n’&lt;/li&gt;
      &lt;li&gt;confirm ‘y’ for setup at the last prompt ‘y/n’&lt;/li&gt;
      &lt;li&gt;‘q’ to quit out and you should be set up&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Send a test file. This should send the test file to your OneDrive account setup with the name “ONEDRIVE” to the directory Documents/
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;echo &quot;THIS IS A TEST FILE&quot; &amp;gt; test.txt
rclone copy test.txt ONEDRIVE:Documents/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><category term="ref" /><summary type="html">Here’s instructions for using rclone on our clusters specifically using a remote/headless machine. This requires more setup but skips the use of X11.</summary></entry><entry><title type="html">Dropbox Upload and Download with Curl and API Key</title><link href="http://localhost:4000/2022/01/25/post-0073.html" rel="alternate" type="text/html" title="Dropbox Upload and Download with Curl and API Key" /><published>2022-01-25T00:00:00-08:00</published><updated>2022-01-25T00:00:00-08:00</updated><id>http://localhost:4000/2022/01/25/post-0073</id><content type="html" xml:base="http://localhost:4000/2022/01/25/post-0073.html">&lt;p&gt;These are the step to upload and download from the console to and from Dropbox.
&lt;br /&gt;1. Go to: https://www.dropbox.com/developers/apps
&lt;br /&gt;2. Create an App. Name is whatever you like but probably something like “Dropbox Access”.
&lt;br /&gt;3. Navigate to Permissions on the top tab. Check account_info.write, account_info.read, files.metadata.write, files.metadata.read, files.content.write, and files.content.read.
&lt;br /&gt;4. Navigate to Settings on the top tab. Generate your access token. If you change your permissions you must regenerate your access token. Always keep your API key secret or else anybody can use it to access everything in your Dropbox.&lt;/p&gt;

&lt;p&gt;###&lt;/p&gt;

&lt;p&gt;&lt;b&gt;For files &amp;lt; 150 Mb using the “2/files/upload” endpoint.&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Upload Instructions. This will upload file, ‘test.txt’, into your Dropbox folder ‘temp_upload’ under the name ‘uploaded_test_file.txt’.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# create test file
echo &quot;TEST THIS&quot; &amp;gt; test.txt

# fill these variables in
API_KEY=&quot;keep your API key secret&quot;
INPUT_PATH=&quot;test.txt&quot;
DROPBOX_FILE_PATH=&quot;/temp_upload/uploaded_test_file.txt&quot;

# run
curl -X POST https://content.dropboxapi.com/2/files/upload \
    --header &quot;Authorization: Bearer ${API_KEY}&quot; \
    --header &quot;Dropbox-API-Arg: {\&quot;path\&quot;: \&quot;${DROPBOX_FILE_PATH}\&quot;}&quot; \
    --header &quot;Content-Type: application/octet-stream&quot; \
    --data-binary @${INPUT_PATH}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Download Instructions. This will download ‘uploaded_test_file.txt’ in Dropbox directory ‘temp_upload’ as ‘downloaded_test_file.txt&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# fill these variables in
API_KEY=&quot;keep your API key secret&quot;
DROPBOX_FILE_PATH=&quot;/temp_upload/uploaded_test_file.txt&quot;
OUTPUT_PATH=&quot;downloaded_test_file.txt&quot;

# run
curl -X POST https://content.dropboxapi.com/2/files/download \
    --header &quot;Authorization: Bearer ${API_KEY}&quot; \
    --header &quot;Dropbox-API-Arg: {\&quot;path\&quot;: \&quot;${DROPBOX_FILE_PATH}\&quot;}&quot; \
    -o &quot;${OUTPUT_PATH}&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;###&lt;/p&gt;

&lt;p&gt;&lt;b&gt;For files &amp;gt; 150 Mb using upload sessions.&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;https://github.com/andreafabrizi/Dropbox-Uploader&lt;/p&gt;</content><author><name></name></author><category term="ref" /><summary type="html">These are the step to upload and download from the console to and from Dropbox. 1. Go to: https://www.dropbox.com/developers/apps 2. Create an App. Name is whatever you like but probably something like “Dropbox Access”. 3. Navigate to Permissions on the top tab. Check account_info.write, account_info.read, files.metadata.write, files.metadata.read, files.content.write, and files.content.read. 4. Navigate to Settings on the top tab. Generate your access token. If you change your permissions you must regenerate your access token. Always keep your API key secret or else anybody can use it to access everything in your Dropbox.</summary></entry><entry><title type="html">Drosophilia Tau DA Results Test Analysis</title><link href="http://localhost:4000/2022/01/21/post-0072.html" rel="alternate" type="text/html" title="Drosophilia Tau DA Results Test Analysis" /><published>2022-01-21T00:00:00-08:00</published><updated>2022-01-21T00:00:00-08:00</updated><id>http://localhost:4000/2022/01/21/post-0072</id><content type="html" xml:base="http://localhost:4000/2022/01/21/post-0072.html">&lt;p&gt;Directory: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/sc_dm6_tau/DA_jan7_2022/test_analysis&lt;/code&gt;
&lt;br /&gt;Run: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/sc_dm6_tau/DA_jan7_2022/test_analysis/run.txt&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This is an example rough pass through analyzing the results of the DA test. This focuses on the ‘3_Parent_d5’ comparisons as the example. Clusters are combined across treatments but kept separate. Thresholds for ‘significantly changing’ sites are &amp;lt; 0.01 raw p-value and &amp;gt; 1.5 Log2 FC. The significant results could be annotated by their motifs and nearest genes.&lt;/p&gt;

&lt;p&gt;5.2-5.7 - P-value distributions are left-skewed. FDR does not work except maybe with WT_to_KI_KI. Volcano plots suggest global opening and closing in some conditions (WT_to_KI_KI shows a global decrease in accessibility across many sites).
8.8 - Heatmap shows groups of sites that are specific to the strains trending in the same direction. The most notable is the group for WT to KI_KI which shows large decreases specific to the biological cluster 3 (in yellow on the left).&lt;/p&gt;

&lt;p&gt;Markdown links:
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/2vbwjy5j27zohi0/dm6_test_da.html?dl=0&quot;&gt;R Markdown HTML&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/an2v1ngucr8nqlt/dm6_test_da.Rmd?dl=0&quot;&gt;R Markdown&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="dm6_tau" /><summary type="html">Directory: /home/groups/oroaklab/nishida/sc_dm6_tau/DA_jan7_2022/test_analysis Run: /home/groups/oroaklab/nishida/sc_dm6_tau/DA_jan7_2022/test_analysis/run.txt</summary></entry><entry><title type="html">SPARK Pre Best Practices Filter, Model Scores</title><link href="http://localhost:4000/2022/01/19/post-0071.html" rel="alternate" type="text/html" title="SPARK Pre Best Practices Filter, Model Scores" /><published>2022-01-19T00:00:00-08:00</published><updated>2022-01-19T00:00:00-08:00</updated><id>http://localhost:4000/2022/01/19/post-0071</id><content type="html" xml:base="http://localhost:4000/2022/01/19/post-0071.html">&lt;p&gt;This markdown takes the pre-filtered data and plots out the metrics that are used for scoring by the logistic model. All variants are plotted and then just the subset of mosaic child calls.&lt;/p&gt;

&lt;p&gt;This data represents the simplex quads only. It uses the broad filter and removes parental germline calls.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;A broad filter to reduce computational load is used.
- Frequent variants appearing 5 or more times are removed from further analysis.
- Common variant allele frequencies determined from ExAC and gnomAD annotations must be less than 0.005.
- Variants require at least 3 non-reference reads and at least 8 reads in all four family members.
- Variants must also fall within exonic or splicing regions from RefSeq annotations.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Markdown showing the error model metrics of the pre-filtered data:
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/md88g4ahmmwuer9/20_logistic_model_params.html?dl=0&quot;&gt;20 Logistic Model Metrics Pre-Filter&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="SPARK" /><summary type="html">This markdown takes the pre-filtered data and plots out the metrics that are used for scoring by the logistic model. All variants are plotted and then just the subset of mosaic child calls.</summary></entry><entry><title type="html">SPARK SSC hg38 Transformed Burden, 01</title><link href="http://localhost:4000/2022/01/18/post-0070.html" rel="alternate" type="text/html" title="SPARK SSC hg38 Transformed Burden, 01" /><published>2022-01-18T00:00:00-08:00</published><updated>2022-01-18T00:00:00-08:00</updated><id>http://localhost:4000/2022/01/18/post-0070</id><content type="html" xml:base="http://localhost:4000/2022/01/18/post-0070.html">&lt;p&gt;The SSC list was transformed from hg19 to hg38 as described &lt;a href=&quot;https://arsnishida.github.io/2021/11/30/post-0066.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;20 sites were removed for having no original FRACTION assignment. 172 sites removed for falling into a SDTRF region in going from hg19 to hg38. 9 sites were removed for having no functional mutation type (both originally and after reannotation). There were 7 mosaic child sites lost in this fashion. 1 had no mutation type in both hg19 and hg38. The other 6 fell in super duplicate regions with 3 of them being within 100 bp of each other constituting a complex event.&lt;/p&gt;

&lt;p&gt;This recreates the burden analysis from the original SSC paper. The trends match but the n’s and signficance do not. This is due to the family list and potentially the LGD/NS lists. The family lists include hundreds more families than the original analysis and are taken from ‘cohort_all_families_list.table’. The LGD/NS lists were taken from ‘Family_Subcohort_Designations.xlsx’. These were found in our Box directory:
&lt;br /&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/All Files/kruppd/Writing/SSC somatic pilot/data/Data Used for Mosaic Paper/High Confidence Variants/&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Markdown showing the SSC solo burden analysis:
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/0pv9gk7cxk24v9j/19_burden_genesets_ssc_missense.html?dl=0&quot;&gt;19 SSC Solo Burden Markdown&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="SPARK" /><summary type="html">The SSC list was transformed from hg19 to hg38 as described here.</summary></entry><entry><title type="html">Drosophilia Tau Final DA</title><link href="http://localhost:4000/2022/01/08/post-0069.html" rel="alternate" type="text/html" title="Drosophilia Tau Final DA" /><published>2022-01-08T00:00:00-08:00</published><updated>2022-01-08T00:00:00-08:00</updated><id>http://localhost:4000/2022/01/08/post-0069</id><content type="html" xml:base="http://localhost:4000/2022/01/08/post-0069.html">&lt;p&gt;Directory: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/sc_dm6_tau/DA_jan7_2022&lt;/code&gt;
&lt;br /&gt;Run: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/sc_dm6_tau/DA_jan7_2022/run.txt&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The DA was performed after TF normalization using the Wilcoxon rank sum test and creates the comparisons in ‘210712_DA_Comparisons.txt’. Mild name changes were made in the comparisons such as ‘Photoreceptor’ to ‘Photoreceptors’ to match the annotation file and using the correct annotation column for the biologically split subsets.&lt;/p&gt;

&lt;p&gt;The following comparisons are nonexistant because they have no cells with the annotation:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- Glia_WT_CS_5_C13 has no cells so all 6 comparisons are missing in 3_Glia_d5.
- Glia_KI_CS_30_C21, Glia_dTaudel_30_C13, Glia_KI_CS_30_C13 in 3_Glia_d30.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The following comparisons are deliberately empty because they have too few cells:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- DA.Glia_WT_CS_30_C11_Glia_PL_CS_30_C11.txt, DA.Glia_WT_CS_30_C13_Glia_CS_30_C13.txt
- DA.Neuron_WT_CS_30_C14_Neuron_dTaudel_30_C14.txt, DA.Neuron_WT_CS_30_C14_Neuron_PL_CS_30_C14.txt
- DA.Photoreceptors_WT_CS_30_C1_Photoreceptors_PL_CS_30_C1.txt, DA.Photoreceptors_WT_CS_30_C3_Photoreceptors_dTaudel_30_C3.txt, DA.Photoreceptors_WT_CS_30_C3_Photoreceptors_KI_CS_30_C3.txt, DA.Photoreceptors_WT_CS_30_C3_Photoreceptors_PL_CS_30_C3.txt, DA.Photoreceptors_WT_CS_30_C3_Photoreceptors_VM_CS_30_C3.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><category term="dm6_tau" /><summary type="html">Directory: /home/groups/oroaklab/nishida/sc_dm6_tau/DA_jan7_2022 Run: /home/groups/oroaklab/nishida/sc_dm6_tau/DA_jan7_2022/run.txt</summary></entry><entry><title type="html">SPARK VEP Annotations</title><link href="http://localhost:4000/2021/12/03/post-0068.html" rel="alternate" type="text/html" title="SPARK VEP Annotations" /><published>2021-12-03T00:00:00-08:00</published><updated>2021-12-03T00:00:00-08:00</updated><id>http://localhost:4000/2021/12/03/post-0068</id><content type="html" xml:base="http://localhost:4000/2021/12/03/post-0068.html">&lt;p&gt;VEP was used to annotate the high confidence lists. The following databases were used. There are redundant scores between the databases but they might possibly differ slightly due to the different versions of references each uses.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;dbNSFP v4.1a from ftp://dbnsfp:dbnsfp@dbnsfp.softgenetics.com/dbNSFP4.1a.zip&lt;/li&gt;
  &lt;li&gt;gnomAD v3.0.1 from https://storage.googleapis.com/gcp-public-data–gnomad/release/3.0.1/coverage/genomes/gnomad.genomes.r3.0.1.coverage.summary.tsv.bgz&lt;/li&gt;
  &lt;li&gt;REVEL v1.3 from https://sites.google.com/site/revelgenomics/downloads&lt;/li&gt;
  &lt;li&gt;LoFtool scores (no version) from https://github.com/Ensembl/VEP_plugins&lt;/li&gt;
  &lt;li&gt;ExACpLI scores (no version) from https://github.com/Ensembl/VEP_plugins&lt;/li&gt;
  &lt;li&gt;blosum62 scores (no version)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I am keeping this separated from the high confidence lists but these columns can be directly added to the highconfidence lists without any reordering (the rows are the same). These are available here. 
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/bjwj52ibth2rytw/quadsimplex.highconfidence.add_annot.txt?dl=0&quot;&gt;Simplex Quad, Added Annotations&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/fgr8kt3mt98juq5/quadmultiplex.highconfidence.add_annot.txt?dl=0&quot;&gt;Multiplex Quad, Added Annotations&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/ntn4cr1jmh44q70/triosimplex.highconfidence.add_annot.txt?dl=0&quot;&gt;Simplex Trio, Added Annotations&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The dbNSFP columns are described here and then are followed by the other scores from the other annotation databases:
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/j95lkv05al56kcp/dbNSFP_columns.txt?dl=0&quot;&gt;Added Annotation Column Descriptions&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="SPARK" /><summary type="html">VEP was used to annotate the high confidence lists. The following databases were used. There are redundant scores between the databases but they might possibly differ slightly due to the different versions of references each uses. dbNSFP v4.1a from ftp://dbnsfp:dbnsfp@dbnsfp.softgenetics.com/dbNSFP4.1a.zip gnomAD v3.0.1 from https://storage.googleapis.com/gcp-public-data–gnomad/release/3.0.1/coverage/genomes/gnomad.genomes.r3.0.1.coverage.summary.tsv.bgz REVEL v1.3 from https://sites.google.com/site/revelgenomics/downloads LoFtool scores (no version) from https://github.com/Ensembl/VEP_plugins ExACpLI scores (no version) from https://github.com/Ensembl/VEP_plugins blosum62 scores (no version)</summary></entry><entry><title type="html">SPARK Burden Tables Gene Sets, SPARK+SSC</title><link href="http://localhost:4000/2021/11/30/post-0067.html" rel="alternate" type="text/html" title="SPARK Burden Tables Gene Sets, SPARK+SSC" /><published>2021-11-30T00:00:00-08:00</published><updated>2021-11-30T00:00:00-08:00</updated><id>http://localhost:4000/2021/11/30/post-0067</id><content type="html" xml:base="http://localhost:4000/2021/11/30/post-0067.html">&lt;p&gt;This performs the burden analysis across the genesets using the combined and harmonized Spark and SSC lists. The SSC is transformed to hg38 but the joint coverages remain in hg19. Joint coverages were manually filtered for duplicate entries for two families, 13431 and 12839.&lt;/p&gt;

&lt;p&gt;Markdowns:
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/9j19yvd2bc66lyi/18_burden_genesets_qsts_ssc_missense.html?dl=0&quot;&gt;18 Burden Genesets, SPARK+SSC and missense&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/nh5cqxu9qosk6aj/18_burden_genesets_qsts_ssc_synonymous.html?dl=0&quot;&gt;18 Burden Genesets, SPARK+SSC and synonymous&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/lu5b5ruetw526jr/18_burden_genesets_qsts_ssc_nonsensesplicing.html?dl=0&quot;&gt;18 Burden Genesets, SPARK+SSC and nonsense-splicing&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="SPARK" /><summary type="html">This performs the burden analysis across the genesets using the combined and harmonized Spark and SSC lists. The SSC is transformed to hg38 but the joint coverages remain in hg19. Joint coverages were manually filtered for duplicate entries for two families, 13431 and 12839.</summary></entry></feed>