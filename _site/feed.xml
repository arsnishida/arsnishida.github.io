<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-05-30T16:57:55-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">ARSN Lab Notebook</title><subtitle>ARSN Lab notebook.</subtitle><entry><title type="html">SPARK Joint Coverage Plots</title><link href="http://localhost:4000/2021/05/30/post-0017.html" rel="alternate" type="text/html" title="SPARK Joint Coverage Plots" /><published>2021-05-30T00:00:00-07:00</published><updated>2021-05-30T00:00:00-07:00</updated><id>http://localhost:4000/2021/05/30/post-0017</id><content type="html" xml:base="http://localhost:4000/2021/05/30/post-0017.html">&lt;p&gt;Directory: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/spark_mosaic/burden&lt;/code&gt;
&lt;br /&gt;Run: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run.txt&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Joint coverage plots were created separately for simplex quads, multiplex quads, and simplex trios. These count the number of bases over 52 thresholds (from the range of needing 1-250 counts) for each member of a family, the total of the family, and the average of the family. These are subset into six regions, non-SDTRF (CDS) sites and SDTRF sites and then those are split into autosomal, X, and Y chromosomes.&lt;/p&gt;

&lt;p&gt;Coverage plots are in the following markdown. At a threshold of 5x coverage still only less than half of the bases are covered. &lt;a href=&quot;https://www.dropbox.com/home/SPARK%20Mosaics/markdowns?preview=burden_coverage_plots.html&quot;&gt;figure-01&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Links to Burden Data:
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/home/SPARK%20Mosaics/burden?preview=jointcoverage.simplextrios.txt&quot;&gt;jointcoverage.simplextrios.txt&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/home/SPARK%20Mosaics/burden?preview=jointcoverage.simplexquads.txt&quot;&gt;jointcoverage.simplexquads.txt&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/home/SPARK%20Mosaics/burden?preview=jointcoverage.multiplexquads.txt&quot;&gt;jointcoverage.multiplexquads.txt&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="SPARK" /><summary type="html">Directory: /home/groups/oroaklab/nishida/spark_mosaic/burden Run: run.txt</summary></entry><entry><title type="html">SPARK Joint Coverage Counter Tool Fidelity</title><link href="http://localhost:4000/2021/05/30/post-0016.html" rel="alternate" type="text/html" title="SPARK Joint Coverage Counter Tool Fidelity" /><published>2021-05-30T00:00:00-07:00</published><updated>2021-05-30T00:00:00-07:00</updated><id>http://localhost:4000/2021/05/30/post-0016</id><content type="html" xml:base="http://localhost:4000/2021/05/30/post-0016.html">&lt;p&gt;Directory: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/spark_mosaic/burden/test_compare&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The tool, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/users/kruppd/scripts/file/joint_coverage_calc_front.py&lt;/code&gt;, needed to be rewritten into something more flexible. It also needs to eliminate hard-coded family information since my tables are already pre-split by family. This changes it into simply looking for the overlap of sites between a sorted coverage file and the reference with bedops and takes advantage of numerical sorting of the output to make quicker counts. Here a comparison is performed attempting to regenerate the original output in both manners and checking for fidelity. Code for running is in: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/spark_mosaic/burden/test_compare/run.txt&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The md5sums are comparable in the first check of comparing the re-use of the original tools.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ md5sum $NEW_OUT
aae58c37f826d37f62e9449e8a03c90a  /home/groups/oroaklab/nishida/spark_mosaic/burden/test_compare/interval_joint_cov_P24_01.comp.table
$ md5sum $ORIGINAL_OUT
aae58c37f826d37f62e9449e8a03c90a  /home/groups/oroaklab/data/SSC/reprocessed/metrics/joint_cov/pilot_24/interval_joint_cov_P24_01.table
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The count outputs are nearly identical in the second check for comparing the new tool to the old tool.  The minor difference is that they are off by 51 due to me missing a count when I am transitioning between thresholds. But since the counts are in the 1M’s this seems like a gentle difference (and can be fixed post-hoc if necessary). Markdown showing the similarities: &lt;a href=&quot;https://www.dropbox.com/home/SPARK%20Mosaics/markdowns?preview=compare_burden_counter.html&quot;&gt;figure-01&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="SPARK" /><summary type="html">Directory: /home/groups/oroaklab/nishida/spark_mosaic/burden/test_compare</summary></entry><entry><title type="html">Single Cell TBR1 Cluster DA</title><link href="http://localhost:4000/2021/05/28/post-0014.html" rel="alternate" type="text/html" title="Single Cell TBR1 Cluster DA" /><published>2021-05-28T00:00:00-07:00</published><updated>2021-05-28T00:00:00-07:00</updated><id>http://localhost:4000/2021/05/28/post-0014</id><content type="html" xml:base="http://localhost:4000/2021/05/28/post-0014.html">&lt;p&gt;Directory: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index/DA&lt;/code&gt;
&lt;br /&gt;Run: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run.txt&lt;/code&gt;
&lt;br /&gt;Header for DA: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;header.txt&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;These are the results from comparing all the clusters against one another to look for differentially accessible peaks. I performed a term factor transformation to adjust for depth and compared cells by pheograph cluster annotation via the Wilcoxon rank sum test. Peaks are annotated to their nearest gene and p-values are corrected with an FDR correction.&lt;/p&gt;

&lt;p&gt;The FDR correction does not work on this dataset. There are +1M peaks but peaks with p-values of &amp;lt; 0.01 are usually in the few hundreds or lower. The FDR correction ends up setting everything to 1. For now, just use the regular p-values. Probably start it at a threshold of 0.01 but you can move it up to 0.05 or even higher if desirable. I left the files with the FDR column in there with the suffix FDR but they won’t be of use.&lt;/p&gt;

&lt;p&gt;Here’s an example of how I’d start parsing through the data. This example would show you the nearby genes that have statistically different peaks between pg_10 and pg_11. This example yields 55 results which is consistent with what we normally see from this analysis (and also a friendly number for humans to parse through).&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# open the file, filter for peaks with a pvalue &amp;lt; 0.01, filter for peaks +/- 10000bp to a TSS, pull out gene names, sort, print unique results
# move the thresholds as desired
cat DA_pg.pg_10_pg_11.txt | awk '$7 &amp;lt; 0.01' | awk '$10 &amp;lt; 10000 &amp;amp;&amp;amp; $10 &amp;gt; -10000' | cut -f 9 | sort | uniq
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><category term="tbr1" /><summary type="html">Directory: /home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index/DA Run: run.txt Header for DA: header.txt</summary></entry><entry><title type="html">SPARK RefSeq CDS and Splice Site Reference Generation</title><link href="http://localhost:4000/2021/05/28/post-0015.html" rel="alternate" type="text/html" title="SPARK RefSeq CDS and Splice Site Reference Generation" /><published>2021-05-28T00:00:00-07:00</published><updated>2021-05-28T00:00:00-07:00</updated><id>http://localhost:4000/2021/05/28/post-0015</id><content type="html" xml:base="http://localhost:4000/2021/05/28/post-0015.html">&lt;p&gt;Directory: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/spark_mosaic/refs/cds_splice_sites&lt;/code&gt;
&lt;br /&gt;Run: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run.txt&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The purpose of this is to establish the reference file created in hg19 for hg38: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/refs/GRCh37/Homo_sapiens_refseq_cds_splice_positions.txt&lt;/code&gt;. There are however no instructions concerning how it was made or the refseq version from which it was created.&lt;/p&gt;

&lt;p&gt;To try to replicate this reference, every CDS and stop codon entry in the GTF will be pulled out to represent ‘cds’. Every transcript with more than one exon will have a ‘splice’ entry for the two bases extending internally for each internal exon boundary.&lt;/p&gt;

&lt;p&gt;Below is a comparison of the originally generated cds/splice reference from an unknown hg19 RefSeq version to a version of hg19 RefSeq from circa ~2015 using the logic above. There is greater than 99.5% similarity between these references with the ~2015 reference having more bases in all categories in general (likely because it is newer). Also included are the numbers from the 2021 RefSeq version for hg38 and the liftOver of that back to hg19. Similarity is closer to 95% here and also the hg38 version contains more bases in all categories relative to the other references. With such high concordance, I am comfortable with using this going forward as our reference.&lt;/p&gt;

&lt;p&gt;SDTRF sites are taken from Annovar’s hg38 genomicSuperDups and simpleRepeats databases (the same used for annotation of the mosaic list). Original hg19 contained 2,909,050 sites representing 8.104452% of the original sites. This hg38 references contains 3,476,939 sites representing 8.492237% of the original sites, a comparable amount.&lt;/p&gt;

&lt;p&gt;Screenshot of spreadsheet: &lt;a href=&quot;https://www.dropbox.com/home/SPARK%20Mosaics/linked_files?preview=blog_SPARK_refseqCdsSplice_compare.png&quot;&gt;figure-01&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Spreadsheet: &lt;a href=&quot;https://www.dropbox.com/home/SPARK%20Mosaics/linked_files?preview=SPARK_refseqCdsSplice_compare.xlsx&quot;&gt;figure-02&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="SPARK" /><summary type="html">Directory: /home/groups/oroaklab/nishida/spark_mosaic/refs/cds_splice_sites Run: run.txt</summary></entry><entry><title type="html">Single Cell TBR1 ENCODE DHS Index Final UMAP and Clusters</title><link href="http://localhost:4000/2021/05/27/post-0013.html" rel="alternate" type="text/html" title="Single Cell TBR1 ENCODE DHS Index Final UMAP and Clusters" /><published>2021-05-27T00:00:00-07:00</published><updated>2021-05-27T00:00:00-07:00</updated><id>http://localhost:4000/2021/05/27/post-0013</id><content type="html" xml:base="http://localhost:4000/2021/05/27/post-0013.html">&lt;p&gt;Directory: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index&lt;/code&gt;
&lt;br /&gt;Run: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run.txt&lt;/code&gt;
&lt;br /&gt;Final Matrix: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tbr1_ko_encodeDHSindex_finalfilter.filt.sparseMatrix.values&lt;/code&gt;
&lt;br /&gt;Final UMAP Dims: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tbr1_ko_encodeDHSindex_finalfilter.filt.cistopic.30.UMAP.dims&lt;/code&gt;
&lt;br /&gt;Final Clusters: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tbr1_ko_encodeDHSindex_finalfilter.filt.cistopic.30.k50.pg.annot&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Here is the final UMAP and clusters. This was performed using the ENCODE DHS index, a milder TSS enrichment filter for cells &amp;gt; 1.5 TSS enrichment, and default scrublet calling. Why does this end up looking better? My guess is that the cells with lower TSS enrichment are genuine clusters (like a cell type that is hard to get in general). These lower TSS cells cannot get normal peaks called so using the ENCODE DHS index is able to better identify their signal. And their inclusion helps cluster everything else. &lt;a href=&quot;https://ohsu.app.box.com/file/815609175624&quot;&gt;figure-01&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Compare these to some failed attempts using higher TSS enrichment filters at 2 and 2.7 which lose all form. &lt;a href=&quot;https://ohsu.app.box.com/file/815609354066&quot;&gt;figure-02&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="tbr1" /><summary type="html">Directory: /home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index Run: run.txt Final Matrix: tbr1_ko_encodeDHSindex_finalfilter.filt.sparseMatrix.values Final UMAP Dims: tbr1_ko_encodeDHSindex_finalfilter.filt.cistopic.30.UMAP.dims Final Clusters: tbr1_ko_encodeDHSindex_finalfilter.filt.cistopic.30.k50.pg.annot</summary></entry><entry><title type="html">SPARK Mosaic List, Summary Counts of Annotations</title><link href="http://localhost:4000/2021/05/11/post-0012.html" rel="alternate" type="text/html" title="SPARK Mosaic List, Summary Counts of Annotations" /><published>2021-05-11T00:00:00-07:00</published><updated>2021-05-11T00:00:00-07:00</updated><id>http://localhost:4000/2021/05/11/post-0012</id><content type="html" xml:base="http://localhost:4000/2021/05/11/post-0012.html">&lt;p&gt;Directory: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;https://www.dropbox.com/home/SPARK%20Mosaics&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This provides a full tabulated count of the annotations per category for each of the lists of SPARK mosaic data using the data without germline parental calls.&lt;/p&gt;

&lt;p&gt;Link to Markdown: &lt;a href=&quot;https://www.dropbox.com/s/bon4m7zfee6yagp/summary_fractions.html?dl=0&quot;&gt;R Markdown&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="SPARK" /><summary type="html">Directory: https://www.dropbox.com/home/SPARK%20Mosaics</summary></entry><entry><title type="html">Single Cell TBR1 ENCODE DHS Index Tests</title><link href="http://localhost:4000/2021/05/11/post-0011.html" rel="alternate" type="text/html" title="Single Cell TBR1 ENCODE DHS Index Tests" /><published>2021-05-11T00:00:00-07:00</published><updated>2021-05-11T00:00:00-07:00</updated><id>http://localhost:4000/2021/05/11/post-0011</id><content type="html" xml:base="http://localhost:4000/2021/05/11/post-0011.html">&lt;p&gt;Directory: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index/first_pass&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Code: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run.txt&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Calling peaks on this data doesn’t work because it is too noisy. Using Casey’s cleaner peak set was working a bit better. Tiling helps sparse amounts of data but won’t help with noise. This peak set is basically Casey’s peak set+. List is from here: &lt;a href=&quot;https://www.biorxiv.org/content/10.1101/2020.06.26.172718v3&quot;&gt;biorxiv paper&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If the data wasn’t as noisy then calling peaks specifically across this dataset is the best approach. You’d even get novel peaks. But with technically poor data the technical methods alone do not seem to be working. Using biologically motivated references however seems to select appropriate sites for consideration in dimensionality reduction. &lt;a href=&quot;https://ohsu.app.box.com/file/809562739594&quot;&gt;figure-01&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Since this seems to be working, the dimensionality reduction needs to be re-run with filtering and doublet removal. Doublet removal on a dataset this size is giving memory issues so I am moving it to Exacloud.&lt;/p&gt;</content><author><name></name></author><category term="tbr1" /><summary type="html">Directory: /home/groups/oroaklab/nishida/sc_tmp1/encode_DHS_index/first_pass</summary></entry><entry><title type="html">Single Cell TBR1 Coembedding Tests</title><link href="http://localhost:4000/2021/05/09/post-0010.html" rel="alternate" type="text/html" title="Single Cell TBR1 Coembedding Tests" /><published>2021-05-09T00:00:00-07:00</published><updated>2021-05-09T00:00:00-07:00</updated><id>http://localhost:4000/2021/05/09/post-0010</id><content type="html" xml:base="http://localhost:4000/2021/05/09/post-0010.html">&lt;p&gt;Directory: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/sc_tmp1/casey_coembed&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;To address the lack of discrete clustering we used previously generated data from Casey to anchor our data.&lt;/p&gt;

&lt;p&gt;Using Casey’s peak set alone with the data creates a bit more separation. Though maybe it is mostly from how small and transparent I plotted the points on the UMAP. &lt;a href=&quot;https://ohsu.app.box.com/file/808812473361&quot;&gt;figure-01&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Direct coembedding of the data together fails. Datasets are completely separated. &lt;a href=&quot;https://ohsu.app.box.com/file/808810814006&quot;&gt;figure-02&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;- Setting up the Arrow file with coembedded data, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run_archr_1_setup.Rscript&lt;/code&gt;.
&lt;br /&gt;- Preliminary analysis with the coembedded data, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run_archr_2_coembed.Rscript&lt;/code&gt;.
&lt;br /&gt;- Commands for merging datasets and using the alternative peak set, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run_coembed.txt&lt;/code&gt;.&lt;/p&gt;</content><author><name></name></author><category term="tbr1" /><summary type="html">Directory: /home/groups/oroaklab/nishida/sc_tmp1/casey_coembed</summary></entry><entry><title type="html">Single Cell Alignments with no Alt Chromosomes</title><link href="http://localhost:4000/2021/05/08/post-0009.html" rel="alternate" type="text/html" title="Single Cell Alignments with no Alt Chromosomes" /><published>2021-05-08T00:00:00-07:00</published><updated>2021-05-08T00:00:00-07:00</updated><id>http://localhost:4000/2021/05/08/post-0009</id><content type="html" xml:base="http://localhost:4000/2021/05/08/post-0009.html">&lt;p&gt;Alt chromosomes in our hg38 and mm10 alignments (&lt;a href=&quot;https://genome.ucsc.edu/FAQ/FAQdownloads.html#downloadAlt&quot;&gt;UCSC description&lt;/a&gt;) cause multi-mapping in those regions. BWA flags multi-mapping reads with a MAPQ score of 0 causing them to all be lost downstream in our analysis pipeline. For most single-cell analyses we do not need to consider the alternative chromosomes and they can fall in regions of genes used as markers.&lt;/p&gt;

&lt;p&gt;Here are replaced genome builds without alts. See &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/refs/hg38/GCA_000001405.15_GRCh38/retrieval.txt&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/refs/mm10/GCA_000001635.5_GRCm38.p3_no_alt_analysis_set/retrieval.txt&lt;/code&gt; for origins of FASTA files. Indexes for BWA were recalled with v0.7.15-r1140.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;FASTQ-Align Call&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ln -s /home/groups/oroaklab/demultiplex/201214_NS500556_0445_AHMF2CBGXF/201214_NS500556_0445_AHMF2CBGXF.1.fq.gz testR1.fq.gz
ln -s /home/groups/oroaklab/demultiplex/201214_NS500556_0445_AHMF2CBGXF/201214_NS500556_0445_AHMF2CBGXF.2.fq.gz testR2.fq.gz 
no_alt_align_hg38_=&quot;/home/groups/oroaklab/refs/hg38/hs38d1_noalt.fna.gz&quot;
no_alt_align_mm10_=&quot;/home/groups/oroaklab/refs/hg38/GCA_000001635.5_GRCm38.p3_noalt.fna.gz&quot;
scitools fastq-align -t 28 $no_alt_align_hg38_ testoutput testR1.fq.gz testR2.fq.gz
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;MAPQ using standard genome with alts vs. hs38d1_noalt&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ samtools view /home/groups/oroaklab/adey_lab/projects/Panc_U54/201214_NS500556_0445_AHMF2CBGXF/201214_NS500556_0445_AHMF2CBGXF.bam chr1:198,636,928-198,659,067 | cut -f 5 | sort | uniq -c
   2500 0
$ samtools view testoutput.bam chr1:198,636,928-198,659,067 | cut -f 5 | sort | uniq -c
     19 0
      1 1
      1 6
      3 24
      1 36
      1 39
     22 40
      1 41
      1 44
      1 45
      1 49
      1 50
      1 51
      2 53
      4 54
      1 57
      2 59
   4874 60
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><category term="scitools" /><summary type="html">Alt chromosomes in our hg38 and mm10 alignments (UCSC description) cause multi-mapping in those regions. BWA flags multi-mapping reads with a MAPQ score of 0 causing them to all be lost downstream in our analysis pipeline. For most single-cell analyses we do not need to consider the alternative chromosomes and they can fall in regions of genes used as markers.</summary></entry><entry><title type="html">Single Cell TBR1 Preliminary Evaluations</title><link href="http://localhost:4000/2021/05/07/post-0008.html" rel="alternate" type="text/html" title="Single Cell TBR1 Preliminary Evaluations" /><published>2021-05-07T00:00:00-07:00</published><updated>2021-05-07T00:00:00-07:00</updated><id>http://localhost:4000/2021/05/07/post-0008</id><content type="html" xml:base="http://localhost:4000/2021/05/07/post-0008.html">&lt;p&gt;Directory: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/sc_tmp1&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Ryan made a first pass through this data written up on &lt;a href=&quot;https://mulqueenr.github.io/tbr1/&quot;&gt;his blog&lt;/a&gt;. I used his annotations and kept the old TSS enrichments (ArchR calculates its own internally). He made these after filtering so not all of the cells in the current ArchR project will have entries but these cells are confidently going to be filtered out. I went through ArchR up to about part 6 in the ArchR full manual. I made a broad first pass to get everything recorded, added Ryan’s existing stuff, plotted the metrics, filtered, and then did the dimensionality reduction and clustering. Then after the lab meeting I went and played around the filtering and iterative LSI options.&lt;/p&gt;

&lt;p&gt;General metrics show low TSS enrichment and higher fragment sizes. &lt;a href=&quot;https://ohsu.app.box.com/file/808812070910&quot;&gt;figure-01&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;“The bump around 200 is tagmentation on either side of a nucleosome (they are about 185bp) below that is subnucleosomal, which can be a sign of over-tagmentation or poor chromatin structure. The linker region between nucleosome is 11-80ish no but usually on the much smaller size so you don’t expect two tagmentation events between nucleosomes. I think in this case it is reflecting nucleosomes falling apart/off DNA.”
&lt;br /&gt;-Ryan&lt;/p&gt;

&lt;p&gt;Various UMAPs with different methods, variables, and cutoffs. All of the methods reveal the characteristics of a blob. &lt;a href=&quot;https://ohsu.app.box.com/file/808811822056&quot;&gt;figure-02&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;- Directory setup and bigwig creation, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run.txt&lt;/code&gt;.
&lt;br /&gt;- Setting up the Arrow file, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run_archr_1_setup.Rscript&lt;/code&gt;.
&lt;br /&gt;- Tiling matrix workaround and the main steps without filtering, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run_archr_2_process.Rscript&lt;/code&gt;.
&lt;br /&gt;- Adding annotations, plotting distributions, filtering, and dimred/clustering, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run_archr_3_filter.Rscript&lt;/code&gt;.
&lt;br /&gt;- Similar to preliminary pass but with harder filtering, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run_archr_4_harderfilter.Rscript&lt;/code&gt;.
&lt;br /&gt;- Harder filtering and alternative LSI calling, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run_archr_5_LSIfeatures_harderfilter.Rscript&lt;/code&gt;.
&lt;br /&gt;- All of the above but with also with filtering by fragment size, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run_archr_6_fragFilter_LSIfeatures_harderfilter.Rscript&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;With module R/4.0.4 this little bit will let you load up the current ArchR project for yourself:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# library, resource ArchR
library(presto)
library(ArchR)

# set env
addArchRGenome(&quot;mm10&quot;)
set.seed(25)

# reload the previous project
proj &amp;lt;- loadArchRProject(path = &quot;/home/groups/oroaklab/nishida/sc_tmp1/ArchROutput/&quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><category term="tbr1" /><summary type="html">Directory: /home/groups/oroaklab/nishida/sc_tmp1</summary></entry></feed>