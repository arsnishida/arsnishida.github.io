<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-05-18T11:38:59-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">ARSN Lab Notebook</title><subtitle>ARSN Lab notebook.</subtitle><entry><title type="html">Cron Info for Automatically Running bcl2fastq</title><link href="http://localhost:4000/2022/05/18/post-0086.html" rel="alternate" type="text/html" title="Cron Info for Automatically Running bcl2fastq" /><published>2022-05-18T00:00:00-07:00</published><updated>2022-05-18T00:00:00-07:00</updated><id>http://localhost:4000/2022/05/18/post-0086</id><content type="html" xml:base="http://localhost:4000/2022/05/18/post-0086.html">&lt;p&gt;The cron job scheduler is currently setup on mccovey only. Sudo permissions would be required to set it up on bonds and mays if desired. This just involves fiddling with the files, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/var/spool/cron/&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/cron.allow&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Here is the one cron job scheduled to look for new obnix runs.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;SHELL=/bin/bash
0 * * * * source /home/groups/oroaklab/Modules/default/init/bash; source /home/groups/oroaklab/nishida/cron/setup/profile; /home/groups/oroaklab/nishida/scripts/check_obnix.sh &amp;gt; /home/groups/oroaklab/nishida/cron/check_obnix.cronlog
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0 * * * *&lt;/code&gt; part signifies to run this at the top of every hour.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;source /home/groups/oroaklab/Modules/default/init/bash; source /home/groups/oroaklab/nishida/cron/setup/profile&lt;/code&gt; part is needed to find the modules and setup a proper bash environment for the job.&lt;/p&gt;

&lt;p&gt;The last part, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/scripts/check_obnix.sh&lt;/code&gt;, is the script being run every hour. The comments should explain everything but it looks for new folders, validates the names, checks for the RTAcomplete.txt file, runs &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/scripts/NextSeq2fastq&lt;/code&gt; (this should be identical to what is in the github but not what is hooked up to our module because I don’t have permissions to change the module), and validates it made the output. I had it make a lot of logs but it has been running without errors for months now so you can turn off some of the extra output going forward.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# !/usr/bin/bash

# get date
DATE=$(date +&quot;%y%m%d_%H_%M&quot;)

# move to cron folder
cd /home/groups/oroaklab/nishida/cron

# check the last 5 directories created with the machine name
ls -dt /home/groups/oroaklab/seq/obnix/* | head -n 5 | grep &quot;_VH00711_&quot; &amp;gt; obnix.$DATE.check.txt

# for each of the names...
while read i; do

	# run name
	run=$(echo $i | sed -e 's/.*\///g')

	# count underscore deliminated parts in name, should be four
	namecount=$(echo $i | sed -e 's/.*\///g' | tr '_' '\n' | wc -l)

	# second member of the name should be the machine, &quot;VH00711&quot;
	name=$(echo $i | sed -e 's/.*\///g' | tr '_' '\t' | cut -f 2)

	# if the name is valid...
	if [[ $name == 'VH00711' &amp;amp;&amp;amp; $namecount == '4' ]]; then

		# check for RTA.complete and absence of FASTQ folder
		if [[ -f &quot;/home/groups/oroaklab/seq/obnix/$run/RTAComplete.txt&quot; &amp;amp;&amp;amp; ! -d &quot;/home/groups/oroaklab/fastq/$run&quot; ]]; then

			# run
			sleep 600 # wait in case the RTA complete shows up earlier than it should
			echo -e &quot;Attempting to run NextSeq2fastq for $run&quot; &amp;gt;&amp;gt; obnix.$DATE.log
			perl /home/groups/oroaklab/nishida/scripts/NextSeq2fastq -N -R $run
			echo -e &quot;Finished running NextSeq2fastq for $run&quot; &amp;gt;&amp;gt; obnix.$DATE.log

			# check that backup was made
			if [[ ! -d &quot;/home/groups/oroakdata/fastq/$run&quot; ]]; then
				echo -e &quot;Backup FASTQ folder was not made. Check manually.&quot; &amp;gt;&amp;gt; obnix.$DATE.err
			fi
		fi
	fi

done &amp;lt; obnix.$DATE.check.txt

# save for now
#rm obnix.$DATE.check.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The only part that needs to change when someone takes over is just changing this directory to something of one’s own. The directory just holds the logs from the cron jobs.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# move to cron folder
cd /home/groups/oroaklab/nishida/cron
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><category term="ref" /><summary type="html">The cron job scheduler is currently setup on mccovey only. Sudo permissions would be required to set it up on bonds and mays if desired. This just involves fiddling with the files, /var/spool/cron/ and /etc/cron.allow.</summary></entry><entry><title type="html">Example of HDR Processing via BWA Alignment</title><link href="http://localhost:4000/2022/05/18/post-0085.html" rel="alternate" type="text/html" title="Example of HDR Processing via BWA Alignment" /><published>2022-05-18T00:00:00-07:00</published><updated>2022-05-18T00:00:00-07:00</updated><id>http://localhost:4000/2022/05/18/post-0085</id><content type="html" xml:base="http://localhost:4000/2022/05/18/post-0085.html">&lt;p&gt;Dir: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/example_brooke_amplican&lt;/code&gt;
&lt;br /&gt;Run: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;README.txt&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This was a small demo sent to Brooke to go over how the amplicon analysis was performed outside of CRISPResso and amplican. CRISPresso was aligning reads improperly and this problem is addressed directly by the program, amplican. But in between the switch of these programs we independently made a few scripts to process the alignment cigars of the amplicons. These were compared to results from amplican and similar results were retrieved. I would suggest using amplican going forward but this goes over what we did in that liminal time.&lt;/p&gt;

&lt;p&gt;Here is the copy of the readme of instructions sent to Brooke.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Example of HDR processing via BWA alignment

cd /home/groups/oroaklab/nishida/test_brooke

# array of sample names
array=(A136P-iPS2_sgRNA-4_Rep1 A136P-iPS2_sgRNA-4_Rep2 A136P-iPS2_sgRNA-4_Rep3 A136P-iPS2_sgRNA-3_Rep1 A136P-iPS2_sgRNA-3_Rep2 A136P-iPS2_sgRNA-3_Rep3 A136P-iPS2_A136P-WT_CON CIRM87_WT-WT_CON)

# 1. Obtain your FASTQs for your samples
# This directory has the FASTQ files from the sequencing run from 200215 for HDR after demultiplexing with 8 samples making 16 FASTQs 
fastq_dir=&quot;/home/groups/oroaklab/nishida/test_brooke/1_fastqs&quot;

# 2. Merge paired FASTQs into a single FASTQ with PEAR
merged_dir=&quot;/home/groups/oroaklab/nishida/test_brooke/2_merged&quot;
for i in &quot;${array[@]}&quot;
do
	/home/groups/oroaklab/src/PEAR/pear-0.9.6/pear -y 20G -j 4 -f $fastq_dir/split.$i.R1.fq.gz -r $fastq_dir/split.$i.R2.fq.gz -o $merged_dir/$i.merge.fq
done

# 3. Make a BWA index with just the desired reference sequence.
reference=&quot;/home/groups/oroaklab/nishida/test_brooke/ref/ref_amp.fa&quot;
bwa index $reference

# 4. Align with BWA
align_dir=&quot;/home/groups/oroaklab/nishida/test_brooke/3_alignment&quot;
for i in &quot;${array[@]}&quot;
do
bwa mem $reference $merged_dir/$i.merge.fq.assembled.fastq &amp;gt; $align_dir/$i.sam
done

# I make a little guide like with whitespaces in a text editor for reference and counting.
AMPLICONREF        GCTACCTCCTCTCTCAGTCCAGCCAGCCACAGTCTGCGGCCACTGCTCCCAGTGCCATGTTCCCGTACCCCGGCCAGCACGGACCGGCGCA-CCCGCCTTCTCCATCGGCAGCCCTAGCCGCTACATGGC
EXAMPLE_MERGEDREAD GCTACCTCCTCTCTCAGTCCAGCCAGCCACAGTCTGCGGCCACTGCTCCCAGTGCCATGTTCCCGTACCCCGGCCAGCACGGACCGGCGCACCCCGCCTTCTGCATCGTCAGCGCTAGCCGCTACATGGC
EXAMPLE_R1         GCTACCTCCTCTCTCAGTCCAGCCAGCCACAGTCTGCGGCCACTGCTCCCAGTGCCATGTTCCCGTACCCCGGC
EXAMPLE_REVCOMP_R2                                                         ATGTTCCCGTACCCCGGCCAGCACGGACCGGCGCACCCCGCCTTCTTCATCCTCAGCGCGAGCCGCTACATGGC
BADQUALREGION_R2                                                                                                  GCCTTCTTCATCCTCAGCGCGAGCCGCTAC
GUIDE3                                                               AGTGCCATGTTCCCGTACCC
GUIDE4   															     	                   GCACGGACCGGCGCACCCCG
GUIDE3_NHEJ_REGION                                                            TTCCCGTACCCCGGC
GUIDE4_NHEJ_REGION                                                                         GCCAGCACGGACCGG

# 5. Summarize CIGARS and bin them into groups. The 7 following inputs go into the script and depend on the size of your reads, the guides used, location of the cutsite, etc. and you will want to edit these.

# a. the SAM alignment file, i.e. A136P-iPS2_sgRNA-4_Rep1.sam
# b. the number of bases that must match at the start, i.e. 20 means the first 20 bases must match for the sequence to be considered
# c. start bp for a window for NHEJ, i.e. 50 means the window for NHEJ counting starts at 50
# d. stop bp for a window for NHEJ, i.e. 75 means the window for NHEJ counting ends at 75
# e. the position of the HDR site, i.e. 92 means the 92nd base is deleted
# f. the size of deletions to ignore, i.e. 20 means a deletion of 20bp or larger will not be considered
# g. the full literal pure HDR sequence, i.e. GCTACCTCCTCTCTCAGTCCAGCCAGCCACAGTCTGCGGCCACTGCTCCCAGTGCCATGTTCCCGTACCCCGGCCAGCACGGACCGGCGCACCCGCCTTCTCCATCGGCAGCCCTAGCCGCTACATGGC

# guide 3 parameters
for i in &quot;${array[@]}&quot;
do
perl /home/groups/oroaklab/nishida/test_brooke/hdr_parse_cigar.pl $align_dir/$i.sam 20 50 75 92 20 GCTACCTCCTCTCTCAGTCCAGCCAGCCACAGTCTGCGGCCACTGCTCCCAGTGCCATGTTCCCGTACCCCGGCCAGCACGGACCGGCGCACCCGCCTTCTCCATCGGCAGCCCTAGCCGCTACATGGC
done &amp;gt; summary_g3.txt

# guide 4 parameters
for i in &quot;${array[@]}&quot;
do
perl /home/groups/oroaklab/nishida/test_brooke/hdr_parse_cigar.pl $align_dir/$i.sam 20 72 87 92 20 GCTACCTCCTCTCTCAGTCCAGCCAGCCACAGTCTGCGGCCACTGCTCCCAGTGCCATGTTCCCGTACCCCGGCCAGCACGGACCGGCGCACCCGCCTTCTCCATCGGCAGCCCTAGCCGCTACATGGC
done &amp;gt; summary_g4.txt

# I personally like to keep header information separate from the data itself so I append it to the file here.
cat header.txt summary_g3.txt &amp;gt; temp1; mv temp1 summary_g3.txt
cat header.txt summary_g4.txt &amp;gt; temp2; mv temp2 summary_g4.txt

# The files, 'summary_g3.txt' and 'summary_g4.txt', would be files I would then pass off to you.
# I run everything with both g3 and g4 parameters because the controls need to be evaluated under both different circumstances.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><category term="amplicon" /><summary type="html">Dir: /home/groups/oroaklab/nishida/example_brooke_amplican Run: README.txt</summary></entry><entry><title type="html">Celsee and Docker Info</title><link href="http://localhost:4000/2022/05/18/post-0084.html" rel="alternate" type="text/html" title="Celsee and Docker Info" /><published>2022-05-18T00:00:00-07:00</published><updated>2022-05-18T00:00:00-07:00</updated><id>http://localhost:4000/2022/05/18/post-0084</id><content type="html" xml:base="http://localhost:4000/2022/05/18/post-0084.html">&lt;p&gt;Dir: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/celsee&lt;/code&gt;
&lt;br /&gt;Run: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;notes.txt&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Here is the copy of the steps for using Docker on our cluster and running the Celsee pipeline. You do need sudo privileges to run this and/or setup from ACC to get Docker running.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Celsee Analysis Steps

1. Start Docker
I would suggest not normally having Docker running in the background, only bring it up when you want to use it. Installed via convenience scripts.
Theoretically(?) this is the only step that requires sudo privileges OR a sudo user to grant privileges to run Docker: `sudo usermod -aG docker lowensev`.
$ sudo service docker start

2. Verify that Docker is running
$ systemctl status docker

3. Import in the Celsee pipeline as a Docker image
I have it just living in my directories.
$ cd /home/groups/oroaklab/nishida/celsee/celsee_analysis
$ bash import.sh 

4. Verify that the image was imported
$ docker images

5. Run Celsee pipeline
- The output location is also used as a temp directory which is a problem.
- But also Docker requires the drives be mounted into Docker and we can't mount anything in /home/groups/. Instead go to /tmp and copy everything over.
- You also need sudo privileges to write the output (this is how it is in the manual and I still can't believe this).
- When running as sudo, acc does weird things to group/user privileges so you need to copy EVERYTHING into the /tmp directory.
- Copy over the config file, the fastqs, all reference files, and the entirety of the celsee-analysis script folder (I think you only need some of these copied but do everything to be safe).
- Also, in the config file, the optional fields are actually required to run and FASTQ files MUST end with either '.fastq' or '.fastq.gz'.
$ # move ALL files to a directory in /tmp
$ sudo python3 run_celsee.py eve_test.config . output Human_GRCh38_genomeSAsparseD3

6. Copy output folder back to /home/groups and delete the /tmp directory

7. Remove the Celsee analysis pipeline image
$ docker image rm celsee-analysis

8. And then shut down Docker (also needs sudo privileges)
$ sudo service docker stop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><category term="ref" /><summary type="html">Dir: /home/groups/oroaklab/nishida/celsee Run: notes.txt</summary></entry><entry><title type="html">SPARK IGV HC List Screenshots, 2022</title><link href="http://localhost:4000/2022/05/03/post-0083.html" rel="alternate" type="text/html" title="SPARK IGV HC List Screenshots, 2022" /><published>2022-05-03T00:00:00-07:00</published><updated>2022-05-03T00:00:00-07:00</updated><id>http://localhost:4000/2022/05/03/post-0083</id><content type="html" xml:base="http://localhost:4000/2022/05/03/post-0083.html">&lt;p&gt;Dir: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/spark_mosaic/IGV_2022&lt;/code&gt;
&lt;br /&gt;Run: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run.make_batches.txt&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;IGV screenshots for the high-confidence lists across WES1, WES2, and WES3 are here:
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/home/SPARK%20Mosaics/final/IGV_screenshots&quot;&gt;AT THIS DROPBOX URL&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/sh/jahriezmyrdnyxu/AABfpi29TMJO_9V8euqBGdaza?dl=0&quot;&gt;AT THIS DROPBOX COPIED LINK&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;There are nine Numbers spreadsheets in the folder, one for each of the lists. As a refresher to how the original set was manually annotated, we both only annotated the MOSAIC_CHILD calls and you created four specific categories for the ones that were removed. The categories are largely describing instances of indels and where they are found. There’s a slide on the post with examples of the four categories and your specific note added on to it.
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/krajx3160l2gcu8/IGV_annotation_examples.pdf?dl=0&quot;&gt;Examples of Four Annotation Categories&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="SPARK" /><summary type="html">Dir: /home/groups/oroaklab/nishida/spark_mosaic/IGV_2022 Run: run.make_batches.txt</summary></entry><entry><title type="html">SPARK Mosaic Index, 22-04-28</title><link href="http://localhost:4000/2022/04/28/post-0082.html" rel="alternate" type="text/html" title="SPARK Mosaic Index, 22-04-28" /><published>2022-04-28T00:00:00-07:00</published><updated>2022-04-28T00:00:00-07:00</updated><id>http://localhost:4000/2022/04/28/post-0082</id><content type="html" xml:base="http://localhost:4000/2022/04/28/post-0082.html">&lt;p&gt;Compiled Writing and Figures:
&lt;br /&gt;&lt;a href=&quot;https://docs.google.com/document/d/1q82t5ll2yVP9Fyrwq7jdnZU2bgDnZEgXCu-Tl0VnDDc/edit?usp=sharing&quot;&gt;Google Doc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;High Confidence Lists:
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/dxaae3ehyr7629h/WES1_MQ.highconfidence.txt?dl=0&quot;&gt;WES1, Mutliplex Quads, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/1zmp22l4c4fmmee/WES1_SQ.highconfidence.txt?dl=0&quot;&gt;WES1, Simplex Quads, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/ak42uwc15cnd9fo/WES1_ST.highconfidence.txt?dl=0&quot;&gt;WES1, Simplex Trios, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/0upte7upfszbymc/WES2_MQ.highconfidence.txt?dl=0&quot;&gt;WES2, Mutliplex Quads, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/inijsgyi798thgq/WES2_SQ.highconfidence.txt?dl=0&quot;&gt;WES2, Simplex Quads, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/6nk4u6orq5kwrc5/WES2_ST.highconfidence.txt?dl=0&quot;&gt;WES2, Simplex Trios, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/ddxbgvlnrxbng5o/WES3_MQ.highconfidence.txt?dl=0&quot;&gt;WES3, Mutliplex Quads, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/ahvdwpzu3n9n200/WES3_SQ.highconfidence.txt?dl=0&quot;&gt;WES3, Simplex Quads, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/o70g7kf895qcfr9/WES3_ST.highconfidence.txt?dl=0&quot;&gt;WES3, Simplex Trios, High Confidence Calls&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Burden Lists:
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/f6fpkuxl58hw19c/WES1_MQ.burden.txt?dl=0&quot;&gt;WES1, Multiplex Quads, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/xtwny8uspd7rfqc/WES1_SQ.burden.txt?dl=0&quot;&gt;WES1, Simplex Trios, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/5h9fsgj4f393z7l/WES1_ST.burden.txt?dl=0&quot;&gt;WES1, Simplex Quads, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/jzmnog6ahy88a7p/WES2_MQ.burden.txt?dl=0&quot;&gt;WES2, Multiplex Quads, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/nr8fxgxlvqy5q9o/WES2_SQ.burden.txt?dl=0&quot;&gt;WES2, Simplex Trios, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/98xfdz17b5do0x8/WES2_ST.burden.txt?dl=0&quot;&gt;WES2, Simplex Quads, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/zmjkj8qf07080oq/WES3_MQ.burden.txt?dl=0&quot;&gt;WES3, Multiplex Quads, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/cixj5vwdrdv2b43/WES3_SQ.burden.txt?dl=0&quot;&gt;WES3, Simplex Quads, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/w7frsoyzzfqnsj4/WES3_ST.burden.txt?dl=0&quot;&gt;WES3, Simplex Trios, High Confidence Calls&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Full Lists:
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/srpxn2lz9rzl5bh/WES1.MQ_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.testfilter_noGermlineParental.txt?dl=0&quot;&gt;WES1, Multiplex Quads w/ Strict Test Filter, no Germline Parental&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/a3rva3qx9tohqqn/WES1.SQ_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.testfilter_noGermlineParental.txt?dl=0&quot;&gt;WES1, Simplex Quads w/ Strict Test Filter, no Germline Parental&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/nzljlw8c9t3mox0/WES1.ST_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.testfilter_noGermlineParental.txt?dl=0&quot;&gt;WES1, Simplex Trios w/ Strict Test Filter, no Germline Parental&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/yis33v5xt6fa327/WES2.MQ_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.testfilter_noGermlineParental.txt?dl=0&quot;&gt;WES2, Multiplex Quads w/ Strict Test Filter, no Germline Parental&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/19ah15iu3ugn6oi/WES2.SQ_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.testfilter_noGermlineParental.txt?dl=0&quot;&gt;WES2, Simplex Quads w/ Strict Test Filter, no Germline Parental&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/dfo7pbrxn2qpshr/WES2.ST_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.testfilter_noGermlineParental.txt?dl=0&quot;&gt;WES2, Simplex Trios w/ Strict Test Filter, no Germline Parental&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/cnz4o9febb4ldag/WES3.MQ_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.testfilter_noGermlineParental.txt?dl=0&quot;&gt;WES3, Multiplex Quads w/ Strict Test Filter, no Germline Parental&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/jj9k78aa7nb9lr3/WES3.SQ_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.testfilter_noGermlineParental.txt?dl=0&quot;&gt;WES3, Simplex Quads w/ Strict Test Filter, no Germline Parental&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/8bwivz2eyo6o02j/WES3.ST_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.testfilter_noGermlineParental.txt?dl=0&quot;&gt;WES3, Simplex Trios w/ Strict Test Filter, no Germline Parental&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/97h0nrfdzqlzz0v/WES1.MQ_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.testfilter.txt?dl=0&quot;&gt;WES1, Multiplex Quads w/ Strict Test Filter&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/4ugsef33shvsy0x/WES1.SQ_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.testfilter.txt?dl=0&quot;&gt;WES1, Simplex Quads w/ Strict Test Filter&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/fpnng461st4cn52/WES1.ST_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.testfilter.txt?dl=0&quot;&gt;WES1, Simplex Trios w/ Strict Test Filter&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/0mgba3b4ayrzn92/WES2.MQ_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.testfilter.txt?dl=0&quot;&gt;WES2, Multiplex Quads w/ Strict Test Filter&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/q556he25jasy1rt/WES2.SQ_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.testfilter.txt?dl=0&quot;&gt;WES2, Simplex Quads w/ Strict Test Filter&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/3rsdzaft00ot4fx/WES2.ST_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.testfilter.txt?dl=0&quot;&gt;WES2, Simplex Trios w/ Strict Test Filter&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/0ixrpcxfx4lfp5b/WES3.MQ_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.testfilter.txt?dl=0&quot;&gt;WES3, Multiplex Quads w/ Strict Test Filter&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/hw46orbl9pc4lae/WES3.SQ_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.testfilter.txt?dl=0&quot;&gt;WES3, Simplex Quads w/ Strict Test Filter&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/i1sr8o39p84egda/WES3.ST_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.testfilter.txt?dl=0&quot;&gt;WES3, Simplex Trios w/ Strict Test Filter&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/un4c7j3w6wdk0nl/WES1.MQ_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.txt?dl=0&quot;&gt;WES1, Multiplex Quads w/ Loose Filter&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/h5kk5y4a2fqq995/WES1.SQ_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.txt?dl=0&quot;&gt;WES1, Simplex Quads w/ Loose Filter&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/7nonw2adwrkigse/WES1.ST_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.txt?dl=0&quot;&gt;WES1, Simplex Trios w/ Loose Filter&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/eud1v4v89z3fuxw/WES2.MQ_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.txt?dl=0&quot;&gt;WES2, Multiplex Quads w/ Loose Filter&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/x1z4f68snms5qjk/WES2.SQ_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.txt?dl=0&quot;&gt;WES2, Simplex Quads w/ Loose Filter&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/5kwhnjgfafyr8yi/WES2.ST_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.txt?dl=0&quot;&gt;WES2, Simplex Trios w/ Loose Filter&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/wvabiebeyiduggp/WES3.MQ_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.txt?dl=0&quot;&gt;WES3, Multiplex Quads w/ Loose Filter&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/vu38rku8u07kgxr/WES3.SQ_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.txt?dl=0&quot;&gt;WES3, Simplex Quads w/ Loose Filter&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/sx7emixq31carxd/WES3.ST_mosaics.8reads_0.001popAF_4cohort_3alt_exonic.txt?dl=0&quot;&gt;WES3, Simplex Trios w/ Loose Filter&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Markdowns:
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/svlsuepuxb5iu1h/00_coverage_outliers.html?dl=0&quot;&gt;00, Report Coverage Outliers&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/col92638myx5um0/01_WES1_MQ.prefilt.html?dl=0&quot;&gt;01, WES1, Multiplex Quad Pre-Filtering&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/99f1htx17fb8sve/01_WES1_SQ.prefilt.html?dl=0&quot;&gt;01, WES1, Simplex Quad Pre-Filtering&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/ljydbrehutzgel5/01_WES1_ST.prefilt.html?dl=0&quot;&gt;01, WES1, Simplex Trio Pre-Filtering&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/4c1q23nlepil5hv/01_WES2_MQ.prefilt.html?dl=0&quot;&gt;01, WES2, Multiplex Quad Pre-Filtering&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/1cxh9bibpaxwu9s/01_WES2_SQ.prefilt.html?dl=0&quot;&gt;01, WES2, Simplex Quad Pre-Filtering&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/9eo69neh022bzen/01_WES2_ST.prefilt.html?dl=0&quot;&gt;01, WES2, Simplex Trio Pre-Filtering&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/ydjoi4zdf92b95o/01_WES3_MQ.prefilt.html?dl=0&quot;&gt;01, WES3, Multiplex Quad Pre-Filtering&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/blir9lgbso14ix7/01_WES3_SQ.prefilt.html?dl=0&quot;&gt;01, WES3, Simplex Quad Pre-Filtering&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/g2srho8t0p6nb7c/01_WES3_ST.prefilt.html?dl=0&quot;&gt;01, WES3, Simplex Trio Pre-Filtering&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/vgvcxi7ui6hxndo/02_WES1_MQ.outliercount.html?dl=0&quot;&gt;02, WES1, Multiplex Quad Variant Count Outliers&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/hrirz5hbf5epico/02_WES1_SQ.outliercount.html?dl=0&quot;&gt;02, WES1, Simplex Quad Variant Count Outliers&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/ba1658i4xnz0yla/02_WES1_ST.outliercount.html?dl=0&quot;&gt;02, WES1, Simplex Trio Variant Count Outliers&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/d90v6u1l3inm6wc/02_WES2_MQ.outliercount.html?dl=0&quot;&gt;02, WES2, Multiplex Quad Variant Count Outliers&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/qgln3y33fjn4c8o/02_WES2_SQ.outliercount.html?dl=0&quot;&gt;02, WES2, Simplex Quad Variant Count Outliers&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/rjv89t4oebus1sa/02_WES2_ST.outliercount.html?dl=0&quot;&gt;02, WES2, Simplex Trio Variant Count Outliers&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/w6ozs3viwc83uqs/02_WES3_MQ.outliercount.html?dl=0&quot;&gt;02, WES3, Multiplex Quad Variant Count Outliers&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/qt7zgfbouk75235/02_WES3_SQ.outliercount.html?dl=0&quot;&gt;02, WES3, Simplex Quad Variant Count Outliers&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/lxii8g7ltd0dv7j/02_WES3_ST.outliercount.html?dl=0&quot;&gt;02, WES3, Simplex Trio Variant Count Outliers&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/vow5hhio1mrrww5/03_WES1_MQ.hcburdentable.html?dl=0&quot;&gt;03, WES1, Multiplex Quad HC and Burden Tables&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/jhkcs5v08lvj3xw/03_WES1_SQ.hcburdentable.html?dl=0&quot;&gt;03, WES1, Simplex Quad HC and Burden Tables&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/jjrmo1umtwmqv38/03_WES1_ST.hcburdentable.html?dl=0&quot;&gt;03, WES1, Simplex Trio HC and Burden Tables&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/njol77niyus4afn/03_WES2_MQ.hcburdentable.html?dl=0&quot;&gt;03, WES2, Multiplex Quad HC and Burden Tables&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/l6dlpj36qv6snqv/03_WES2_SQ.hcburdentable.html?dl=0&quot;&gt;03, WES2, Simplex Quad HC and Burden Tables&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/lwwbpfdxzqkaum2/03_WES2_ST.hcburdentable.html?dl=0&quot;&gt;03, WES2, Simplex Trio HC and Burden Tables&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/1b337bb2o79b7jq/03_WES3_MQ.hcburdentable.html?dl=0&quot;&gt;03, WES3, Multiplex Quad HC and Burden Tables&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/zeh30zz2fevmsqw/03_WES3_SQ.hcburdentable.html?dl=0&quot;&gt;03, WES3, Simplex Quad HC and Burden Tables&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/elfy452hmdtssnh/03_WES3_ST.hcburdentable.html?dl=0&quot;&gt;03, WES3, Simplex Trio HC and Burden Tables&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;IGV Shots:
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/sh/jahriezmyrdnyxu/AABfpi29TMJO_9V8euqBGdaza?dl=0&quot;&gt;IGV Shots of High Confidence Sites&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Joint Coverages:
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/l3731hncx2fcmun/jointcov.WES1.MQ.txt?dl=0&quot;&gt;Genomic Joint Coverage, WES1 Multiplex Quads&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/2xtzs29xo0g4owa/jointcov.WES1.SQ.txt?dl=0&quot;&gt;Genomic Joint Coverage, WES1 Simplex Quads&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/4kthhvk58spea82/jointcov.WES1.ST.txt?dl=0&quot;&gt;Genomic Joint Coverage, WES1 Simplex Trios&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/57wkgj0cgrh4v2b/jointcov.WES2.MQ.txt?dl=0&quot;&gt;Genomic Joint Coverage, WES2 Multiplex Quads&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/f4hgv5i8pninzn3/jointcov.WES2.SQ.txt?dl=0&quot;&gt;Genomic Joint Coverage, WES2 Simplex Quads&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/n9bbnmm6jtlde8d/jointcov.WES2.ST.txt?dl=0&quot;&gt;Genomic Joint Coverage, WES2 Simplex Trios&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/tvs3pj7c4tkpa3e/jointcov.WES3.MQ.txt?dl=0&quot;&gt;Genomic Joint Coverage, WES3 Multiplex Quads&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/gn6znkoylpgn6f0/jointcov.WES3.SQ.txt?dl=0&quot;&gt;Genomic Joint Coverage, WES3 Simplex Quads&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/8048eoc8j4t68gg/jointcov.WES3.ST.txt?dl=0&quot;&gt;Genomic Joint Coverage, WES3 Simplex Trios&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Splice Distances:
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/2uvhvd7ki6lvp9d/splice_distances.WES1_MQ.txt?dl=0&quot;&gt;WES1, Multiplex Quads, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/3sf9eim1su24jed/splice_distances.WES1_SQ.txt?dl=0&quot;&gt;WES1, Simplex Quads, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/ylca4v3z3gnfc8n/splice_distances.WES1_ST.txt?dl=0&quot;&gt;WES1, Simplex Trios, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/k07bqimxqryzomm/splice_distances.WES2_MQ.txt?dl=0&quot;&gt;WES2, Multiplex Quads, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/wer0cih4icsjs0n/splice_distances.WES2_SQ.txt?dl=0&quot;&gt;WES2, Simplex Quads, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/rvvhf4kaecgxfsn/splice_distances.WES2_ST.txt?dl=0&quot;&gt;WES2, Simplex Trios, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/aoh20vxqvwkhkr7/splice_distances.WES3_MQ.txt?dl=0&quot;&gt;WES3, Multiplex Quads, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/4l2vsgiyvyfge6b/splice_distances.WES3_SQ.txt?dl=0&quot;&gt;WES3, Simplex Quads, High Confidence Calls&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/bic5g0k3bwrylqn/splice_distances.WES3_ST.txt?dl=0&quot;&gt;WES3, Simplex Trios, High Confidence Calls&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="SPARK" /><category term="INDEX" /><summary type="html">Compiled Writing and Figures: Google Doc</summary></entry><entry><title type="html">scRNA-seq and scATAC-seq Data Analysis DREAM Challenge - Dataset 2 Data Generation</title><link href="http://localhost:4000/2022/04/21/post-0081.html" rel="alternate" type="text/html" title="scRNA-seq and scATAC-seq Data Analysis DREAM Challenge - Dataset 2 Data Generation" /><published>2022-04-21T00:00:00-07:00</published><updated>2022-04-21T00:00:00-07:00</updated><id>http://localhost:4000/2022/04/21/post-0081</id><content type="html" xml:base="http://localhost:4000/2022/04/21/post-0081.html">&lt;p&gt;Program Versions:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;macs2 v2.1.1.20160309
samtools v1.10
bedtools v2.22.0
python v2.7.9
perl v5.16.3
R v3.5.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;R Packages:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; sessionInfo()
R version 3.5.1 (2018-07-02)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: CentOS Linux 7 (Core)

Matrix products: default
BLAS: /home/groups/oroaklab/src/R/R-3.5.1/lib/libRblas.so
LAPACK: /home/groups/oroaklab/src/R/R-3.5.1/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets  methods  
[8] base     

other attached packages:
[1] ComplexHeatmap_1.20.0 Matrix_1.2-18         cisTopic_0.3.0       
[4] Rphenograph_0.99.1    igraph_1.2.4.2        ggplot2_3.2.1 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;STEP 1 - CALLING PEAKS
&lt;br /&gt;INPUT FILE(s): &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;full_dataset.bam&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.bam&lt;/code&gt;
&lt;br /&gt;OUTPUT FILE(s): &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;full_dataset.peaks.bed&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.peaks.bed&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# call peaks, full
$ time macs2 callpeak --keep-dup all -t full_dataset.bam -n test1
real    8m37.638s
user    8m30.649s
sys     0m10.417s

# merge and filter peaks, full
$ perl 01_filter_peaks.pl test1_peaks.narrowPeak test1 500

# call peaks, downsampled
$ time macs2 callpeak --keep-dup all -t downsampled_40.bam -n test2
real    6m16.453s
user    5m54.677s
sys     0m7.381s

# merge and filter peaks, downsampled
$ perl 01.filter_peaks.pl test2_peaks.narrowPeak test2 500

$ md5sum *bed
c18d03f4d22e6938202e9578b2086dad  downsampled_40.500.bed
018e2e40df7f998d19df2f340bbb207c  full_dataset.peaks.bed
018e2e40df7f998d19df2f340bbb207c  test1.500.bed
c18d03f4d22e6938202e9578b2086dad  test2.500.bed
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;STEP 2 - MATRIX GENERATION
&lt;br /&gt;INPUT FILE(s): &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.bam&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.500.bed&lt;/code&gt;
&lt;br /&gt;OUTPUT FILE(s): &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.500.counts.sparseMatrix.cols.gz&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.500.counts.sparseMatrix.rows.gz&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.500.counts.sparseMatrix.values.gz&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;time perl 02.make_count_matrix.pl downsampled_40.bam downsampled_40.500.bed test2
real    3m25.788s
user    5m30.598s
sys     0m8.572s

$ zcat downsampled_40.500.counts.sparseMatrix.values.gz &amp;gt; temp1
$ zcat test2.counts.sparseMatrix.values.gz &amp;gt; temp2
$ md5sum temp*
708ad4f6aabbbfed78771e3bc29fd5da  temp1
708ad4f6aabbbfed78771e3bc29fd5da  temp2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;STEP 3 - DIMENSIONALITY REDUCTION WITH CISTOPICS3
&lt;br /&gt;INPUT FILE(s): &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.500.counts.sparseMatrix.values.gz&lt;/code&gt;
&lt;br /&gt;OUTPUT FILE(s): &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.500.counts.cistopic.15.matrix&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.500.counts.cistopic.20.matrix&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.500.counts.cistopic.25.matrix&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ time Rscript downsampled_40.500.counts.cistopic.r
real    29m28.503s
user    29m16.418s
sys     0m9.162s

# not similar by md5sum
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;STEP 4 - CISTOPIC3 MATRIX TO UMAP DIMS
&lt;br /&gt;INPUT FILE(s): &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.500.counts.cistopic.15.matrix&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.500.counts.cistopic.20.matrix&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.500.counts.cistopic.25.matrix&lt;/code&gt;
&lt;br /&gt;OUTPUT FILE(s): &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.500.counts.cistopic.15.UMAP.dims&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.500.counts.cistopic.20.UMAP.dims&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.500.counts.cistopic.25.UMAP.dims&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ time Rscript downsampled_40.500.counts.cistopic.15.UMAP.R
real    1m1.257s
user    0m59.971s
sys     0m1.055s

$ time Rscript downsampled_40.500.counts.cistopic.20.UMAP.R
real    1m0.584s
user    0m59.771s
sys     0m0.673s

$ time Rscript downsampled_40.500.counts.cistopic.25.UMAP.R
real    1m5.051s
user    1m3.943s
sys     0m0.939s

# not similar by md5sum
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;STEP 5 - CLUSTERING WITH PHENOGRAPHS
&lt;br /&gt;INPUT FILE(s): &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.500.counts.cistopic.15.matrix&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.500.counts.cistopic.20.matrix&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.500.counts.cistopic.25.matrix&lt;/code&gt;
&lt;br /&gt;OUTPUT FILE(s): &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.500.counts.cistopic.15.k50.pg.annot&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.500.counts.cistopic.20.k50.pg.annot&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;downsampled_40.500.counts.cistopic.25.k50.pg.annot&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ time Rscript test2.15.k50.phenograph.R
real	0m24.443s
user	0m23.771s
sys	0m0.549s

$ time Rscript test2.20.k50.phenograph.R
real	0m26.302s
user	0m25.649s
sys	0m0.594s

$ time Rscript test2.25.k50.phenograph.R
real	0m25.757s
user	0m25.171s
sys	0m0.504s

$ md5sum *annot
af37ea4bec6586681b1c814c93a256ce  downsampled_40.500.counts.cistopic.15.k50.pg.annot
bedc6d7799fc618654e63450691cc9b7  downsampled_40.500.counts.cistopic.20.k50.pg.annot
4915ad625b38b70ac7d3f969c4159a97  downsampled_40.500.counts.cistopic.25.k50.pg.annot
af37ea4bec6586681b1c814c93a256ce  test2.15.k50.pg.annot
bedc6d7799fc618654e63450691cc9b7  test2.20.k50.pg.annot
4915ad625b38b70ac7d3f969c4159a97  test2.25.k50.pg.annot
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><category term="dream" /><summary type="html">Program Versions: macs2 v2.1.1.20160309 samtools v1.10 bedtools v2.22.0 python v2.7.9 perl v5.16.3 R v3.5.1</summary></entry><entry><title type="html">scRNA-seq Second Pass Pipeline - 220324_HB_Coassay_RNA</title><link href="http://localhost:4000/2022/04/11/post-0080.html" rel="alternate" type="text/html" title="scRNA-seq Second Pass Pipeline - 220324_HB_Coassay_RNA" /><published>2022-04-11T00:00:00-07:00</published><updated>2022-04-11T00:00:00-07:00</updated><id>http://localhost:4000/2022/04/11/post-0080</id><content type="html" xml:base="http://localhost:4000/2022/04/11/post-0080.html">&lt;p&gt;This describes a second pass at the processing pipeline for sc-RNAseq. The main changes from the first pass are the name changes to the tags and breaking the final steps into multiple parts to use the intermediate output for filtering purposes. Talking with Zach from the Saunders lab, here are some differences or elaborations we can add. Their work seems structured around DropSeq pipelines and tools related to edgeR and making DGE objects. Tag usage seems to indicate a lot being originally adapted from this &lt;a href=&quot;https://github.com/broadinstitute/Drop-seq/blob/master/doc/Drop-seq_Alignment_Cookbook.pdf&quot;&gt;link to DropSeq PDF&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;built around snakemake paired with SLURM jobs&lt;/li&gt;
  &lt;li&gt;uses condaenvs instead of modules	since they are on exacloud&lt;/li&gt;
  &lt;li&gt;uses XC, XM, XG tags vs. the current choice of BC, XU, and XT tags&lt;/li&gt;
  &lt;li&gt;performs read adapter trimming&lt;/li&gt;
  &lt;li&gt;uses cellbender(?) for background removal&lt;/li&gt;
  &lt;li&gt;uses DropSeq tools(?) for cell calling (some method to choose cell filtering thresholds rather than arbitrary thresholds)&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# setup
cd /home/groups/oroaklab/nishida/test_scrna/test_scrna_mar29/
module load picard/2.26.2
module load STAR/2.7.9a
module load subread/2.0.3

# link file
ln -s /home/groups/oroaklab/demultiplex/220324_VH00711_12_AAAV7VKM5/220324_VH00711_12_AAAV7VKM5.scRNA.SL.220324_HB_Coassay_RNA.R1.fq.gz .
FASTQ_FILE=&quot;220324_VH00711_12_AAAV7VKM5.scRNA.SL.220324_HB_Coassay_RNA.R1.fq.gz&quot;

# transform FASTQs to unaligned single-read BAMS
time picard FastqToSam F1=$FASTQ_FILE OUTPUT=$FASTQ_FILE.bam SM=$FASTQ_FILE
#real    9m41.929s

# move bc to XC tag and umi to XM tag
time samtools view -h $FASTQ_FILE.bam | awk '/^@/ {print;next} {N=split($1,n,&quot;:&quot;); O=split(n[2],o,&quot;=&quot;); print $0 &quot;\tXC:Z:&quot; n[1] &quot;\tXM:Z:&quot; o[2]}' | samtools view -bS - &amp;gt; temp.bam
#real    7m11.938s

# STAR alignment of unaligned BAM to reference
time STAR --runThreadN 24 --genomeDir /home/groups/oroaklab/refs/STAR/hg38 --readFilesCommand samtools view -h --readFilesType SAM SE --readFilesIn temp.bam --outSAMtype BAM Unsorted --outFilterScoreMinOverLread 0 --outFilterMatchNminOverLread 0 --outFileNamePrefix aligned
#real    7m16.440s

# sort
time samtools sort alignedAligned.out.bam -o alignedAligned.out.sort.bam
#real    15m23.468s

# use subread's featurecounts to add in 'XT' tags
time featureCounts -a /home/groups/oroaklab/refs/STAR/Homo_sapiens.GRCh38.104.gtf -R BAM -g gene_id -Q 30 -s 0 -T 24 -o alignedAligned.out.sort.annot.bam alignedAligned.out.sort.bam
#real    0m28.182s

# open SAM, filter for Q, pull out columns, use only uniquely mapping annotated reads, strip labels
QFILTER=&quot;20&quot;
samtools view -q ${QFILTER} alignedAligned.out.sort.bam.featureCounts.bam | cut -f 12,17,18,21 | awk '$1 == &quot;NH:i:1&quot; &amp;amp;&amp;amp; $4 != &quot;&quot;' | awk '$1 == &quot;NH:i:1&quot; &amp;amp;&amp;amp; $4 != &quot;&quot;' | sed -e 's/..:Z://g' &amp;gt; TEMP
#real	2m21.242s

# count cell info from TEMP file
time perl count_cell_info.pl TEMP &amp;gt; metrics_cell_counts.txt
#real	0m15.108s

# example header of output
# CELL	TOTAL_READS	UNIQUE_UMIS	UNIQUE_UMIS_ANNOTS	PERCENT_UNIQ
# CCGGTATCGTGGTACCGGCTAAGAGACT	7	7	7	100
# CCGGTATCGTCCAATTCCATGGTTCAGC	5142	328	352	6.84558537534033
# CCGGTATCGTATAATCGCGGTCATATAG	1354	163	165	12.1861152141802

# make sparse, keep only unique combinations, remove UMI info, count, format to sparse
time cat TEMP | sort | uniq | cut -f 2,4 | uniq -c | sed -e 's/^[ ]*//g' | awk '{print $3,$2,$1}' | tr ' ' '\t' &amp;gt; TEMP2
#real	1m54.927s
cat TEMP2 | cut -f 1 | sort -n | uniq &amp;gt; 220324_HB_Coassay_RNA.sparseMatrix.rows

# make list of cells to use
UMI_PER_CELL_CUTOFF=100
UNIQ_PER_CUTOFF=10
cat metrics_cell_counts.txt | awk -v umicut=$UMI_PER_CELL_CUTOFF -v uniqcut=$UNIQ_PER_CUTOFF '$3 &amp;gt; umicut &amp;amp;&amp;amp; $5 &amp;lt; uniqcut' | cut -f 1 | sort -n &amp;gt; 220324_HB_Coassay_RNA.sparseMatrix.cols

# make sparse
perl make_sparse.pl 220324_HB_Coassay_RNA.sparseMatrix.rows 220324_HB_Coassay_RNA.sparseMatrix.cols TEMP2 | sort -n -k 1,2 &amp;gt; 220324_HB_Coassay_RNA.sparseMatrix.values

# make fake rows with BED positions not gene names to trick cistopics
mv 220324_HB_Coassay_RNA.sparseMatrix.rows 220324_HB_Coassay_RNA.sparseMatrix.rows_save
cat /home/groups/oroaklab/refs/hg38/masterlistDHS/DHS_Index_and_Vocabulary_hg38_WM20190703.non_overlap.bed | head -n 20446 &amp;gt; 220324_HB_Coassay_RNA.sparseMatrix.rows

# cistopics on sparse matrix and plot
scitools matrix-cistopic3 -X 220324_HB_Coassay_RNA.sparseMatrix.values
scitools matrix-umap 220324_HB_Coassay_RNA.cistopic.30.matrix
scitools matrix-pg 220324_HB_Coassay_RNA.cistopic.30.matrix
scitools plot-dims -A 220324_HB_Coassay_RNA.cistopic.30.k50.pg.annot 220324_HB_Coassay_RNA.cistopic.30.UMAP.dims 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And here is a shot of the data gone through dimensionality reduction with cistopics. Relatively cleaned up despite very few reads being used.
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/utobouaeouw3nqr/blog_scrna.220324_HB_Coassay_RNA.cistopic.30.UMAP_pass2.plot.png?dl=0&quot;&gt;UMAP of scRNA-seq&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="scrna" /><summary type="html">This describes a second pass at the processing pipeline for sc-RNAseq. The main changes from the first pass are the name changes to the tags and breaking the final steps into multiple parts to use the intermediate output for filtering purposes. Talking with Zach from the Saunders lab, here are some differences or elaborations we can add. Their work seems structured around DropSeq pipelines and tools related to edgeR and making DGE objects. Tag usage seems to indicate a lot being originally adapted from this link to DropSeq PDF. built around snakemake paired with SLURM jobs uses condaenvs instead of modules since they are on exacloud uses XC, XM, XG tags vs. the current choice of BC, XU, and XT tags performs read adapter trimming uses cellbender(?) for background removal uses DropSeq tools(?) for cell calling (some method to choose cell filtering thresholds rather than arbitrary thresholds)</summary></entry><entry><title type="html">SPARK WES2 and WES3 Outliers by Counts and Coverage</title><link href="http://localhost:4000/2022/04/08/post-0079.html" rel="alternate" type="text/html" title="SPARK WES2 and WES3 Outliers by Counts and Coverage" /><published>2022-04-08T00:00:00-07:00</published><updated>2022-04-08T00:00:00-07:00</updated><id>http://localhost:4000/2022/04/08/post-0079</id><content type="html" xml:base="http://localhost:4000/2022/04/08/post-0079.html">&lt;p&gt;These markdowns represent the data preparation and figure generation for identifying outliers. Coverages are merged across lists in a separate markdown.&lt;/p&gt;

&lt;p&gt;Markdowns:
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/thbr9vgqibvbobj/01_WES2_SQ.html?dl=0&quot;&gt;WES2_SQ Prep&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/we6ixqoi5iedtfn/01_WES2_MQ.html?dl=0&quot;&gt;WES2_MQ Prep&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/2lt3iohpemotvew/01_WES2_ST.html?dl=0&quot;&gt;WES2_ST Prep&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/cpwikcnv1hrjx34/01_WES3_SQ.html?dl=0&quot;&gt;WES3_SQ Prep&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/q7eahh0vj743377/01_WES3_MQ.html?dl=0&quot;&gt;WES3_MQ Prep&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/j0aqujobwvemu0a/01_WES3_ST.html?dl=0&quot;&gt;WES3_ST Prep&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/5ytjk71msu8xe21/02_WES2_SQ.html?dl=0&quot;&gt;WES2_SQ Outlier Plots&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/ldlqrday2v6cpq7/02_WES2_MQ.html?dl=0&quot;&gt;WES2_MQ Outlier Plots&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/8meafdj3kj3ec10/02_WES2_ST.html?dl=0&quot;&gt;WES2_ST Outlier Plots&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/gw650phhs3db3xx/02_WES3_SQ.html?dl=0&quot;&gt;WES3_SQ Outlier Plots&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/6mfpzw4pl8996e3/02_WES3_MQ.html?dl=0&quot;&gt;WES3_MQ Outlier Plots&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/jeeqfj7bcdrhfxn/02_WES3_ST.html?dl=0&quot;&gt;WES3_ST Outlier Plots&lt;/a&gt;
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/7gcqbxsjhtdy7nd/02_WES2_WES3_combined.html?dl=0&quot;&gt;WES2 and WES3 Combined Coverage Plots&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Relevant plots for outlier detection here: &lt;a href=&quot;https://www.dropbox.com/s/ixc4lo7a0uh7irh/wes2_wes3_outlier_cov.pdf?dl=0&quot;&gt;outlier figures&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;From the combination of the coverages, the lowest 0-5% of families in coverage came from the following lists showing the worse coverages in WES3:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Num Families in Lowest Fifth-Tile by List
WES2_MQ - 4, WES2_SQ - 2, WES2_ST - 9
WES3_MQ - 19, WES3_SQ - 52, WES3_ST - 38
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There were 32 outliers calls using the same count thresholds as the WES1 list. As contrast, the WES1 lists had only 10 outlying calls with ~33% more families.&lt;/p&gt;

&lt;p&gt;All family outliers by list and FRACTION annotation:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;6, MOSAIC_CHILD, WES2.MQ
##        FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE
## 72  SF0158322    SIB               0.3928909     6           15.27141
## 183 SF0075609    PRO               0.5239183    14           26.72173
## 265 SF0151665    PRO               0.5931233     6           10.11594
## 376 SF0202052    SIB               0.7676529     9           11.72405

1, MOSAIC_CHILD, WES3.ST
##        FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE
## 357 SF0323152    PRO               0.7481966    74           98.90449

3, GERMLINE_CHILD, WES2.MQ
##        FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE
## 4   SF0149123    SIB               0.1322793     2           15.11953
## 6   SF0163256    SIB               0.1918058    10           52.13608
## 342 SF0223942    SIB               0.7000389    77          109.99389

2, GERMLINE_CHILD, WES3.MQ
##        FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE
## 2   SF0358698    SIB               0.0892429     5           56.02686
## 230 SF0283718    SIB               0.6034980    59           97.76337

3, MOSAIC_PARENTAL_NONTRANS, WES2.SQ
##        FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE
## 3   SF0170260     FA               0.2105921     3           14.24555
## 29  SF0228054     FA               0.3018997     9           29.81122
## 129 SF0153456     FA               0.6423237    27           42.03488

1, MOSAIC_PARENTAL_NONTRANS, WES2.MQ
##        FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE
## 204 SF0181472     MO               0.5424785    39           71.89225

5, MOSAIC_PARENTAL_NONTRANS, WES2.ST
##         FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE
## 11   SF0149922     FA               0.2254580     9           39.91874
## 313  SF0199636     FA               0.4987807    82          164.40092
## 580  SF0245361     MO               0.5896181     8           13.56810
## 601  SF0161221     FA               0.5944195     8           13.45851
## 1164 SF0151784     MO               0.7809484    57           72.98818
## 1201 SF0042891     FA               0.7965546    23           28.87436

3, MOSAIC_PARENTAL_NONTRANS, WES3.SQ
##        FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE
## 63  SF0336708     FA               0.2639459     4           15.15462
## 78  SF0342265     MO               0.2768700     4           14.44721
## 159 SF0324757     FA               0.3945041  2808         7117.79595

2, MOSAIC_PARENTAL_NONTRANS, WES2.MQ
##       FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE
## 12 SF0350442     MO               0.1662686     2           12.02873
## 20 SF0319187     MO               0.1995900     3           15.03081

5, MOSAIC_PARENTAL_NONTRANS, WES3.ST
##        FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE
## 4   SF0360546     MO               0.1294841     7           54.06067
## 28  SF0288445     MO               0.2055009     3           14.59847
## 59  SF0197166     FA               0.2550314   100          392.10863
## 104 SF0364547     MO               0.3277593     9           27.45917
## 157 SF0363100     FA               0.3803137     7           18.40586

1, MOSAIC_PARENTAL_TRANS, WES3.MQ
##       FAMILY PERSON PERCENT_BASES_AUTOSOMAL COUNT SNVS_PER_EXOMEBASE
## 57 SF0369960     FA               0.3092882     2           6.466462
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><category term="SPARK" /><summary type="html">These markdowns represent the data preparation and figure generation for identifying outliers. Coverages are merged across lists in a separate markdown.</summary></entry><entry><title type="html">Shotgun Sequencing of Amplicon Sequence, 220406</title><link href="http://localhost:4000/2022/04/06/post-0078.html" rel="alternate" type="text/html" title="Shotgun Sequencing of Amplicon Sequence, 220406" /><published>2022-04-06T00:00:00-07:00</published><updated>2022-04-06T00:00:00-07:00</updated><id>http://localhost:4000/2022/04/06/post-0078</id><content type="html" xml:base="http://localhost:4000/2022/04/06/post-0078.html">&lt;p&gt;Dir: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/amplicon_220406&lt;/code&gt;
&lt;br /&gt;Run: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/groups/oroaklab/nishida/amplicon_220406/run.txt&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This describes how to find our desired edit from shotgun sequencing of amplicon sequence. In lieu of standard amplicon input, we are taking the reads, aligning to hg38, and using GATK’s Haplotype Caller to identify the changes. Reads are being treated as paired-end and as a side-note about half the reads can be merged by overlap.&lt;/p&gt;

&lt;p&gt;The description of the reference creation, interpretation, and format of the summary is described here: &lt;a href=&quot;https://arsnishida.github.io/2022/03/07/post-0075.html&quot;&gt;first amplicon sequencing results&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For each sample, the following output is provided:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;SAMPLE - Sample ID.&lt;/li&gt;
  &lt;li&gt;EDIT_T_OR_F - True if the variant 161416811 AC to A is called. False if otherwise.&lt;/li&gt;
  &lt;li&gt;DEPTH - The depth at 161416811 if EDIT_T_OR_F is True. NA if False.&lt;/li&gt;
  &lt;li&gt;ALT_DEPTH - The depth of the edit at 161416811 if EDIT_T_OR_F is True. NA if False.&lt;/li&gt;
  &lt;li&gt;EDIT_FREQ - ALT_DEPTH / DEPTH&lt;/li&gt;
  &lt;li&gt;NUM_VARS_IN_NHEJ_REGION - The number of other variants called in the NHEJ region, 161416793-161416808.&lt;/li&gt;
  &lt;li&gt;NUM_VARS_WITHIN_10_BP - The number of other variants called +/- 10bp from 161416811 (161416801-161416821).&lt;/li&gt;
  &lt;li&gt;NUM_VARS_WITHIN_25_BP - The number of other variants called +/- 25bp from 161416811 (161416786-161416836).&lt;/li&gt;
  &lt;li&gt;NUM_VARS_WITHIN_50_BP - The number of other variants called +/- 50bp from 161416811 (161416761-161416861).&lt;/li&gt;
  &lt;li&gt;READ_DEPTH_AT_161416811 - Number of reads at the site via GATK DepthOfCoverage (not going to be the same as the depths counted via Haplotype Caller due to local alignment)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This output is copy+pasted below here. The edit was found in the A136P controls and all the other non-control samples with at least 1000 reads of coverage. It was also found in the HDR7_NTC control but it and the HDR6_NTC control had nearly no reads.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#SAMPLE	EDIT_T_OR_F	DEPTH	ALT_DEPTH	EDIT_FREQ	NUM_VARS_IN_NHEJ_REGION	NUM_VARS_WITHIN_10_BP	NUM_VARS_WITHIN_25_BP	NUM_VARS_WITHIN_50_BP	READ_DEPTH_AT_161416811
HDR6_A136P_Control	TRUE	2648	1280	0.483383685800604	0	0	0	0	5652
HDR6_CIRM87	FALSE	NA	NA	NA	0	0	0	0	6117
HDR6_NTC	FALSE	NA	NA	NA	0	0	0	0	16
HDR6_sg4_SYN88_1	TRUE	2721	1004	0.368981991914737	1	0	1	1	6791
HDR6_sg4_SYN88_2	TRUE	2772	1038	0.374458874458874	1	0	1	1	6219
HDR6_sg4_SYN88_3	TRUE	2708	974	0.359675036927622	1	0	1	1	5567
HDR6_sg4_WT88_1	TRUE	2794	1128	0.403722261989979	0	0	0	0	7411
HDR6_sg4_WT88_2	TRUE	2841	1019	0.358676522351285	0	0	0	0	6783
HDR6_sg4_WT88_3	TRUE	2798	959	0.342744817726948	0	0	0	0	6720
HDR7_A136P_Control	TRUE	2768	1299	0.469291907514451	0	0	0	0	7322
HDR7_CIRM87	FALSE	NA	NA	NA	0	0	0	0	5979
HDR7_NTC	TRUE	49	27	0.551020408163265	0	0	0	0	30
HDR7_sg4M_SYN88_1	TRUE	2798	1245	0.444960686204432	0	0	0	0	7936
HDR7_sg4M_SYN88_2	TRUE	2795	1229	0.439713774597496	0	0	0	0	7049
HDR7_sg4M_SYN88_3	TRUE	2797	1256	0.449052556310332	0	0	0	0	7418
HDR7_sg4M_SYN88_4	TRUE	2814	1187	0.42181947405828	0	0	0	0	8328
HDR7_sg4M_WT88_1	TRUE	2760	1315	0.476449275362319	0	0	0	0	6757
HDR7_sg4M_WT88_2	TRUE	2706	1189	0.439393939393939	0	0	0	0	6162
HDR7_sg4M_WT88_3	TRUE	2708	1206	0.445347119645495	0	0	0	0	6155
HDR7_sg4M_WT88_4	TRUE	2758	1292	0.468455402465555	0	0	0	0	6581
HDR7_sg4_SYN88_1	TRUE	2813	1230	0.437255599004621	0	0	0	0	7298
HDR7_sg4_SYN88_2	TRUE	2735	1294	0.473126142595978	0	0	0	0	6037
HDR7_sg4_SYN88_3	TRUE	2682	1159	0.43214019388516	0	0	0	0	6421
HDR7_sg4_SYN88_4	TRUE	2790	1198	0.429390681003584	0	0	0	0	6627
HDR7_sg4_WT88_1	TRUE	2758	1237	0.448513415518492	0	0	0	0	8276
HDR7_sg4_WT88_2	TRUE	2853	1251	0.438485804416404	0	0	0	0	7712
HDR7_sg4_WT88_3	TRUE	1572	637	0.405216284987277	0	0	0	0	1715
HDR7_sg4_WT88_4	TRUE	2767	1310	0.473436935308999	0	0	0	0	7281
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here is a list of all the variants/edit appearing more than once and their count.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;     25 chr2    161416811       AC      A
      5 chr2    161416993       ACCCAGC A
      5 chr2    161416990       TC      T
      5 chr2    161416582       G       T
      3 chr2    161416794       C       A
      3 chr2    161416581       G       T
      2 chr2    161417380       G       A
      2 chr2    161416993       A       AGGT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><category term="amplicon" /><summary type="html">Dir: /home/groups/oroaklab/nishida/amplicon_220406 Run: /home/groups/oroaklab/nishida/amplicon_220406/run.txt</summary></entry><entry><title type="html">scRNA-seq First Pass Pipeline - 220324_HB_Coassay_RNA</title><link href="http://localhost:4000/2022/04/03/post-0077.html" rel="alternate" type="text/html" title="scRNA-seq First Pass Pipeline - 220324_HB_Coassay_RNA" /><published>2022-04-03T00:00:00-07:00</published><updated>2022-04-03T00:00:00-07:00</updated><id>http://localhost:4000/2022/04/03/post-0077</id><content type="html" xml:base="http://localhost:4000/2022/04/03/post-0077.html">&lt;p&gt;Here is a rough, first pass processing pipeline for sc-RNAseq. In general, it works by turning the FASTQ into a BAM and adding the barcodes, UMIs, alignment, and annotation to that BAM. The purpose is creating a complete BAM that can then be filtered, de-duped, and counted on the fly. This means there’s only one single BAM with all the information and one can pull out what they need from it without having to go back steps. The broad steps are adapted from the following pipeline: https://github.com/epigen/scifiRNA-seq.&lt;/p&gt;

&lt;p&gt;Here are some issues with the technical side of the pipeline.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The barcodes are saved in the BC tag and the UMIs are saved in the XU tag. These are appropriate, standardized tags but there are various other standardized tags that conceivably these can go under.&lt;/li&gt;
  &lt;li&gt;Deduplication technically does what it is supposed to do, it looks at the combination of barcode+umi+annotatedGene and keeps only unique results. It is written in with just bash sort and uniq commands parsing the BAM. This is a nice shortcut but it is likely we will want to save an entirely new BAM for the purposes of visualization.&lt;/li&gt;
  &lt;li&gt;In this one test pass I am not filtering for alignment quality but this would be simple to add in with the samtools view command.&lt;/li&gt;
  &lt;li&gt;I ran deduplication with scitools rmdup and picard MarkDuplicates. There is a part of me that thinks scitools rmdup should just work for this but I would need to dig into why or why not more specifically. To get picard MarkDuplicates to be barcode and UMI aware I believe we would need to make a new tag that combines the two together. It’s worth testing this out and comparing but the existing solution works for now.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Pipeline:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# setup
cd /home/groups/oroaklab/nishida/test_scrna/test_scrna_mar29/
module load picard/2.26.2
module load STAR/2.7.9a
module load subread/2.0.3

# link file
ln -s /home/groups/oroaklab/demultiplex/220324_VH00711_12_AAAV7VKM5/220324_VH00711_12_AAAV7VKM5.scRNA.SL.220324_HB_Coassay_RNA.R1.fq.gz .
FASTQ_FILE=&quot;220324_VH00711_12_AAAV7VKM5.scRNA.SL.220324_HB_Coassay_RNA.R1.fq.gz&quot;

# transform FASTQs to unaligned single-read BAMS
picard FastqToSam F1=$FASTQ_FILE OUTPUT=$FASTQ_FILE.bam SM=$FASTQ_FILE

# move bc to BC tag and umi to XU tag
samtools view -h $FASTQ_FILE.bam | awk '/^@/ {print;next} {N=split($1,n,&quot;:&quot;); O=split(n[2],o,&quot;=&quot;); print $0 &quot;\tBC:Z:&quot; n[1] &quot;\tXU:Z:&quot; o[2]}' | samtools view -bS - &amp;gt; temp.bam

# STAR alignment of unaligned BAM to reference
STAR --runThreadN 24 --genomeDir /home/groups/oroaklab/refs/STAR/hg38 --readFilesCommand samtools view -h --readFilesType SAM SE --readFilesIn temp.bam --outSAMtype BAM Unsorted --outFilterScoreMinOverLread 0 --outFilterMatchNminOverLread 0 --outFileNamePrefix aligned

# sort
samtools sort alignedAligned.out.bam -o alignedAligned.out.sort.bam

# use subread's featurecounts to add in 'XT' tags
featureCounts -a /home/groups/oroaklab/refs/STAR/Homo_sapiens.GRCh38.104.gtf -R BAM -g gene_id -Q 30 -s 0 -T 24 -o alignedAligned.out.sort.annot.bam alignedAligned.out.sort.bam

# make sparse
# open SAM, pull out columns, use only uniquely mapping annotated reads, strip labels, keep only unique combinations, remove UMI info, count, format to sparse
samtools view alignedAligned.out.sort.bam.featureCounts.bam | cut -f 12,17,18,21 | awk '$1 == &quot;NH:i:1&quot; &amp;amp;&amp;amp; $4 != &quot;&quot;' | sed -e 's/..:Z://g' | sort | uniq | cut -f 2,4 | uniq -c | sed -e 's/^[ ]*//g' | awk '{print $3,$2,$1}' | tr ' ' '\t' &amp;gt; z.hg38.txt
cat z.hg38.txt | cut -f 1 | sort -n | uniq &amp;gt; sparse.hg38.rows
cat z.hg38.txt | cut -f 2 | sort -n | uniq &amp;gt; sparse.hg38.cols
perl make_sparse.pl sparse.hg38.rows sparse.hg38.cols z.hg38.txt | sort -n -k 1,2 &amp;gt; sparse.hg38.values

# make fake rows with BED positions and not gene names to trick cistopics
# cistopics on sparse matrix and plot
scitools matrix-cistopic3 -X 220324_HB_Coassay_RNA.sparseMatrix.values
scitools matrix-umap 220324_HB_Coassay_RNA.cistopic.50.matrix
scitools matrix-pg 220324_HB_Coassay_RNA.cistopic.50.matrix
scitools plot-dims -A 220324_HB_Coassay_RNA.cistopic.50.k50.pg.annot 220324_HB_Coassay_RNA.cistopic.50.UMAP.dims

# for future reference...
#scitools bam-rmdup -t 24 temp_tag.hg38Aligned.sorted.out.bam
#picard MarkDuplicates I=temp_tag.hg38Aligned.sorted.out.bam REMOVE_DUPLICATES=true O=temp_tag.hg38Aligned.sorted.rmdup.out.bam M=rmdup_metrics.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here are some metrics with the output which might identify some problems. In general, the amount of usable data at the end seems too low but I also don’t know all the expectations.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Uniquely aligning reads is high at ~80%&lt;/li&gt;
  &lt;li&gt;The number of reads that were even annotated was low. ~10M reads which is ~18% of the total. This includes every read too so also multi-mapping reads. The annotation currently does not include rRNA which might be where all the reads are going?&lt;/li&gt;
  &lt;li&gt;The number of annotated, uniquely mapping, and deduplicated reads is similarly low at less than 1 million reads.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# number of initial reads
$ zcat 220324_VH00711_12_AAAV7VKM5.scRNA.SL.220324_HB_Coassay_RNA.R1.fq.gz | wc -l | awk '{print $1/4}'
55,896,785

# alignment percentages
$ cat alignedLog.final.out | grep &quot;%&quot;
                        Uniquely mapped reads % |	79.59%
                      Mismatch rate per base, % |	1.41%
                         Deletion rate per base |	0.02%
                        Insertion rate per base |	0.03%
             % of reads mapped to multiple loci |	18.33%
             % of reads mapped to too many loci |	1.80%
       % of reads unmapped: too many mismatches |	0.00%
                 % of reads unmapped: too short |	0.00%
                     % of reads unmapped: other |	0.28%
                            % of chimeric reads |	0.00%

# number of annotated reads
$ cat alignedAligned.out.sort.annot.bam.summary | grep &quot;Assigned&quot;
Assigned	9926854

# number of de-deduplicated annotated reads
$ cat 220324_HB_Coassay_RNA.sparseMatrix.values | awk '{sum+=$3}END{print sum}'
603194
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And here is a shot of the data gone through dimensionality reduction with cistopics. There’s structure but a lot of messy, diverse clusters. I think the messiness makes sense given the extra sparseness of the matrix.
&lt;br /&gt;&lt;a href=&quot;https://www.dropbox.com/s/rby6ltxidup3oag/blog_scrna.220324_HB_Coassay_RNA.cistopic.50.UMAP.plot.png?dl=0&quot;&gt;UMAP of scRNA-seq&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="scrna" /><summary type="html">Here is a rough, first pass processing pipeline for sc-RNAseq. In general, it works by turning the FASTQ into a BAM and adding the barcodes, UMIs, alignment, and annotation to that BAM. The purpose is creating a complete BAM that can then be filtered, de-duped, and counted on the fly. This means there’s only one single BAM with all the information and one can pull out what they need from it without having to go back steps. The broad steps are adapted from the following pipeline: https://github.com/epigen/scifiRNA-seq.</summary></entry></feed>